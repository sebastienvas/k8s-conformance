Activated service account credentials for: [gob-prow@gob-prow.iam.gserviceaccount.com]
fatal: Not a git repository (or any of the parent directories): .git
+ /workspace/scenarios/kubernetes_e2e.py --check-version-skew=false --cluster= --deployment=gke --extract=gke-default --gcp-node-image=gci --gcp-network=default --gcp-project=senlu-customer-gce-staging --gcp-zone=us-west1-pj1 --gke-environment=https://gce-staging-sandbox-test-container.sandbox.googleapis.com/ --provider=gke '--test_args=--ginkgo.focus=\[Conformance\] --ginkgo.skip=Alpha|\[(Disruptive|Feature:[^\]]+|Flaky)\] --gce-api-endpoint=https://www.googleapis.com/compute/cm_staging_v1/' --timeout=200m
starts with local mode
Environment:
ARTIFACTS=/logs/artifacts
BAZEL_REMOTE_CACHE_ENABLED=false
BAZEL_VERSION=0.23.2
BOSKOS_METRICS_PORT=tcp://10.47.252.108:8888
BOSKOS_METRICS_PORT_8888_TCP=tcp://10.47.252.108:8888
BOSKOS_METRICS_PORT_8888_TCP_ADDR=10.47.252.108
BOSKOS_METRICS_PORT_8888_TCP_PORT=8888
BOSKOS_METRICS_PORT_8888_TCP_PROTO=tcp
BOSKOS_METRICS_SERVICE_HOST=10.47.252.108
BOSKOS_METRICS_SERVICE_PORT=8888
BOSKOS_METRICS_SERVICE_PORT_DEFAULT=8888
BOSKOS_PORT=tcp://10.47.245.87:80
BOSKOS_PORT_80_TCP=tcp://10.47.245.87:80
BOSKOS_PORT_80_TCP_ADDR=10.47.245.87
BOSKOS_PORT_80_TCP_PORT=80
BOSKOS_PORT_80_TCP_PROTO=tcp
BOSKOS_SERVICE_HOST=10.47.245.87
BOSKOS_SERVICE_PORT=80
BOSKOS_SERVICE_PORT_DEFAULT=80
BUILD_ID=1128314412210327555
BUILD_NUMBER=1128314412210327555
CLOUDSDK_COMPONENT_MANAGER_DISABLE_UPDATE_CHECK=true
CLOUDSDK_CORE_DISABLE_PROMPTS=1
CLOUDSDK_EXPERIMENTAL_FAST_COMPONENT_UPDATE=false
DOCKER_IN_DOCKER_ENABLED=false
E2E_GOOGLE_APPLICATION_CREDENTIALS=/etc/service-account/service-account.json
ENTRYPOINT_OPTIONS={"timeout":13200000000000,"grace_period":15000000000,"artifact_dir":"/logs/artifacts","args":["runner.sh","/workspace/scenarios/kubernetes_e2e.py","--check-version-skew=false","--cluster=","--deployment=gke","--extract=gke-default","--gcp-node-image=gci","--gcp-network=default","--gcp-project=senlu-customer-gce-staging","--gcp-zone=us-west1-pj1","--gke-environment=https://gce-staging-sandbox-test-container.sandbox.googleapis.com/","--provider=gke","--test_args=--ginkgo.focus=\\[Conformance\\] --ginkgo.skip=Alpha|\\[(Disruptive|Feature:[^\\]]+|Flaky)\\] --gce-api-endpoint=https://www.googleapis.com/compute/cm_staging_v1/","--timeout=200m"],"process_log":"/logs/process-log.txt","marker_file":"/logs/marker-file.txt","metadata_file":"/logs/artifacts/metadata.json"}
GOOGLE_APPLICATION_CREDENTIALS=/etc/service-account/service-account.json
GOPATH=/home/prow/go
GO_TARBALL=go1.12.1b4.linux-amd64.tar.gz
HOME=/workspace
HOSTNAME=1721524d-7659-11e9-9653-7621f038c66b
IMAGE=gcr.io/k8s-testimages/kubekins-e2e:v20190419-3a36c16-master
INSTANCE_PREFIX=e2e-f3159dd9b8-3e8d8
JENKINS_GCE_SSH_PRIVATE_KEY_FILE=/workspace/.ssh/google_compute_engine
JENKINS_GCE_SSH_PUBLIC_KEY_FILE=/workspace/.ssh/google_compute_engine.pub
JOB_NAME=ci-kubernetes-e2e-gke-on-gce-staging-conformance
JOB_SPEC={"type":"periodic","job":"ci-kubernetes-e2e-gke-on-gce-staging-conformance","buildid":"1128314412210327555","prowjobid":"1721524d-7659-11e9-9653-7621f038c66b"}
JOB_TYPE=periodic
KUBERNETES_PORT=tcp://10.47.240.1:443
KUBERNETES_PORT_443_TCP=tcp://10.47.240.1:443
KUBERNETES_PORT_443_TCP_ADDR=10.47.240.1
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_SERVICE_HOST=10.47.240.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBETEST_IN_DOCKER=true
KUBETEST_MANUAL_DUMP=y
KUBE_AWS_INSTANCE_PREFIX=e2e-f3159dd9b8-3e8d8
KUBE_GCE_INSTANCE_PREFIX=e2e-f3159dd9b8-3e8d8
PATH=/home/prow/go/bin:/go/bin:/usr/local/go/bin:/google-cloud-sdk/bin:/workspace:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
PROW_JOB_ID=1721524d-7659-11e9-9653-7621f038c66b
PWD=/workspace
SHLVL=1
SOURCE_DATE_EPOCH=
TERM=xterm
USER=prow
WORKSPACE=/workspace
_=/workspace/scenarios/kubernetes_e2e.py
Run: ('kubetest', '--dump=/logs/artifacts', '--gcp-service-account=/etc/service-account/service-account.json', '--up', '--down', '--test', '--deployment=gke', '--provider=gke', '--cluster=e2e-f3159dd9b8-3e8d8', '--gcp-network=e2e-f3159dd9b8-3e8d8', '--check-version-skew=false', '--extract=gke-default', '--gcp-node-image=gci', '--gcp-network=default', '--gcp-project=senlu-customer-gce-staging', '--gcp-zone=us-west1-pj1', '--gke-environment=https://gce-staging-sandbox-test-container.sandbox.googleapis.com/', '--test_args=--ginkgo.focus=\\[Conformance\\] --ginkgo.skip=Alpha|\\[(Disruptive|Feature:[^\\]]+|Flaky)\\] --gce-api-endpoint=https://www.googleapis.com/compute/cm_staging_v1/', '--timeout=200m')
2019/05/14 15:01:45 main.go:321: Limiting testing to 3h20m0s
2019/05/14 15:01:45 process.go:153: Running: gcloud config set project senlu-customer-gce-staging
Updated property [core/project].
2019/05/14 15:01:45 process.go:155: Step 'gcloud config set project senlu-customer-gce-staging' finished in 430.533049ms
2019/05/14 15:01:45 process.go:153: Running: gcloud auth activate-service-account --key-file=/etc/service-account/service-account.json
Activated service account credentials for: [gob-prow@gob-prow.iam.gserviceaccount.com]
2019/05/14 15:01:46 process.go:155: Step 'gcloud auth activate-service-account --key-file=/etc/service-account/service-account.json' finished in 591.566107ms
2019/05/14 15:01:46 main.go:770: Checking existing of GCP ssh keys...
2019/05/14 15:01:46 main.go:780: Checking presence of public key in senlu-customer-gce-staging
2019/05/14 15:01:46 process.go:153: Running: gcloud compute --project=senlu-customer-gce-staging project-info describe
2019/05/14 15:01:47 process.go:155: Step 'gcloud compute --project=senlu-customer-gce-staging project-info describe' finished in 1.211202729s
2019/05/14 15:01:47 extract_k8s.go:135: rm kubernetes
2019/05/14 15:01:47 process.go:153: Running: gcloud container get-server-config --project=senlu-customer-gce-staging --zone=us-west1-pj1 --format=value(defaultClusterVersion)
Fetching server config for us-west1-pj1
2019/05/14 15:01:49 process.go:155: Step 'gcloud container get-server-config --project=senlu-customer-gce-staging --zone=us-west1-pj1 --format=value(defaultClusterVersion)' finished in 1.317248491s
2019/05/14 15:01:49 process.go:153: Running: gsutil cat gs://kubernetes-release-dev/ci/latest-1.11.txt
2019/05/14 15:01:51 process.go:155: Step 'gsutil cat gs://kubernetes-release-dev/ci/latest-1.11.txt' finished in 2.929555529s
2019/05/14 15:01:51 extract_k8s.go:287: U=https://storage.googleapis.com/kubernetes-release-dev/ci R=v1.11.11-beta.0.1+9016740a6ffe91 get-kube.sh
2019/05/14 15:01:51 process.go:153: Running: ./get-kube.sh
Downloading kubernetes release v1.11.11-beta.0.1+9016740a6ffe91
  from https://storage.googleapis.com/kubernetes-release-dev/ci/v1.11.11-beta.0.1+9016740a6ffe91/kubernetes.tar.gz
  to /workspace/kubernetes.tar.gz
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100 1732k  100 1732k    0     0  47.6M      0 --:--:-- --:--:-- --:--:-- 48.3M
Unpacking kubernetes release v1.11.11-beta.0.1+9016740a6ffe91
Kubernetes release: v1.11.11-beta.0.1+9016740a6ffe91
Server: linux/amd64  (to override, set KUBERNETES_SERVER_ARCH)
Client: linux/amd64  (autodetected)

Will download kubernetes-server-linux-amd64.tar.gz from https://storage.googleapis.com/kubernetes-release-dev/ci/v1.11.11-beta.0.1+9016740a6ffe91
Will download and extract kubernetes-client-linux-amd64.tar.gz from https://storage.googleapis.com/kubernetes-release-dev/ci/v1.11.11-beta.0.1+9016740a6ffe91
Will download and extract kubernetes-test.tar.gz from https://storage.googleapis.com/kubernetes-release-dev/ci/v1.11.11-beta.0.1+9016740a6ffe91
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0 23  416M   23 96.7M    0     0  75.0M      0  0:00:05  0:00:01  0:00:04 75.0M 52  416M   52  216M    0     0  97.9M      0  0:00:04  0:00:02  0:00:02 97.9M 92  416M   92  384M    0     0   122M      0  0:00:03  0:00:03 --:--:--  122M100  416M  100  416M    0     0   127M      0  0:00:03  0:00:03 --:--:--  127M

md5sum(kubernetes-server-linux-amd64.tar.gz)=e8968e2cfd4acc9c48e8f30c8f5877dc
sha1sum(kubernetes-server-linux-amd64.tar.gz)=8c9c0e542a0dc1fca7dfa7ff3389f919cffb39c4

  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100 13.2M  100 13.2M    0     0  30.0M      0 --:--:-- --:--:-- --:--:-- 30.0M

md5sum(kubernetes-client-linux-amd64.tar.gz)=bbe8ecf192c136d7dda44c397217fb87
sha1sum(kubernetes-client-linux-amd64.tar.gz)=ae2d0a01ed1336b74dea77b14062beeda8542081

Extracting /workspace/kubernetes/client/kubernetes-client-linux-amd64.tar.gz into /workspace/kubernetes/platforms/linux/amd64
Add '/workspace/kubernetes/client/bin' to your PATH to use newly-installed binaries.
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0 1383M    0 4904k    0     0  9490k      0  0:02:29 --:--:--  0:02:29 9485k 12 1383M   12  168M    0     0  73.9M      0  0:00:18  0:00:02  0:00:16 73.9M 14 1383M   14  203M    0     0  82.2M      0  0:00:16  0:00:02  0:00:14 82.2M 26 1383M   26  369M    0     0   106M      0  0:00:12  0:00:03  0:00:09  106M 39 1383M   39  552M    0     0   120M      0  0:00:11  0:00:04  0:00:07  120M 47 1383M   47  656M    0     0   117M      0  0:00:11  0:00:05  0:00:06  128M 56 1383M   56  784M    0     0   121M      0  0:00:11  0:00:06  0:00:05  146M 66 1383M   66  924M    0     0   123M      0  0:00:11  0:00:07  0:00:04  144M 77 1383M   77 1072M    0     0   125M      0  0:00:11  0:00:08  0:00:03  138M 87 1383M   87 1209M    0     0   127M      0  0:00:10  0:00:09  0:00:01  134M 99 1383M   99 1379M    0     0   131M      0  0:00:10  0:00:10 --:--:--  148M100 1383M  100 1383M    0     0   131M      0  0:00:10  0:00:10 --:--:--  149M

md5sum(kubernetes-test.tar.gz)=d35b65f85898b7d970795e0c9ca50980
sha1sum(kubernetes-test.tar.gz)=316b82ce0d1cd5d39e90f2f8eaf528ac99a35e4b

Extracting kubernetes-test.tar.gz into /workspace/kubernetes
2019/05/14 15:04:04 process.go:155: Step './get-kube.sh' finished in 2m12.690030424s
2019/05/14 15:04:19 process.go:153: Running: gcloud compute networks describe default --project=senlu-customer-gce-staging --format=value(name)
2019/05/14 15:04:24 process.go:155: Step 'gcloud compute networks describe default --project=senlu-customer-gce-staging --format=value(name)' finished in 5.303282217s
2019/05/14 15:04:24 process.go:153: Running: gcloud container clusters create --quiet --project=senlu-customer-gce-staging --zone=us-west1-pj1 --machine-type=n1-standard-2 --image-type=gci --num-nodes=3 --network=default e2e-f3159dd9b8-3e8d8
WARNING: Starting in 1.12, new clusters will have basic authentication disabled by default. Basic authentication can be enabled (or disabled) manually using the `--[no-]enable-basic-auth` flag.
WARNING: Starting in 1.12, new clusters will not have a client certificate issued. You can manually enable (or disable) the issuance of the client certificate using the `--[no-]issue-client-certificate` flag.
WARNING: Currently VPC-native is not the default mode during cluster creation. In the future, this will become the default mode and can be disabled using `--no-enable-ip-alias` flag. Use `--[no-]enable-ip-alias` flag to suppress this warning.
WARNING: Starting in 1.12, default node pools in new clusters will have their legacy Compute Engine instance metadata endpoints disabled by default. To create a cluster with legacy instance metadata endpoints disabled in the default node pool, run `clusters create` with the flag `--metadata disable-legacy-endpoints=true`.
This will disable the autorepair feature for nodes. Please see https://cloud.google.com/kubernetes-engine/docs/node-auto-repair for more information on node autorepairs.
WARNING: Starting in Kubernetes v1.10, new clusters will no longer get compute-rw and storage-ro scopes added to what is specified in --scopes (though the latter will remain included in the default --scopes). To use these scopes, add them explicitly to --scopes. To use the new behavior, set container/new_scopes_behavior property (gcloud config set container/new_scopes_behavior true).
Creating cluster e2e-f3159dd9b8-3e8d8 in us-west1-pj1...
.......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.
Created [https://gce-staging-sandbox-test-container.sandbox.googleapis.com/v1/projects/senlu-customer-gce-staging/zones/us-west1-pj1/clusters/e2e-f3159dd9b8-3e8d8].
To inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-west1-pj1/e2e-f3159dd9b8-3e8d8?project=senlu-customer-gce-staging
kubeconfig entry generated for e2e-f3159dd9b8-3e8d8.
NAME                  LOCATION      MASTER_VERSION  MASTER_IP       MACHINE_TYPE   NODE_VERSION  NUM_NODES  STATUS
e2e-f3159dd9b8-3e8d8  us-west1-pj1  1.11.8-gke.6    35.230.205.166  n1-standard-2  1.11.8-gke.6  3          RUNNING
2019/05/14 15:07:00 process.go:155: Step 'gcloud container clusters create --quiet --project=senlu-customer-gce-staging --zone=us-west1-pj1 --machine-type=n1-standard-2 --image-type=gci --num-nodes=3 --network=default e2e-f3159dd9b8-3e8d8' finished in 2m36.059936762s
2019/05/14 15:07:00 process.go:153: Running: ./cluster/kubectl.sh --match-server-version=false version
2019/05/14 15:07:03 process.go:155: Step './cluster/kubectl.sh --match-server-version=false version' finished in 3.512134435s
2019/05/14 15:07:03 process.go:153: Running: ./cluster/kubectl.sh --match-server-version=false get nodes -oyaml
2019/05/14 15:07:04 process.go:155: Step './cluster/kubectl.sh --match-server-version=false get nodes -oyaml' finished in 500.117599ms
2019/05/14 15:07:04 process.go:153: Running: gcloud container clusters get-credentials e2e-f3159dd9b8-3e8d8 --project=senlu-customer-gce-staging --zone=us-west1-pj1
Fetching cluster endpoint and auth data.
kubeconfig entry generated for e2e-f3159dd9b8-3e8d8.
2019/05/14 15:07:05 process.go:155: Step 'gcloud container clusters get-credentials e2e-f3159dd9b8-3e8d8 --project=senlu-customer-gce-staging --zone=us-west1-pj1' finished in 800.037193ms
2019/05/14 15:07:06 process.go:153: Running: kubectl get nodes --no-headers
2019/05/14 15:07:10 process.go:155: Step 'kubectl get nodes --no-headers' finished in 4.039774839s
2019/05/14 15:07:10 e2e.go:462: Cluster nodes:
gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk   Ready   <none>   36s   v1.11.8-gke.6
gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq   Ready   <none>   34s   v1.11.8-gke.6
gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m   Ready   <none>   37s   v1.11.8-gke.6
2019/05/14 15:07:10 process.go:153: Running: ./cluster/kubectl.sh --match-server-version=false version
2019/05/14 15:07:10 process.go:155: Step './cluster/kubectl.sh --match-server-version=false version' finished in 246.562721ms
2019/05/14 15:07:10 process.go:153: Running: ./hack/ginkgo-e2e.sh --ginkgo.focus=\[Conformance\] --ginkgo.skip=Alpha|\[(Disruptive|Feature:[^\]]+|Flaky)\] --gce-api-endpoint=https://www.googleapis.com/compute/cm_staging_v1/ --num-nodes=3 --report-dir=/logs/artifacts --disable-log-dump=true
Conformance test: not doing test setup.
May 14 15:07:11.029: INFO: Overriding default scale value of zero to 1
May 14 15:07:11.029: INFO: Overriding default milliseconds value of zero to 5000
I0514 15:07:11.178456     651 e2e.go:333] Starting e2e run "f2d248a9-7659-11e9-96ed-42d4de3e15aa" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1557846430 - Will randomize all specs
Will run 166 of 1009 specs

May 14 15:07:11.262: INFO: Fetching cloud provider for "gke"
I0514 15:07:11.262678     651 gce.go:844] Using DefaultTokenSource &oauth2.reuseTokenSource{new:jwt.jwtSource{ctx:(*context.emptyCtx)(0xc4200e6058), conf:(*jwt.Config)(0xc420985480)}, mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(nil)}
I0514 15:07:11.392068     651 gce.go:844] Using DefaultTokenSource &oauth2.reuseTokenSource{new:jwt.jwtSource{ctx:(*context.emptyCtx)(0xc4200e6058), conf:(*jwt.Config)(0xc42090c400)}, mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(nil)}
I0514 15:07:11.425326     651 gce.go:844] Using DefaultTokenSource &oauth2.reuseTokenSource{new:jwt.jwtSource{ctx:(*context.emptyCtx)(0xc4200e6058), conf:(*jwt.Config)(0xc42090c600)}, mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(nil)}
W0514 15:07:11.456065     651 gce.go:443] No network name or URL specified.
May 14 15:07:12.455: INFO: lookupDiskImageSources: gcloud error with [[]string{"instance-groups", "list-instances", "gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-grp", "--format=get(instance)"}]; err:exit status 1
May 14 15:07:12.455: INFO:  > ERROR: (gcloud.compute.instance-groups.list-instances) Some requests did not succeed:
May 14 15:07:12.455: INFO:  >  - Invalid value for field 'zone': 'us-west1-pj1'. Unknown zone.
May 14 15:07:12.455: INFO:  > 
May 14 15:07:12.455: INFO:  > 
May 14 15:07:12.455: INFO: Cluster image sources lookup failed: exit status 1

May 14 15:07:12.455: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:07:12.458: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 14 15:07:12.467: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 14 15:07:12.763: INFO: The status of Pod fluentd-gcp-v3.2.0-2d4fx is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:12.763: INFO: The status of Pod fluentd-gcp-v3.2.0-96cdk is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:12.763: INFO: The status of Pod fluentd-gcp-v3.2.0-kjzgl is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:12.763: INFO: The status of Pod kube-dns-785fdb56c-w2llr is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:12.763: INFO: The status of Pod kube-dns-785fdb56c-zq2ht is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:12.763: INFO: The status of Pod l7-default-backend-7ff48cffd7-7dcfl is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:12.763: INFO: 12 / 18 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 14 15:07:12.763: INFO: expected 8 pod replicas in namespace 'kube-system', 5 are Running and Ready.
May 14 15:07:12.763: INFO: POD                                  NODE                                                 PHASE    GRACE  CONDITIONS
May 14 15:07:12.763: INFO: fluentd-gcp-v3.2.0-2d4fx             gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC  }]
May 14 15:07:12.763: INFO: fluentd-gcp-v3.2.0-96cdk             gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC  }]
May 14 15:07:12.763: INFO: fluentd-gcp-v3.2.0-kjzgl             gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC  }]
May 14 15:07:12.763: INFO: kube-dns-785fdb56c-w2llr             gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC ContainersNotReady containers with unready status: [kubedns dnsmasq sidecar prometheus-to-sd]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [kubedns dnsmasq sidecar prometheus-to-sd]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC  }]
May 14 15:07:12.763: INFO: kube-dns-785fdb56c-zq2ht             gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:54 +0000 UTC ContainersNotReady containers with unready status: [kubedns]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [kubedns]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:54 +0000 UTC  }]
May 14 15:07:12.763: INFO: l7-default-backend-7ff48cffd7-7dcfl  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:54 +0000 UTC ContainersNotReady containers with unready status: [default-http-backend]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [default-http-backend]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:54 +0000 UTC  }]
May 14 15:07:12.763: INFO: 
May 14 15:07:14.779: INFO: The status of Pod fluentd-gcp-v3.2.0-2d4fx is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:14.779: INFO: The status of Pod fluentd-gcp-v3.2.0-96cdk is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:14.779: INFO: The status of Pod fluentd-gcp-v3.2.0-kjzgl is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:14.779: INFO: The status of Pod kube-dns-785fdb56c-w2llr is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:14.779: INFO: The status of Pod kube-dns-785fdb56c-zq2ht is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:14.779: INFO: 12 / 17 pods in namespace 'kube-system' are running and ready (2 seconds elapsed)
May 14 15:07:14.779: INFO: expected 8 pod replicas in namespace 'kube-system', 6 are Running and Ready.
May 14 15:07:14.779: INFO: POD                       NODE                                                 PHASE    GRACE  CONDITIONS
May 14 15:07:14.779: INFO: fluentd-gcp-v3.2.0-2d4fx  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC  }]
May 14 15:07:14.779: INFO: fluentd-gcp-v3.2.0-96cdk  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC  }]
May 14 15:07:14.779: INFO: fluentd-gcp-v3.2.0-kjzgl  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC  }]
May 14 15:07:14.779: INFO: kube-dns-785fdb56c-w2llr  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC ContainersNotReady containers with unready status: [kubedns dnsmasq sidecar prometheus-to-sd]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [kubedns dnsmasq sidecar prometheus-to-sd]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC  }]
May 14 15:07:14.779: INFO: kube-dns-785fdb56c-zq2ht  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:54 +0000 UTC ContainersNotReady containers with unready status: [kubedns]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [kubedns]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:54 +0000 UTC  }]
May 14 15:07:14.779: INFO: 
May 14 15:07:16.781: INFO: The status of Pod fluentd-gcp-v3.2.0-2d4fx is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:16.782: INFO: The status of Pod fluentd-gcp-v3.2.0-96cdk is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:16.782: INFO: The status of Pod kube-dns-785fdb56c-w2llr is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:16.782: INFO: 14 / 17 pods in namespace 'kube-system' are running and ready (4 seconds elapsed)
May 14 15:07:16.782: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 14 15:07:16.782: INFO: POD                       NODE                                                 PHASE    GRACE  CONDITIONS
May 14 15:07:16.782: INFO: fluentd-gcp-v3.2.0-2d4fx  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:05 +0000 UTC  }]
May 14 15:07:16.782: INFO: fluentd-gcp-v3.2.0-96cdk  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC  }]
May 14 15:07:16.782: INFO: kube-dns-785fdb56c-w2llr  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC ContainersNotReady containers with unready status: [kubedns]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [kubedns]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC  }]
May 14 15:07:16.782: INFO: 
May 14 15:07:18.780: INFO: The status of Pod fluentd-gcp-v3.2.0-96cdk is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:18.780: INFO: The status of Pod kube-dns-785fdb56c-w2llr is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:18.780: INFO: 15 / 17 pods in namespace 'kube-system' are running and ready (6 seconds elapsed)
May 14 15:07:18.780: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 14 15:07:18.780: INFO: POD                       NODE                                                 PHASE    GRACE  CONDITIONS
May 14 15:07:18.780: INFO: fluentd-gcp-v3.2.0-96cdk  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC  }]
May 14 15:07:18.780: INFO: kube-dns-785fdb56c-w2llr  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC ContainersNotReady containers with unready status: [kubedns]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [kubedns]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC  }]
May 14 15:07:18.780: INFO: 
May 14 15:07:20.778: INFO: The status of Pod fluentd-gcp-v3.2.0-96cdk is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:20.778: INFO: The status of Pod kube-dns-785fdb56c-w2llr is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 14 15:07:20.778: INFO: 15 / 17 pods in namespace 'kube-system' are running and ready (8 seconds elapsed)
May 14 15:07:20.778: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 14 15:07:20.778: INFO: POD                       NODE                                                 PHASE    GRACE  CONDITIONS
May 14 15:07:20.778: INFO: fluentd-gcp-v3.2.0-96cdk  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:07:10 +0000 UTC  }]
May 14 15:07:20.778: INFO: kube-dns-785fdb56c-w2llr  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC ContainersNotReady containers with unready status: [kubedns]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [kubedns]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:06:57 +0000 UTC  }]
May 14 15:07:20.778: INFO: 
May 14 15:07:22.777: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (10 seconds elapsed)
May 14 15:07:22.777: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
May 14 15:07:22.781: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 14 15:07:22.781: INFO: Dumping network health container logs from all nodes to file /logs/artifacts/nethealth.txt
May 14 15:07:22.785: INFO: e2e test version: v1.11.11-beta.0.1+9016740a6ffe91
May 14 15:07:22.786: INFO: kube-apiserver version: v1.11.8-gke.6
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:07:22.786: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
E0514 15:07:22.828142     651 memcache.go:147] couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request
STEP: Building a namespace api object
May 14 15:07:23.098: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 14 15:07:23.308: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"fa201550-7659-11e9-a4a8-42010a8c006e", Controller:(*bool)(0xc420f81036), BlockOwnerDeletion:(*bool)(0xc420f81037)}}
May 14 15:07:23.400: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"fa1d8884-7659-11e9-a4a8-42010a8c006e", Controller:(*bool)(0xc420ff8426), BlockOwnerDeletion:(*bool)(0xc420ff8427)}}
May 14 15:07:23.490: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"fa1e9c46-7659-11e9-a4a8-42010a8c006e", Controller:(*bool)(0xc420ff8616), BlockOwnerDeletion:(*bool)(0xc420ff8617)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:07:28.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-c76mc" for this suite.
May 14 15:07:40.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:07:42.817: INFO: namespace: e2e-tests-gc-c76mc, resource: bindings, ignored listing per whitelist
May 14 15:07:44.020: INFO: namespace e2e-tests-gc-c76mc deletion completed in 15.340214178s

• [SLOW TEST:21.234 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:07:44.020: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 14 15:07:44.638: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-8btm8,SelfLink:/api/v1/namespaces/e2e-tests-watch-8btm8/configmaps/e2e-watch-test-resource-version,UID:06ab5c0b-765a-11e9-a4a8-42010a8c006e,ResourceVersion:895,Generation:0,CreationTimestamp:2019-05-14 15:07:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 14 15:07:44.638: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-8btm8,SelfLink:/api/v1/namespaces/e2e-tests-watch-8btm8/configmaps/e2e-watch-test-resource-version,UID:06ab5c0b-765a-11e9-a4a8-42010a8c006e,ResourceVersion:896,Generation:0,CreationTimestamp:2019-05-14 15:07:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:07:44.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-8btm8" for this suite.
May 14 15:07:50.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:07:52.856: INFO: namespace: e2e-tests-watch-8btm8, resource: bindings, ignored listing per whitelist
May 14 15:07:54.020: INFO: namespace e2e-tests-watch-8btm8 deletion completed in 9.378986923s

• [SLOW TEST:10.001 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:07:54.021: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:07:54.358: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0c9d4e46-765a-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-wzhwh" to be "success or failure"
May 14 15:07:54.457: INFO: Pod "downwardapi-volume-0c9d4e46-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 98.770995ms
May 14 15:07:56.520: INFO: Pod "downwardapi-volume-0c9d4e46-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.161972498s
May 14 15:07:58.523: INFO: Pod "downwardapi-volume-0c9d4e46-765a-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.165438201s
STEP: Saw pod success
May 14 15:07:58.523: INFO: Pod "downwardapi-volume-0c9d4e46-765a-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:07:58.525: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-0c9d4e46-765a-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:07:58.732: INFO: Waiting for pod downwardapi-volume-0c9d4e46-765a-11e9-96ed-42d4de3e15aa to disappear
May 14 15:07:58.831: INFO: Pod downwardapi-volume-0c9d4e46-765a-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:07:58.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wzhwh" for this suite.
May 14 15:08:05.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:08:05.332: INFO: namespace: e2e-tests-downward-api-wzhwh, resource: bindings, ignored listing per whitelist
May 14 15:08:08.986: INFO: namespace e2e-tests-downward-api-wzhwh deletion completed in 10.150854142s

• [SLOW TEST:14.966 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:08:08.986: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-1581bb98-765a-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 15:08:09.336: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-158f80fe-765a-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-4dnlp" to be "success or failure"
May 14 15:08:09.426: INFO: Pod "pod-projected-configmaps-158f80fe-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 90.149138ms
May 14 15:08:11.430: INFO: Pod "pod-projected-configmaps-158f80fe-765a-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.093708225s
STEP: Saw pod success
May 14 15:08:11.430: INFO: Pod "pod-projected-configmaps-158f80fe-765a-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:08:11.432: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-configmaps-158f80fe-765a-11e9-96ed-42d4de3e15aa container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 15:08:11.637: INFO: Waiting for pod pod-projected-configmaps-158f80fe-765a-11e9-96ed-42d4de3e15aa to disappear
May 14 15:08:11.722: INFO: Pod pod-projected-configmaps-158f80fe-765a-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:08:11.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4dnlp" for this suite.
May 14 15:08:17.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:08:19.384: INFO: namespace: e2e-tests-projected-4dnlp, resource: bindings, ignored listing per whitelist
May 14 15:08:21.073: INFO: namespace e2e-tests-projected-4dnlp deletion completed in 9.348176066s

• [SLOW TEST:12.087 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:08:21.073: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-1cb87f77-765a-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 15:08:21.434: INFO: Waiting up to 5m0s for pod "pod-secrets-1cc671d3-765a-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-secrets-x9xmz" to be "success or failure"
May 14 15:08:21.548: INFO: Pod "pod-secrets-1cc671d3-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 113.025016ms
May 14 15:08:23.551: INFO: Pod "pod-secrets-1cc671d3-765a-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.116754376s
STEP: Saw pod success
May 14 15:08:23.551: INFO: Pod "pod-secrets-1cc671d3-765a-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:08:23.554: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-secrets-1cc671d3-765a-11e9-96ed-42d4de3e15aa container secret-volume-test: <nil>
STEP: delete the pod
May 14 15:08:23.742: INFO: Waiting for pod pod-secrets-1cc671d3-765a-11e9-96ed-42d4de3e15aa to disappear
May 14 15:08:23.834: INFO: Pod pod-secrets-1cc671d3-765a-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:08:23.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x9xmz" for this suite.
May 14 15:08:30.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:08:33.039: INFO: namespace: e2e-tests-secrets-x9xmz, resource: bindings, ignored listing per whitelist
May 14 15:08:33.039: INFO: namespace e2e-tests-secrets-x9xmz deletion completed in 9.201286529s

• [SLOW TEST:11.966 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:08:33.039: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should create and stop a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a replication controller
May 14 15:08:33.173: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-7vq7s'
May 14 15:08:33.603: INFO: stderr: ""
May 14 15:08:33.603: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 14 15:08:33.603: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7vq7s'
May 14 15:08:33.801: INFO: stderr: ""
May 14 15:08:33.801: INFO: stdout: "update-demo-nautilus-dcm4g update-demo-nautilus-zbj8p "
May 14 15:08:33.801: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-dcm4g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7vq7s'
May 14 15:08:34.041: INFO: stderr: ""
May 14 15:08:34.041: INFO: stdout: ""
May 14 15:08:34.041: INFO: update-demo-nautilus-dcm4g is created but not running
May 14 15:08:39.042: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7vq7s'
May 14 15:08:39.162: INFO: stderr: ""
May 14 15:08:39.162: INFO: stdout: "update-demo-nautilus-dcm4g update-demo-nautilus-zbj8p "
May 14 15:08:39.162: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-dcm4g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7vq7s'
May 14 15:08:39.289: INFO: stderr: ""
May 14 15:08:39.289: INFO: stdout: "true"
May 14 15:08:39.289: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-dcm4g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7vq7s'
May 14 15:08:39.423: INFO: stderr: ""
May 14 15:08:39.423: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 14 15:08:39.424: INFO: validating pod update-demo-nautilus-dcm4g
May 14 15:08:39.544: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 15:08:39.544: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 15:08:39.544: INFO: update-demo-nautilus-dcm4g is verified up and running
May 14 15:08:39.544: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-zbj8p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7vq7s'
May 14 15:08:39.759: INFO: stderr: ""
May 14 15:08:39.759: INFO: stdout: "true"
May 14 15:08:39.759: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-zbj8p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7vq7s'
May 14 15:08:39.923: INFO: stderr: ""
May 14 15:08:39.923: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 14 15:08:39.923: INFO: validating pod update-demo-nautilus-zbj8p
May 14 15:08:40.018: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 15:08:40.018: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 15:08:40.018: INFO: update-demo-nautilus-zbj8p is verified up and running
STEP: using delete to clean up resources
May 14 15:08:40.018: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7vq7s'
May 14 15:08:40.335: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 15:08:40.335: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 14 15:08:40.335: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-7vq7s'
May 14 15:08:40.637: INFO: stderr: "No resources found.\n"
May 14 15:08:40.637: INFO: stdout: ""
May 14 15:08:40.637: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -l name=update-demo --namespace=e2e-tests-kubectl-7vq7s -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 14 15:08:40.763: INFO: stderr: ""
May 14 15:08:40.763: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:08:40.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7vq7s" for this suite.
May 14 15:08:46.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:08:48.977: INFO: namespace: e2e-tests-kubectl-7vq7s, resource: bindings, ignored listing per whitelist
May 14 15:08:49.881: INFO: namespace e2e-tests-kubectl-7vq7s deletion completed in 9.115189266s

• [SLOW TEST:16.842 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create and stop a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:08:49.882: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 14 15:08:50.144: INFO: Waiting up to 5m0s for pod "pod-2de1c6fa-765a-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-mk8rk" to be "success or failure"
May 14 15:08:50.234: INFO: Pod "pod-2de1c6fa-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 90.373589ms
May 14 15:08:52.238: INFO: Pod "pod-2de1c6fa-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.093969615s
May 14 15:08:54.241: INFO: Pod "pod-2de1c6fa-765a-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.097023101s
STEP: Saw pod success
May 14 15:08:54.241: INFO: Pod "pod-2de1c6fa-765a-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:08:54.243: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-2de1c6fa-765a-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:08:54.445: INFO: Waiting for pod pod-2de1c6fa-765a-11e9-96ed-42d4de3e15aa to disappear
May 14 15:08:54.531: INFO: Pod pod-2de1c6fa-765a-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:08:54.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mk8rk" for this suite.
May 14 15:09:00.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:09:02.145: INFO: namespace: e2e-tests-emptydir-mk8rk, resource: bindings, ignored listing per whitelist
May 14 15:09:03.838: INFO: namespace e2e-tests-emptydir-mk8rk deletion completed in 9.303908863s

• [SLOW TEST:13.956 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:09:03.838: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override command
May 14 15:09:04.077: INFO: Waiting up to 5m0s for pod "client-containers-363148c2-765a-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-containers-r5jqs" to be "success or failure"
May 14 15:09:04.174: INFO: Pod "client-containers-363148c2-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 96.578359ms
May 14 15:09:06.333: INFO: Pod "client-containers-363148c2-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.255920781s
May 14 15:09:08.337: INFO: Pod "client-containers-363148c2-765a-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.259236963s
STEP: Saw pod success
May 14 15:09:08.337: INFO: Pod "client-containers-363148c2-765a-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:09:08.339: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod client-containers-363148c2-765a-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:09:08.539: INFO: Waiting for pod client-containers-363148c2-765a-11e9-96ed-42d4de3e15aa to disappear
May 14 15:09:08.628: INFO: Pod client-containers-363148c2-765a-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:09:08.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-r5jqs" for this suite.
May 14 15:09:14.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:09:15.128: INFO: namespace: e2e-tests-containers-r5jqs, resource: bindings, ignored listing per whitelist
May 14 15:09:18.134: INFO: namespace e2e-tests-containers-r5jqs deletion completed in 9.3526251s

• [SLOW TEST:14.296 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:09:18.134: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1316
[It] should create a deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 14 15:09:18.385: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-c8x96'
May 14 15:09:18.604: INFO: stderr: ""
May 14 15:09:18.604: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1321
May 14 15:09:20.787: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-c8x96'
May 14 15:09:21.112: INFO: stderr: ""
May 14 15:09:21.112: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:09:21.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c8x96" for this suite.
May 14 15:09:27.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:09:27.428: INFO: namespace: e2e-tests-kubectl-c8x96, resource: bindings, ignored listing per whitelist
May 14 15:09:30.710: INFO: namespace e2e-tests-kubectl-c8x96 deletion completed in 9.594321232s

• [SLOW TEST:12.576 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a deployment from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:09:30.711: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-vb29k
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 14 15:09:30.870: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 14 15:09:57.544: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.40.0.10 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-vb29k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:09:57.544: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:09:58.702: INFO: Found all expected endpoints: [netserver-0]
May 14 15:09:58.705: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.40.1.18 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-vb29k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:09:58.705: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:09:59.780: INFO: Found all expected endpoints: [netserver-1]
May 14 15:09:59.784: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.40.2.6 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-vb29k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:09:59.784: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:10:00.844: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:10:00.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-vb29k" for this suite.
May 14 15:10:23.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:10:25.060: INFO: namespace: e2e-tests-pod-network-test-vb29k, resource: bindings, ignored listing per whitelist
May 14 15:10:26.270: INFO: namespace e2e-tests-pod-network-test-vb29k deletion completed in 25.421520945s

• [SLOW TEST:55.559 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:10:26.270: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-jvrkn
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StaefulSet
May 14 15:10:26.693: INFO: Found 1 stateful pods, waiting for 3
May 14 15:10:36.983: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 14 15:10:36.983: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 14 15:10:36.983: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
May 14 15:10:46.698: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 14 15:10:46.698: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 14 15:10:46.698: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
May 14 15:10:46.901: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 14 15:10:56.944: INFO: Updating stateful set ss2
May 14 15:10:56.952: INFO: Waiting for Pod e2e-tests-statefulset-jvrkn/ss2-2 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Restoring Pods to the correct revision when they are deleted
May 14 15:11:08.297: INFO: Found 2 stateful pods, waiting for 3
May 14 15:11:18.301: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 14 15:11:18.301: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 14 15:11:18.301: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 14 15:11:18.406: INFO: Updating stateful set ss2
May 14 15:11:18.416: INFO: Waiting for Pod e2e-tests-statefulset-jvrkn/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
May 14 15:11:28.445: INFO: Updating stateful set ss2
May 14 15:11:28.453: INFO: Waiting for StatefulSet e2e-tests-statefulset-jvrkn/ss2 to complete update
May 14 15:11:28.453: INFO: Waiting for Pod e2e-tests-statefulset-jvrkn/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
May 14 15:11:38.460: INFO: Waiting for StatefulSet e2e-tests-statefulset-jvrkn/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 14 15:11:48.461: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jvrkn
May 14 15:11:48.566: INFO: Scaling statefulset ss2 to 0
May 14 15:12:18.600: INFO: Waiting for statefulset status.replicas updated to 0
May 14 15:12:18.602: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:12:18.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jvrkn" for this suite.
May 14 15:12:25.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:12:26.821: INFO: namespace: e2e-tests-statefulset-jvrkn, resource: bindings, ignored listing per whitelist
May 14 15:12:28.664: INFO: namespace e2e-tests-statefulset-jvrkn deletion completed in 9.675445694s

• [SLOW TEST:122.394 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:12:28.664: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:12:29.002: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b055caa3-765a-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-skpzh" to be "success or failure"
May 14 15:12:29.102: INFO: Pod "downwardapi-volume-b055caa3-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 100.042864ms
May 14 15:12:31.105: INFO: Pod "downwardapi-volume-b055caa3-765a-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.10303564s
STEP: Saw pod success
May 14 15:12:31.105: INFO: Pod "downwardapi-volume-b055caa3-765a-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:12:31.107: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-b055caa3-765a-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:12:31.319: INFO: Waiting for pod downwardapi-volume-b055caa3-765a-11e9-96ed-42d4de3e15aa to disappear
May 14 15:12:31.425: INFO: Pod downwardapi-volume-b055caa3-765a-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:12:31.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-skpzh" for this suite.
May 14 15:12:37.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:12:39.171: INFO: namespace: e2e-tests-downward-api-skpzh, resource: bindings, ignored listing per whitelist
May 14 15:12:40.940: INFO: namespace e2e-tests-downward-api-skpzh deletion completed in 9.511233543s

• [SLOW TEST:12.276 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:12:40.941: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should scale a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a replication controller
May 14 15:12:41.130: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:41.697: INFO: stderr: ""
May 14 15:12:41.697: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 14 15:12:41.697: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:41.938: INFO: stderr: ""
May 14 15:12:41.938: INFO: stdout: "update-demo-nautilus-pv9n6 update-demo-nautilus-vjzql "
May 14 15:12:41.938: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-pv9n6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:42.149: INFO: stderr: ""
May 14 15:12:42.149: INFO: stdout: ""
May 14 15:12:42.149: INFO: update-demo-nautilus-pv9n6 is created but not running
May 14 15:12:47.149: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:47.266: INFO: stderr: ""
May 14 15:12:47.266: INFO: stdout: "update-demo-nautilus-pv9n6 update-demo-nautilus-vjzql "
May 14 15:12:47.266: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-pv9n6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:47.378: INFO: stderr: ""
May 14 15:12:47.378: INFO: stdout: "true"
May 14 15:12:47.378: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-pv9n6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:47.522: INFO: stderr: ""
May 14 15:12:47.522: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 14 15:12:47.522: INFO: validating pod update-demo-nautilus-pv9n6
May 14 15:12:47.626: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 15:12:47.626: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 15:12:47.626: INFO: update-demo-nautilus-pv9n6 is verified up and running
May 14 15:12:47.626: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-vjzql -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:47.841: INFO: stderr: ""
May 14 15:12:47.841: INFO: stdout: "true"
May 14 15:12:47.841: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-vjzql -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:47.944: INFO: stderr: ""
May 14 15:12:47.944: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 14 15:12:47.944: INFO: validating pod update-demo-nautilus-vjzql
May 14 15:12:48.034: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 15:12:48.034: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 15:12:48.034: INFO: update-demo-nautilus-vjzql is verified up and running
STEP: scaling down the replication controller
May 14 15:12:48.034: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:49.449: INFO: stderr: ""
May 14 15:12:49.449: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 14 15:12:49.449: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:49.576: INFO: stderr: ""
May 14 15:12:49.577: INFO: stdout: "update-demo-nautilus-pv9n6 update-demo-nautilus-vjzql "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 14 15:12:54.577: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:54.697: INFO: stderr: ""
May 14 15:12:54.697: INFO: stdout: "update-demo-nautilus-vjzql "
May 14 15:12:54.697: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-vjzql -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:54.796: INFO: stderr: ""
May 14 15:12:54.796: INFO: stdout: "true"
May 14 15:12:54.796: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-vjzql -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:54.902: INFO: stderr: ""
May 14 15:12:54.902: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 14 15:12:54.902: INFO: validating pod update-demo-nautilus-vjzql
May 14 15:12:54.907: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 15:12:54.907: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 15:12:54.907: INFO: update-demo-nautilus-vjzql is verified up and running
STEP: scaling up the replication controller
May 14 15:12:54.907: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:56.047: INFO: stderr: ""
May 14 15:12:56.047: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 14 15:12:56.047: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:56.301: INFO: stderr: ""
May 14 15:12:56.301: INFO: stdout: "update-demo-nautilus-bgmsj update-demo-nautilus-vjzql "
May 14 15:12:56.301: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-bgmsj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:12:56.527: INFO: stderr: ""
May 14 15:12:56.528: INFO: stdout: ""
May 14 15:12:56.528: INFO: update-demo-nautilus-bgmsj is created but not running
May 14 15:13:01.531: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:13:01.677: INFO: stderr: ""
May 14 15:13:01.677: INFO: stdout: "update-demo-nautilus-bgmsj update-demo-nautilus-vjzql "
May 14 15:13:01.677: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-bgmsj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:13:01.791: INFO: stderr: ""
May 14 15:13:01.791: INFO: stdout: "true"
May 14 15:13:01.791: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-bgmsj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:13:01.900: INFO: stderr: ""
May 14 15:13:01.900: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 14 15:13:01.900: INFO: validating pod update-demo-nautilus-bgmsj
May 14 15:13:01.996: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 15:13:01.996: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 15:13:01.996: INFO: update-demo-nautilus-bgmsj is verified up and running
May 14 15:13:01.996: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-vjzql -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:13:02.104: INFO: stderr: ""
May 14 15:13:02.104: INFO: stdout: "true"
May 14 15:13:02.104: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-vjzql -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:13:02.238: INFO: stderr: ""
May 14 15:13:02.238: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 14 15:13:02.238: INFO: validating pod update-demo-nautilus-vjzql
May 14 15:13:02.244: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 15:13:02.244: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 15:13:02.244: INFO: update-demo-nautilus-vjzql is verified up and running
STEP: using delete to clean up resources
May 14 15:13:02.245: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:13:02.535: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 15:13:02.535: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 14 15:13:02.535: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-6fnjw'
May 14 15:13:02.882: INFO: stderr: "No resources found.\n"
May 14 15:13:02.882: INFO: stdout: ""
May 14 15:13:02.882: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -l name=update-demo --namespace=e2e-tests-kubectl-6fnjw -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 14 15:13:03.000: INFO: stderr: ""
May 14 15:13:03.000: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:13:03.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6fnjw" for this suite.
May 14 15:13:25.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:13:26.416: INFO: namespace: e2e-tests-kubectl-6fnjw, resource: bindings, ignored listing per whitelist
May 14 15:13:28.398: INFO: namespace e2e-tests-kubectl-6fnjw deletion completed in 25.394144799s

• [SLOW TEST:47.457 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should scale a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:13:28.398: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 14 15:13:28.741: INFO: Waiting up to 5m0s for pod "pod-d3ef81fe-765a-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-j8gfn" to be "success or failure"
May 14 15:13:28.837: INFO: Pod "pod-d3ef81fe-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 95.48715ms
May 14 15:13:30.840: INFO: Pod "pod-d3ef81fe-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.098780163s
May 14 15:13:32.843: INFO: Pod "pod-d3ef81fe-765a-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.102121048s
STEP: Saw pod success
May 14 15:13:32.843: INFO: Pod "pod-d3ef81fe-765a-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:13:32.846: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-d3ef81fe-765a-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:13:33.037: INFO: Waiting for pod pod-d3ef81fe-765a-11e9-96ed-42d4de3e15aa to disappear
May 14 15:13:33.123: INFO: Pod pod-d3ef81fe-765a-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:13:33.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j8gfn" for this suite.
May 14 15:13:39.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:13:40.971: INFO: namespace: e2e-tests-emptydir-j8gfn, resource: bindings, ignored listing per whitelist
May 14 15:13:42.444: INFO: namespace e2e-tests-emptydir-j8gfn deletion completed in 9.233494935s

• [SLOW TEST:14.046 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:13:42.444: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
May 14 15:13:42.734: INFO: Waiting up to 5m0s for pod "pod-dc446a12-765a-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-d7mmz" to be "success or failure"
May 14 15:13:42.827: INFO: Pod "pod-dc446a12-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 92.860085ms
May 14 15:13:44.830: INFO: Pod "pod-dc446a12-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095609259s
May 14 15:13:46.834: INFO: Pod "pod-dc446a12-765a-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.100045316s
STEP: Saw pod success
May 14 15:13:46.834: INFO: Pod "pod-dc446a12-765a-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:13:46.837: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-dc446a12-765a-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:13:47.034: INFO: Waiting for pod pod-dc446a12-765a-11e9-96ed-42d4de3e15aa to disappear
May 14 15:13:47.121: INFO: Pod pod-dc446a12-765a-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:13:47.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-d7mmz" for this suite.
May 14 15:13:53.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:13:53.909: INFO: namespace: e2e-tests-emptydir-d7mmz, resource: bindings, ignored listing per whitelist
May 14 15:13:56.312: INFO: namespace e2e-tests-emptydir-d7mmz deletion completed in 9.187974707s

• [SLOW TEST:13.869 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:13:56.313: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating replication controller my-hostname-basic-e493fbb3-765a-11e9-96ed-42d4de3e15aa
May 14 15:13:56.771: INFO: Pod name my-hostname-basic-e493fbb3-765a-11e9-96ed-42d4de3e15aa: Found 1 pods out of 1
May 14 15:13:56.771: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e493fbb3-765a-11e9-96ed-42d4de3e15aa" are running
May 14 15:14:00.865: INFO: Pod "my-hostname-basic-e493fbb3-765a-11e9-96ed-42d4de3e15aa-94wkm" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 15:13:56 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 15:13:56 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-e493fbb3-765a-11e9-96ed-42d4de3e15aa]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-e493fbb3-765a-11e9-96ed-42d4de3e15aa]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 15:13:56 +0000 UTC Reason: Message:}])
May 14 15:14:00.866: INFO: Trying to dial the pod
May 14 15:14:05.988: INFO: Controller my-hostname-basic-e493fbb3-765a-11e9-96ed-42d4de3e15aa: Got expected result from replica 1 [my-hostname-basic-e493fbb3-765a-11e9-96ed-42d4de3e15aa-94wkm]: "my-hostname-basic-e493fbb3-765a-11e9-96ed-42d4de3e15aa-94wkm", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:14:05.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-d79gp" for this suite.
May 14 15:14:12.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:14:12.968: INFO: namespace: e2e-tests-replication-controller-d79gp, resource: bindings, ignored listing per whitelist
May 14 15:14:15.367: INFO: namespace e2e-tests-replication-controller-d79gp deletion completed in 9.371330826s

• [SLOW TEST:19.054 seconds]
[sig-apps] ReplicationController
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:14:15.367: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-efdfd0e6-765a-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 15:14:15.714: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-efeda43d-765a-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-gj8ck" to be "success or failure"
May 14 15:14:15.805: INFO: Pod "pod-projected-configmaps-efeda43d-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 91.177118ms
May 14 15:14:17.808: INFO: Pod "pod-projected-configmaps-efeda43d-765a-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.094448637s
STEP: Saw pod success
May 14 15:14:17.808: INFO: Pod "pod-projected-configmaps-efeda43d-765a-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:14:17.811: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-configmaps-efeda43d-765a-11e9-96ed-42d4de3e15aa container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 15:14:18.031: INFO: Waiting for pod pod-projected-configmaps-efeda43d-765a-11e9-96ed-42d4de3e15aa to disappear
May 14 15:14:18.120: INFO: Pod pod-projected-configmaps-efeda43d-765a-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:14:18.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gj8ck" for this suite.
May 14 15:14:24.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:14:25.806: INFO: namespace: e2e-tests-projected-gj8ck, resource: bindings, ignored listing per whitelist
May 14 15:14:27.370: INFO: namespace e2e-tests-projected-gj8ck deletion completed in 9.246815236s

• [SLOW TEST:12.004 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:14:27.371: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 14 15:14:27.635: INFO: (0) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 95.742958ms)
May 14 15:14:27.642: INFO: (1) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.205386ms)
May 14 15:14:27.646: INFO: (2) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.884493ms)
May 14 15:14:27.651: INFO: (3) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.998141ms)
May 14 15:14:27.655: INFO: (4) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.895383ms)
May 14 15:14:27.659: INFO: (5) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.76708ms)
May 14 15:14:27.663: INFO: (6) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.041026ms)
May 14 15:14:27.667: INFO: (7) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.011824ms)
May 14 15:14:27.672: INFO: (8) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.149856ms)
May 14 15:14:27.680: INFO: (9) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.177453ms)
May 14 15:14:27.688: INFO: (10) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.337893ms)
May 14 15:14:27.697: INFO: (11) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.806938ms)
May 14 15:14:27.707: INFO: (12) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 10.171597ms)
May 14 15:14:27.714: INFO: (13) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.987074ms)
May 14 15:14:27.726: INFO: (14) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 12.371454ms)
May 14 15:14:27.739: INFO: (15) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 12.182096ms)
May 14 15:14:27.745: INFO: (16) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.785585ms)
May 14 15:14:27.752: INFO: (17) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.113716ms)
May 14 15:14:27.755: INFO: (18) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.710477ms)
May 14 15:14:27.760: INFO: (19) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.339956ms)
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:14:27.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-476bn" for this suite.
May 14 15:14:33.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:14:34.087: INFO: namespace: e2e-tests-proxy-476bn, resource: bindings, ignored listing per whitelist
May 14 15:14:37.026: INFO: namespace e2e-tests-proxy-476bn deletion completed in 9.263713608s

• [SLOW TEST:9.656 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:14:37.026: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:14:37.283: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fccbf8f8-765a-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-dc8qt" to be "success or failure"
May 14 15:14:37.371: INFO: Pod "downwardapi-volume-fccbf8f8-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 88.631154ms
May 14 15:14:39.375: INFO: Pod "downwardapi-volume-fccbf8f8-765a-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092216348s
May 14 15:14:41.379: INFO: Pod "downwardapi-volume-fccbf8f8-765a-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.095827999s
STEP: Saw pod success
May 14 15:14:41.379: INFO: Pod "downwardapi-volume-fccbf8f8-765a-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:14:41.381: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-fccbf8f8-765a-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:14:41.644: INFO: Waiting for pod downwardapi-volume-fccbf8f8-765a-11e9-96ed-42d4de3e15aa to disappear
May 14 15:14:41.734: INFO: Pod downwardapi-volume-fccbf8f8-765a-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:14:41.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dc8qt" for this suite.
May 14 15:14:47.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:14:49.392: INFO: namespace: e2e-tests-projected-dc8qt, resource: bindings, ignored listing per whitelist
May 14 15:14:51.241: INFO: namespace e2e-tests-projected-dc8qt deletion completed in 9.504178407s

• [SLOW TEST:14.214 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:14:51.241: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ftjmg
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 14 15:14:51.384: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 14 15:15:16.534: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.40.1.34:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ftjmg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:15:16.534: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:15:16.693: INFO: Found all expected endpoints: [netserver-0]
May 14 15:15:16.696: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.40.2.10:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ftjmg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:15:16.696: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:15:16.764: INFO: Found all expected endpoints: [netserver-1]
May 14 15:15:16.767: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.40.0.14:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ftjmg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:15:16.767: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:15:16.840: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:15:16.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ftjmg" for this suite.
May 14 15:15:39.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:15:39.739: INFO: namespace: e2e-tests-pod-network-test-ftjmg, resource: bindings, ignored listing per whitelist
May 14 15:15:42.231: INFO: namespace e2e-tests-pod-network-test-ftjmg deletion completed in 25.300708512s

• [SLOW TEST:50.990 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:15:42.231: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override arguments
May 14 15:15:42.614: INFO: Waiting up to 5m0s for pod "client-containers-23bac165-765b-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-containers-jnsjt" to be "success or failure"
May 14 15:15:42.707: INFO: Pod "client-containers-23bac165-765b-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 92.912049ms
May 14 15:15:44.710: INFO: Pod "client-containers-23bac165-765b-11e9-96ed-42d4de3e15aa": Phase="Running", Reason="", readiness=true. Elapsed: 2.096118146s
May 14 15:15:46.713: INFO: Pod "client-containers-23bac165-765b-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.099115048s
STEP: Saw pod success
May 14 15:15:46.713: INFO: Pod "client-containers-23bac165-765b-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:15:46.715: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod client-containers-23bac165-765b-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:15:46.912: INFO: Waiting for pod client-containers-23bac165-765b-11e9-96ed-42d4de3e15aa to disappear
May 14 15:15:47.006: INFO: Pod client-containers-23bac165-765b-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:15:47.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-jnsjt" for this suite.
May 14 15:15:53.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:15:53.744: INFO: namespace: e2e-tests-containers-jnsjt, resource: bindings, ignored listing per whitelist
May 14 15:15:56.224: INFO: namespace e2e-tests-containers-jnsjt deletion completed in 9.214962739s

• [SLOW TEST:13.993 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:15:56.224: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 14 15:15:56.524: INFO: Waiting up to 5m0s for pod "pod-2c071f41-765b-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-n2znn" to be "success or failure"
May 14 15:15:56.661: INFO: Pod "pod-2c071f41-765b-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 137.313318ms
May 14 15:15:58.668: INFO: Pod "pod-2c071f41-765b-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.144680807s
STEP: Saw pod success
May 14 15:15:58.668: INFO: Pod "pod-2c071f41-765b-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:15:58.671: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-2c071f41-765b-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:15:58.865: INFO: Waiting for pod pod-2c071f41-765b-11e9-96ed-42d4de3e15aa to disappear
May 14 15:15:58.956: INFO: Pod pod-2c071f41-765b-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:15:58.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n2znn" for this suite.
May 14 15:16:05.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:16:09.036: INFO: namespace: e2e-tests-emptydir-n2znn, resource: bindings, ignored listing per whitelist
May 14 15:16:10.404: INFO: namespace e2e-tests-emptydir-n2znn deletion completed in 11.444446853s

• [SLOW TEST:14.180 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:16:10.404: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-34745831-765b-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 15:16:10.759: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3481eb90-765b-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-92q7m" to be "success or failure"
May 14 15:16:10.849: INFO: Pod "pod-projected-secrets-3481eb90-765b-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 89.785518ms
May 14 15:16:12.853: INFO: Pod "pod-projected-secrets-3481eb90-765b-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.093352412s
May 14 15:16:14.856: INFO: Pod "pod-projected-secrets-3481eb90-765b-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.097047573s
STEP: Saw pod success
May 14 15:16:14.856: INFO: Pod "pod-projected-secrets-3481eb90-765b-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:16:14.858: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-secrets-3481eb90-765b-11e9-96ed-42d4de3e15aa container projected-secret-volume-test: <nil>
STEP: delete the pod
May 14 15:16:15.071: INFO: Waiting for pod pod-projected-secrets-3481eb90-765b-11e9-96ed-42d4de3e15aa to disappear
May 14 15:16:15.179: INFO: Pod pod-projected-secrets-3481eb90-765b-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:16:15.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-92q7m" for this suite.
May 14 15:16:21.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:16:24.159: INFO: namespace: e2e-tests-projected-92q7m, resource: bindings, ignored listing per whitelist
May 14 15:16:24.406: INFO: namespace e2e-tests-projected-92q7m deletion completed in 9.222410433s

• [SLOW TEST:14.002 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:16:24.406: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-upd-3cccb679-765b-11e9-96ed-42d4de3e15aa
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-3cccb679-765b-11e9-96ed-42d4de3e15aa
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:16:31.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-glqr6" for this suite.
May 14 15:16:53.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:16:55.514: INFO: namespace: e2e-tests-configmap-glqr6, resource: bindings, ignored listing per whitelist
May 14 15:16:56.406: INFO: namespace e2e-tests-configmap-glqr6 deletion completed in 25.28141943s

• [SLOW TEST:32.000 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:16:56.407: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:16:56.766: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4fee060a-765b-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-8pprl" to be "success or failure"
May 14 15:16:56.855: INFO: Pod "downwardapi-volume-4fee060a-765b-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 89.108141ms
May 14 15:16:58.859: INFO: Pod "downwardapi-volume-4fee060a-765b-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.09293013s
STEP: Saw pod success
May 14 15:16:58.859: INFO: Pod "downwardapi-volume-4fee060a-765b-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:16:58.862: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-4fee060a-765b-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:16:59.059: INFO: Waiting for pod downwardapi-volume-4fee060a-765b-11e9-96ed-42d4de3e15aa to disappear
May 14 15:16:59.149: INFO: Pod downwardapi-volume-4fee060a-765b-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:16:59.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8pprl" for this suite.
May 14 15:17:05.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:17:08.010: INFO: namespace: e2e-tests-projected-8pprl, resource: bindings, ignored listing per whitelist
May 14 15:17:08.433: INFO: namespace e2e-tests-projected-8pprl deletion completed in 9.280631469s

• [SLOW TEST:12.026 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:17:08.433: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-57097ec4-765b-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 15:17:08.774: INFO: Waiting up to 5m0s for pod "pod-secrets-57166913-765b-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-secrets-n6xpm" to be "success or failure"
May 14 15:17:08.889: INFO: Pod "pod-secrets-57166913-765b-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 114.410976ms
May 14 15:17:10.891: INFO: Pod "pod-secrets-57166913-765b-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.117199772s
STEP: Saw pod success
May 14 15:17:10.892: INFO: Pod "pod-secrets-57166913-765b-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:17:10.893: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-secrets-57166913-765b-11e9-96ed-42d4de3e15aa container secret-volume-test: <nil>
STEP: delete the pod
May 14 15:17:11.098: INFO: Waiting for pod pod-secrets-57166913-765b-11e9-96ed-42d4de3e15aa to disappear
May 14 15:17:11.194: INFO: Pod pod-secrets-57166913-765b-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:17:11.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-n6xpm" for this suite.
May 14 15:17:17.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:17:19.375: INFO: namespace: e2e-tests-secrets-n6xpm, resource: bindings, ignored listing per whitelist
May 14 15:17:20.374: INFO: namespace e2e-tests-secrets-n6xpm deletion completed in 9.173643427s

• [SLOW TEST:11.941 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:17:20.374: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
May 14 15:17:25.581: INFO: Successfully updated pod "labelsupdate5e26775f-765b-11e9-96ed-42d4de3e15aa"
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:17:27.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tkqg6" for this suite.
May 14 15:17:49.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:17:51.915: INFO: namespace: e2e-tests-projected-tkqg6, resource: bindings, ignored listing per whitelist
May 14 15:17:53.177: INFO: namespace e2e-tests-projected-tkqg6 deletion completed in 25.48780298s

• [SLOW TEST:32.803 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:17:53.178: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-71c3b17f-765b-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 15:17:53.617: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-71d2037c-765b-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-tt4d7" to be "success or failure"
May 14 15:17:53.718: INFO: Pod "pod-projected-secrets-71d2037c-765b-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 101.195151ms
May 14 15:17:55.722: INFO: Pod "pod-projected-secrets-71d2037c-765b-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.104850316s
STEP: Saw pod success
May 14 15:17:55.722: INFO: Pod "pod-projected-secrets-71d2037c-765b-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:17:55.724: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-secrets-71d2037c-765b-11e9-96ed-42d4de3e15aa container projected-secret-volume-test: <nil>
STEP: delete the pod
May 14 15:17:55.941: INFO: Waiting for pod pod-projected-secrets-71d2037c-765b-11e9-96ed-42d4de3e15aa to disappear
May 14 15:17:56.029: INFO: Pod pod-projected-secrets-71d2037c-765b-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:17:56.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tt4d7" for this suite.
May 14 15:18:02.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:18:04.119: INFO: namespace: e2e-tests-projected-tt4d7, resource: bindings, ignored listing per whitelist
May 14 15:18:05.243: INFO: namespace e2e-tests-projected-tt4d7 deletion completed in 9.210440663s

• [SLOW TEST:12.065 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:18:05.243: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:264
[It] should do a rolling update of a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the initial replication controller
May 14 15:18:05.433: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:07.786: INFO: stderr: ""
May 14 15:18:07.786: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 14 15:18:07.786: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:08.090: INFO: stderr: ""
May 14 15:18:08.090: INFO: stdout: "update-demo-nautilus-h8b9l update-demo-nautilus-j5sbw "
May 14 15:18:08.090: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-h8b9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:08.301: INFO: stderr: ""
May 14 15:18:08.301: INFO: stdout: ""
May 14 15:18:08.301: INFO: update-demo-nautilus-h8b9l is created but not running
May 14 15:18:13.302: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:13.593: INFO: stderr: ""
May 14 15:18:13.593: INFO: stdout: "update-demo-nautilus-h8b9l update-demo-nautilus-j5sbw "
May 14 15:18:13.593: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-h8b9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:13.850: INFO: stderr: ""
May 14 15:18:13.850: INFO: stdout: "true"
May 14 15:18:13.850: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-h8b9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:14.065: INFO: stderr: ""
May 14 15:18:14.065: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 14 15:18:14.065: INFO: validating pod update-demo-nautilus-h8b9l
May 14 15:18:14.159: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 15:18:14.159: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 15:18:14.159: INFO: update-demo-nautilus-h8b9l is verified up and running
May 14 15:18:14.159: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-j5sbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:14.534: INFO: stderr: ""
May 14 15:18:14.534: INFO: stdout: "true"
May 14 15:18:14.534: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-nautilus-j5sbw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:14.737: INFO: stderr: ""
May 14 15:18:14.737: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus-amd64:1.0"
May 14 15:18:14.737: INFO: validating pod update-demo-nautilus-j5sbw
May 14 15:18:14.833: INFO: got data: {
  "image": "nautilus.jpg"
}

May 14 15:18:14.833: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 14 15:18:14.833: INFO: update-demo-nautilus-j5sbw is verified up and running
STEP: rolling-update to new replication controller
May 14 15:18:14.833: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:38.713: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 14 15:18:38.713: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 14 15:18:38.713: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:39.075: INFO: stderr: ""
May 14 15:18:39.075: INFO: stdout: "update-demo-kitten-sznj5 update-demo-kitten-zv9bc "
May 14 15:18:39.075: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-kitten-sznj5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:39.455: INFO: stderr: ""
May 14 15:18:39.455: INFO: stdout: "true"
May 14 15:18:39.455: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-kitten-sznj5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:39.738: INFO: stderr: ""
May 14 15:18:39.738: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
May 14 15:18:39.738: INFO: validating pod update-demo-kitten-sznj5
May 14 15:18:39.856: INFO: got data: {
  "image": "kitten.jpg"
}

May 14 15:18:39.856: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 14 15:18:39.856: INFO: update-demo-kitten-sznj5 is verified up and running
May 14 15:18:39.856: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-kitten-zv9bc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:40.299: INFO: stderr: ""
May 14 15:18:40.299: INFO: stdout: "true"
May 14 15:18:40.299: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods update-demo-kitten-zv9bc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hll65'
May 14 15:18:40.610: INFO: stderr: ""
May 14 15:18:40.610: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten-amd64:1.0"
May 14 15:18:40.610: INFO: validating pod update-demo-kitten-zv9bc
May 14 15:18:40.719: INFO: got data: {
  "image": "kitten.jpg"
}

May 14 15:18:40.719: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 14 15:18:40.719: INFO: update-demo-kitten-zv9bc is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:18:40.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hll65" for this suite.
May 14 15:19:02.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:19:06.021: INFO: namespace: e2e-tests-kubectl-hll65, resource: bindings, ignored listing per whitelist
May 14 15:19:06.021: INFO: namespace e2e-tests-kubectl-hll65 deletion completed in 25.297081128s

• [SLOW TEST:60.779 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should do a rolling update of a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:19:06.029: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-mthlw
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a new StatefulSet
May 14 15:19:06.498: INFO: Found 1 stateful pods, waiting for 3
May 14 15:19:16.504: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 14 15:19:16.504: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 14 15:19:16.504: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 14 15:19:16.607: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-mthlw ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 15:19:17.177: INFO: stderr: ""
May 14 15:19:17.177: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 15:19:17.177: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21
May 14 15:19:27.592: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 14 15:19:37.637: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-mthlw ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:19:37.998: INFO: stderr: ""
May 14 15:19:37.998: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 15:19:37.998: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 15:19:48.029: INFO: Waiting for StatefulSet e2e-tests-statefulset-mthlw/ss2 to complete update
May 14 15:19:48.029: INFO: Waiting for Pod e2e-tests-statefulset-mthlw/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff
STEP: Rolling back to a previous revision
May 14 15:19:58.036: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-mthlw ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 15:19:58.250: INFO: stderr: ""
May 14 15:19:58.250: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 15:19:58.250: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 15:20:08.280: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 14 15:20:18.312: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-mthlw ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:20:18.499: INFO: stderr: ""
May 14 15:20:18.499: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 15:20:18.499: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 14 15:20:38.525: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mthlw
May 14 15:20:38.629: INFO: Scaling statefulset ss2 to 0
May 14 15:21:08.704: INFO: Waiting for statefulset status.replicas updated to 0
May 14 15:21:08.774: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:21:09.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mthlw" for this suite.
May 14 15:21:15.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:21:16.971: INFO: namespace: e2e-tests-statefulset-mthlw, resource: bindings, ignored listing per whitelist
May 14 15:21:18.186: INFO: namespace e2e-tests-statefulset-mthlw deletion completed in 9.036611242s

• [SLOW TEST:132.157 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should perform rolling updates and roll backs of template modifications [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:21:18.186: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 14 15:21:18.511: INFO: Waiting up to 5m0s for pod "pod-ebf1c4ca-765b-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-cx78r" to be "success or failure"
May 14 15:21:18.625: INFO: Pod "pod-ebf1c4ca-765b-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 113.336941ms
May 14 15:21:20.633: INFO: Pod "pod-ebf1c4ca-765b-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121905811s
May 14 15:21:22.637: INFO: Pod "pod-ebf1c4ca-765b-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.125252352s
STEP: Saw pod success
May 14 15:21:22.637: INFO: Pod "pod-ebf1c4ca-765b-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:21:22.639: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-ebf1c4ca-765b-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:21:22.839: INFO: Waiting for pod pod-ebf1c4ca-765b-11e9-96ed-42d4de3e15aa to disappear
May 14 15:21:22.928: INFO: Pod pod-ebf1c4ca-765b-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:21:22.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cx78r" for this suite.
May 14 15:21:29.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:21:29.670: INFO: namespace: e2e-tests-emptydir-cx78r, resource: bindings, ignored listing per whitelist
May 14 15:21:32.185: INFO: namespace e2e-tests-emptydir-cx78r deletion completed in 9.254078243s

• [SLOW TEST:13.999 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:21:32.185: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 14 15:21:33.195: INFO: Number of nodes with available pods: 0
May 14 15:21:33.195: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:21:34.201: INFO: Number of nodes with available pods: 0
May 14 15:21:34.201: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:21:35.206: INFO: Number of nodes with available pods: 1
May 14 15:21:35.206: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq is running more than one daemon pod
May 14 15:21:36.201: INFO: Number of nodes with available pods: 2
May 14 15:21:36.201: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq is running more than one daemon pod
May 14 15:21:37.202: INFO: Number of nodes with available pods: 3
May 14 15:21:37.202: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 14 15:21:37.434: INFO: Number of nodes with available pods: 2
May 14 15:21:37.434: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq is running more than one daemon pod
May 14 15:21:38.442: INFO: Number of nodes with available pods: 2
May 14 15:21:38.443: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq is running more than one daemon pod
May 14 15:21:39.441: INFO: Number of nodes with available pods: 3
May 14 15:21:39.441: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-lqp8x, will wait for the garbage collector to delete the pods
May 14 15:21:39.872: INFO: Deleting {extensions DaemonSet} daemon-set took: 94.219528ms
May 14 15:21:39.972: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.36715ms
May 14 15:21:45.877: INFO: Number of nodes with available pods: 0
May 14 15:21:45.877: INFO: Number of running nodes: 0, number of available pods: 0
May 14 15:21:45.882: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lqp8x/daemonsets","resourceVersion":"4092"},"items":null}

May 14 15:21:45.885: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lqp8x/pods","resourceVersion":"4092"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:21:45.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lqp8x" for this suite.
May 14 15:21:52.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:21:53.141: INFO: namespace: e2e-tests-daemonsets-lqp8x, resource: bindings, ignored listing per whitelist
May 14 15:21:55.001: INFO: namespace e2e-tests-daemonsets-lqp8x deletion completed in 9.101099477s

• [SLOW TEST:22.816 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:21:55.001: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:21:55.250: INFO: Waiting up to 5m0s for pod "downwardapi-volume-01d87adc-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-8pxxt" to be "success or failure"
May 14 15:21:55.343: INFO: Pod "downwardapi-volume-01d87adc-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 92.79281ms
May 14 15:21:57.347: INFO: Pod "downwardapi-volume-01d87adc-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.096976709s
STEP: Saw pod success
May 14 15:21:57.347: INFO: Pod "downwardapi-volume-01d87adc-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:21:57.350: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-01d87adc-765c-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:21:57.538: INFO: Waiting for pod downwardapi-volume-01d87adc-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:21:57.630: INFO: Pod downwardapi-volume-01d87adc-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:21:57.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8pxxt" for this suite.
May 14 15:22:03.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:22:04.571: INFO: namespace: e2e-tests-projected-8pxxt, resource: bindings, ignored listing per whitelist
May 14 15:22:06.986: INFO: namespace e2e-tests-projected-8pxxt deletion completed in 9.350870184s

• [SLOW TEST:11.985 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:22:06.986: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name s-test-opt-del-090fc2b5-765c-11e9-96ed-42d4de3e15aa
STEP: Creating secret with name s-test-opt-upd-090fc320-765c-11e9-96ed-42d4de3e15aa
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-090fc2b5-765c-11e9-96ed-42d4de3e15aa
STEP: Updating secret s-test-opt-upd-090fc320-765c-11e9-96ed-42d4de3e15aa
STEP: Creating secret with name s-test-opt-create-090fc33c-765c-11e9-96ed-42d4de3e15aa
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:22:11.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xlqj6" for this suite.
May 14 15:22:34.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:22:35.324: INFO: namespace: e2e-tests-projected-xlqj6, resource: bindings, ignored listing per whitelist
May 14 15:22:37.188: INFO: namespace e2e-tests-projected-xlqj6 deletion completed in 25.247673878s

• [SLOW TEST:30.202 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:22:37.188: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:22:37.544: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1b0b346e-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-xtrt5" to be "success or failure"
May 14 15:22:37.670: INFO: Pod "downwardapi-volume-1b0b346e-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 125.401822ms
May 14 15:22:39.677: INFO: Pod "downwardapi-volume-1b0b346e-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.13277655s
STEP: Saw pod success
May 14 15:22:39.677: INFO: Pod "downwardapi-volume-1b0b346e-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:22:39.682: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-1b0b346e-765c-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:22:39.891: INFO: Waiting for pod downwardapi-volume-1b0b346e-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:22:39.988: INFO: Pod downwardapi-volume-1b0b346e-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:22:39.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xtrt5" for this suite.
May 14 15:22:46.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:22:47.308: INFO: namespace: e2e-tests-downward-api-xtrt5, resource: bindings, ignored listing per whitelist
May 14 15:22:49.182: INFO: namespace e2e-tests-downward-api-xtrt5 deletion completed in 9.191256722s

• [SLOW TEST:11.994 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:22:49.183: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:22:49.470: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2224f257-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-9qpt2" to be "success or failure"
May 14 15:22:49.562: INFO: Pod "downwardapi-volume-2224f257-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 91.871445ms
May 14 15:22:51.568: INFO: Pod "downwardapi-volume-2224f257-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.098189039s
STEP: Saw pod success
May 14 15:22:51.568: INFO: Pod "downwardapi-volume-2224f257-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:22:51.572: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-2224f257-765c-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:22:51.779: INFO: Waiting for pod downwardapi-volume-2224f257-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:22:51.867: INFO: Pod downwardapi-volume-2224f257-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:22:51.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9qpt2" for this suite.
May 14 15:22:58.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:22:59.440: INFO: namespace: e2e-tests-projected-9qpt2, resource: bindings, ignored listing per whitelist
May 14 15:23:01.140: INFO: namespace e2e-tests-projected-9qpt2 deletion completed in 9.269453757s

• [SLOW TEST:11.957 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:23:01.140: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name s-test-opt-del-294398bf-765c-11e9-96ed-42d4de3e15aa
STEP: Creating secret with name s-test-opt-upd-29439917-765c-11e9-96ed-42d4de3e15aa
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-294398bf-765c-11e9-96ed-42d4de3e15aa
STEP: Updating secret s-test-opt-upd-29439917-765c-11e9-96ed-42d4de3e15aa
STEP: Creating secret with name s-test-opt-create-29439931-765c-11e9-96ed-42d4de3e15aa
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:23:05.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8cnvq" for this suite.
May 14 15:23:28.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:23:30.881: INFO: namespace: e2e-tests-secrets-8cnvq, resource: bindings, ignored listing per whitelist
May 14 15:23:31.438: INFO: namespace e2e-tests-secrets-8cnvq deletion completed in 25.510949407s

• [SLOW TEST:30.298 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:23:31.439: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
May 14 15:23:31.712: INFO: Waiting up to 5m0s for pod "pod-3b57577a-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-xn7gs" to be "success or failure"
May 14 15:23:31.805: INFO: Pod "pod-3b57577a-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 93.189833ms
May 14 15:23:33.809: INFO: Pod "pod-3b57577a-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.096394419s
STEP: Saw pod success
May 14 15:23:33.809: INFO: Pod "pod-3b57577a-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:23:33.815: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-3b57577a-765c-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:23:34.004: INFO: Waiting for pod pod-3b57577a-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:23:34.089: INFO: Pod pod-3b57577a-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:23:34.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xn7gs" for this suite.
May 14 15:23:40.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:23:43.312: INFO: namespace: e2e-tests-emptydir-xn7gs, resource: bindings, ignored listing per whitelist
May 14 15:23:44.110: INFO: namespace e2e-tests-emptydir-xn7gs deletion completed in 10.017298943s

• [SLOW TEST:12.671 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:23:44.110: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-42ec57c8-765c-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 15:23:44.559: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-42fde39e-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-nt2w4" to be "success or failure"
May 14 15:23:44.650: INFO: Pod "pod-projected-configmaps-42fde39e-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 91.352109ms
May 14 15:23:46.653: INFO: Pod "pod-projected-configmaps-42fde39e-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.094463169s
May 14 15:23:48.656: INFO: Pod "pod-projected-configmaps-42fde39e-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.097321477s
STEP: Saw pod success
May 14 15:23:48.656: INFO: Pod "pod-projected-configmaps-42fde39e-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:23:48.658: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-configmaps-42fde39e-765c-11e9-96ed-42d4de3e15aa container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 15:23:48.866: INFO: Waiting for pod pod-projected-configmaps-42fde39e-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:23:48.948: INFO: Pod pod-projected-configmaps-42fde39e-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:23:48.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nt2w4" for this suite.
May 14 15:23:55.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:23:56.812: INFO: namespace: e2e-tests-projected-nt2w4, resource: bindings, ignored listing per whitelist
May 14 15:23:58.476: INFO: namespace e2e-tests-projected-nt2w4 deletion completed in 9.439691743s

• [SLOW TEST:14.366 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:23:58.476: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:23:58.835: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4b7fdbb1-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-7qzj2" to be "success or failure"
May 14 15:23:58.921: INFO: Pod "downwardapi-volume-4b7fdbb1-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 85.711917ms
May 14 15:24:00.928: INFO: Pod "downwardapi-volume-4b7fdbb1-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.092101705s
STEP: Saw pod success
May 14 15:24:00.928: INFO: Pod "downwardapi-volume-4b7fdbb1-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:24:00.930: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-4b7fdbb1-765c-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:24:01.133: INFO: Waiting for pod downwardapi-volume-4b7fdbb1-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:24:01.228: INFO: Pod downwardapi-volume-4b7fdbb1-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:24:01.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7qzj2" for this suite.
May 14 15:24:07.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:24:08.448: INFO: namespace: e2e-tests-projected-7qzj2, resource: bindings, ignored listing per whitelist
May 14 15:24:10.746: INFO: namespace e2e-tests-projected-7qzj2 deletion completed in 9.515038102s

• [SLOW TEST:12.270 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:24:10.746: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 14 15:24:11.320: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-clsjr,SelfLink:/api/v1/namespaces/e2e-tests-watch-clsjr/configmaps/e2e-watch-test-watch-closed,UID:52deabe8-765c-11e9-a4a8-42010a8c006e,ResourceVersion:4643,Generation:0,CreationTimestamp:2019-05-14 15:24:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 14 15:24:11.320: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-clsjr,SelfLink:/api/v1/namespaces/e2e-tests-watch-clsjr/configmaps/e2e-watch-test-watch-closed,UID:52deabe8-765c-11e9-a4a8-42010a8c006e,ResourceVersion:4644,Generation:0,CreationTimestamp:2019-05-14 15:24:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 14 15:24:11.423: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-clsjr,SelfLink:/api/v1/namespaces/e2e-tests-watch-clsjr/configmaps/e2e-watch-test-watch-closed,UID:52deabe8-765c-11e9-a4a8-42010a8c006e,ResourceVersion:4645,Generation:0,CreationTimestamp:2019-05-14 15:24:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 14 15:24:11.423: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-clsjr,SelfLink:/api/v1/namespaces/e2e-tests-watch-clsjr/configmaps/e2e-watch-test-watch-closed,UID:52deabe8-765c-11e9-a4a8-42010a8c006e,ResourceVersion:4647,Generation:0,CreationTimestamp:2019-05-14 15:24:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:24:11.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-clsjr" for this suite.
May 14 15:24:17.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:24:18.828: INFO: namespace: e2e-tests-watch-clsjr, resource: bindings, ignored listing per whitelist
May 14 15:24:20.971: INFO: namespace e2e-tests-watch-clsjr deletion completed in 9.543963036s

• [SLOW TEST:10.225 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:24:20.971: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-58d7cc66-765c-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 15:24:21.318: INFO: Waiting up to 5m0s for pod "pod-secrets-58e6353d-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-secrets-2dtzl" to be "success or failure"
May 14 15:24:21.408: INFO: Pod "pod-secrets-58e6353d-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 89.66872ms
May 14 15:24:23.411: INFO: Pod "pod-secrets-58e6353d-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.09235451s
May 14 15:24:25.414: INFO: Pod "pod-secrets-58e6353d-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.095589505s
STEP: Saw pod success
May 14 15:24:25.414: INFO: Pod "pod-secrets-58e6353d-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:24:25.417: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-secrets-58e6353d-765c-11e9-96ed-42d4de3e15aa container secret-env-test: <nil>
STEP: delete the pod
May 14 15:24:25.647: INFO: Waiting for pod pod-secrets-58e6353d-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:24:25.749: INFO: Pod pod-secrets-58e6353d-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:24:25.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2dtzl" for this suite.
May 14 15:24:31.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:24:32.962: INFO: namespace: e2e-tests-secrets-2dtzl, resource: bindings, ignored listing per whitelist
May 14 15:24:35.006: INFO: namespace e2e-tests-secrets-2dtzl deletion completed in 9.253217727s

• [SLOW TEST:14.035 seconds]
[sig-api-machinery] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:24:35.006: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
May 14 15:24:38.124: INFO: Successfully updated pod "annotationupdate61422656-765c-11e9-96ed-42d4de3e15aa"
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:24:42.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rd76b" for this suite.
May 14 15:25:04.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:25:07.191: INFO: namespace: e2e-tests-downward-api-rd76b, resource: bindings, ignored listing per whitelist
May 14 15:25:07.377: INFO: namespace e2e-tests-downward-api-rd76b deletion completed in 25.216198673s

• [SLOW TEST:32.371 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:25:07.377: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 14 15:25:31.722: INFO: Container started at 2019-05-14 15:25:09 +0000 UTC, pod became ready at 2019-05-14 15:25:31 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:25:31.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kv8tc" for this suite.
May 14 15:25:53.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:25:56.691: INFO: namespace: e2e-tests-container-probe-kv8tc, resource: bindings, ignored listing per whitelist
May 14 15:25:57.006: INFO: namespace e2e-tests-container-probe-kv8tc deletion completed in 25.280677915s

• [SLOW TEST:49.629 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:25:57.006: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:25:57.330: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92224415-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-pxxlg" to be "success or failure"
May 14 15:25:57.419: INFO: Pod "downwardapi-volume-92224415-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 89.238454ms
May 14 15:25:59.423: INFO: Pod "downwardapi-volume-92224415-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.093200798s
STEP: Saw pod success
May 14 15:25:59.423: INFO: Pod "downwardapi-volume-92224415-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:25:59.426: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-92224415-765c-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:25:59.623: INFO: Waiting for pod downwardapi-volume-92224415-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:25:59.711: INFO: Pod downwardapi-volume-92224415-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:25:59.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pxxlg" for this suite.
May 14 15:26:09.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:26:10.483: INFO: namespace: e2e-tests-projected-pxxlg, resource: bindings, ignored listing per whitelist
May 14 15:26:13.015: INFO: namespace e2e-tests-projected-pxxlg deletion completed in 13.215179074s

• [SLOW TEST:16.009 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:26:13.015: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-9ba0ccdd-765c-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 15:26:13.370: INFO: Waiting up to 5m0s for pod "pod-configmaps-9baf77dc-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-configmap-nbc8z" to be "success or failure"
May 14 15:26:13.463: INFO: Pod "pod-configmaps-9baf77dc-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 93.36653ms
May 14 15:26:15.467: INFO: Pod "pod-configmaps-9baf77dc-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097090785s
May 14 15:26:17.470: INFO: Pod "pod-configmaps-9baf77dc-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.099708778s
STEP: Saw pod success
May 14 15:26:17.470: INFO: Pod "pod-configmaps-9baf77dc-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:26:17.472: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-configmaps-9baf77dc-765c-11e9-96ed-42d4de3e15aa container configmap-volume-test: <nil>
STEP: delete the pod
May 14 15:26:17.840: INFO: Waiting for pod pod-configmaps-9baf77dc-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:26:17.928: INFO: Pod pod-configmaps-9baf77dc-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:26:17.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nbc8z" for this suite.
May 14 15:26:24.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:26:24.717: INFO: namespace: e2e-tests-configmap-nbc8z, resource: bindings, ignored listing per whitelist
May 14 15:26:27.313: INFO: namespace e2e-tests-configmap-nbc8z deletion completed in 9.380965267s

• [SLOW TEST:14.298 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Events
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:26:27.313: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-a429bb70-765c-11e9-96ed-42d4de3e15aa,GenerateName:,Namespace:e2e-tests-events-l6nmz,SelfLink:/api/v1/namespaces/e2e-tests-events-l6nmz/pods/send-events-a429bb70-765c-11e9-96ed-42d4de3e15aa,UID:a437ba10-765c-11e9-a4a8-42010a8c006e,ResourceVersion:5105,Generation:0,CreationTimestamp:2019-05-14 15:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 477803070,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8jg86 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8jg86,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-8jg86 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42217c810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42217c830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:26:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:26:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 15:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.140.0.68,PodIP:10.40.1.71,StartTime:2019-05-14 15:26:27 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-14 15:26:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64@sha256:2dd4032e98a0450d95a0ac71a5e465f542a900812d8c41bc6ca635aed1a5fc91 docker://9c956c6a7455e0182140afb26a615f2e97e39e2c6c136a18a45e617adc2dc379}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
STEP: checking for scheduler event about the pod
Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:26:33.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-l6nmz" for this suite.
May 14 15:26:56.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:26:57.985: INFO: namespace: e2e-tests-events-l6nmz, resource: bindings, ignored listing per whitelist
May 14 15:26:59.235: INFO: namespace e2e-tests-events-l6nmz deletion completed in 25.275032508s

• [SLOW TEST:31.922 seconds]
[k8s.io] [sig-node] Events
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:26:59.236: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 14 15:26:59.381: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 version --client'
May 14 15:26:59.524: INFO: stderr: ""
May 14 15:26:59.524: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11+\", GitVersion:\"v1.11.11-beta.0.1+9016740a6ffe91\", GitCommit:\"9016740a6ffe91bb29824f80c34087b993903bd6\", GitTreeState:\"clean\", BuildDate:\"2019-05-01T22:52:44Z\", GoVersion:\"go1.10.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 14 15:26:59.527: INFO: Not supported for server versions before "1.11.11-beta.0.1+9016740a6ffe91"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:26:59.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rpwgm" for this suite.
May 14 15:27:05.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:27:05.799: INFO: namespace: e2e-tests-kubectl-rpwgm, resource: bindings, ignored listing per whitelist
May 14 15:27:09.128: INFO: namespace e2e-tests-kubectl-rpwgm deletion completed in 9.59216057s

S [SKIPPING] [9.892 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if kubectl describe prints relevant information for rc and pods  [Conformance] [It]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684

    May 14 15:26:59.527: Not supported for server versions before "1.11.11-beta.0.1+9016740a6ffe91"

    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:305
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:27:09.128: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-bd161d37-765c-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 15:27:09.481: INFO: Waiting up to 5m0s for pod "pod-secrets-bd23aaed-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-secrets-8fxm4" to be "success or failure"
May 14 15:27:09.568: INFO: Pod "pod-secrets-bd23aaed-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 87.114661ms
May 14 15:27:11.576: INFO: Pod "pod-secrets-bd23aaed-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.095203192s
STEP: Saw pod success
May 14 15:27:11.576: INFO: Pod "pod-secrets-bd23aaed-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:27:11.582: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-secrets-bd23aaed-765c-11e9-96ed-42d4de3e15aa container secret-volume-test: <nil>
STEP: delete the pod
May 14 15:27:11.823: INFO: Waiting for pod pod-secrets-bd23aaed-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:27:11.919: INFO: Pod pod-secrets-bd23aaed-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:27:11.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8fxm4" for this suite.
May 14 15:27:18.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:27:19.875: INFO: namespace: e2e-tests-secrets-8fxm4, resource: bindings, ignored listing per whitelist
May 14 15:27:21.302: INFO: namespace e2e-tests-secrets-8fxm4 deletion completed in 9.379916854s

• [SLOW TEST:12.174 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:27:21.302: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
[It] should create an rc from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 14 15:27:21.528: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-xh89p'
May 14 15:27:21.785: INFO: stderr: ""
May 14 15:27:21.785: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 14 15:27:21.965: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-k2nj4]
May 14 15:27:21.965: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-k2nj4" in namespace "e2e-tests-kubectl-xh89p" to be "running and ready"
May 14 15:27:22.054: INFO: Pod "e2e-test-nginx-rc-k2nj4": Phase="Pending", Reason="", readiness=false. Elapsed: 88.889985ms
May 14 15:27:24.057: INFO: Pod "e2e-test-nginx-rc-k2nj4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092304428s
May 14 15:27:26.060: INFO: Pod "e2e-test-nginx-rc-k2nj4": Phase="Running", Reason="", readiness=true. Elapsed: 4.095751964s
May 14 15:27:26.061: INFO: Pod "e2e-test-nginx-rc-k2nj4" satisfied condition "running and ready"
May 14 15:27:26.061: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-k2nj4]
May 14 15:27:26.061: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-xh89p'
May 14 15:27:26.330: INFO: stderr: ""
May 14 15:27:26.330: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1221
May 14 15:27:26.330: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-xh89p'
May 14 15:27:26.660: INFO: stderr: ""
May 14 15:27:26.660: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:27:26.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xh89p" for this suite.
May 14 15:27:48.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:27:49.033: INFO: namespace: e2e-tests-kubectl-xh89p, resource: bindings, ignored listing per whitelist
May 14 15:27:52.104: INFO: namespace e2e-tests-kubectl-xh89p deletion completed in 25.438238131s

• [SLOW TEST:30.802 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create an rc from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:27:52.105: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
May 14 15:27:52.471: INFO: Waiting up to 5m0s for pod "pod-d6c2ed32-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-h7ccl" to be "success or failure"
May 14 15:27:52.561: INFO: Pod "pod-d6c2ed32-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 89.962554ms
May 14 15:27:54.565: INFO: Pod "pod-d6c2ed32-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.093735522s
STEP: Saw pod success
May 14 15:27:54.566: INFO: Pod "pod-d6c2ed32-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:27:54.569: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-d6c2ed32-765c-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:27:54.785: INFO: Waiting for pod pod-d6c2ed32-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:27:54.872: INFO: Pod pod-d6c2ed32-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:27:54.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h7ccl" for this suite.
May 14 15:28:01.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:28:02.669: INFO: namespace: e2e-tests-emptydir-h7ccl, resource: bindings, ignored listing per whitelist
May 14 15:28:04.200: INFO: namespace e2e-tests-emptydir-h7ccl deletion completed in 9.237648042s

• [SLOW TEST:12.095 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:28:04.202: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:28:04.479: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ddea8446-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-hbp5r" to be "success or failure"
May 14 15:28:04.577: INFO: Pod "downwardapi-volume-ddea8446-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 98.237515ms
May 14 15:28:06.581: INFO: Pod "downwardapi-volume-ddea8446-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.101661165s
STEP: Saw pod success
May 14 15:28:06.581: INFO: Pod "downwardapi-volume-ddea8446-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:28:06.583: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-ddea8446-765c-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:28:06.779: INFO: Waiting for pod downwardapi-volume-ddea8446-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:28:06.867: INFO: Pod downwardapi-volume-ddea8446-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:28:06.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hbp5r" for this suite.
May 14 15:28:13.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:28:15.608: INFO: namespace: e2e-tests-downward-api-hbp5r, resource: bindings, ignored listing per whitelist
May 14 15:28:16.037: INFO: namespace e2e-tests-downward-api-hbp5r deletion completed in 9.167114429s

• [SLOW TEST:11.836 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:28:16.038: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name projected-secret-test-e4f44f6a-765c-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 15:28:16.368: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e50217e9-765c-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-sq4zm" to be "success or failure"
May 14 15:28:16.456: INFO: Pod "pod-projected-secrets-e50217e9-765c-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 87.980941ms
May 14 15:28:18.459: INFO: Pod "pod-projected-secrets-e50217e9-765c-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.091038075s
STEP: Saw pod success
May 14 15:28:18.459: INFO: Pod "pod-projected-secrets-e50217e9-765c-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:28:18.461: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-secrets-e50217e9-765c-11e9-96ed-42d4de3e15aa container secret-volume-test: <nil>
STEP: delete the pod
May 14 15:28:18.657: INFO: Waiting for pod pod-projected-secrets-e50217e9-765c-11e9-96ed-42d4de3e15aa to disappear
May 14 15:28:18.741: INFO: Pod pod-projected-secrets-e50217e9-765c-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:28:18.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sq4zm" for this suite.
May 14 15:28:24.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:28:26.692: INFO: namespace: e2e-tests-projected-sq4zm, resource: bindings, ignored listing per whitelist
May 14 15:28:28.047: INFO: namespace e2e-tests-projected-sq4zm deletion completed in 9.29984556s

• [SLOW TEST:12.009 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:28:28.047: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1276
[It] should support rolling-update to same image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 14 15:28:28.221: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 run e2e-test-nginx-rc --image=k8s.gcr.io/nginx-slim-amd64:0.20 --generator=run/v1 --namespace=e2e-tests-kubectl-tglrq'
May 14 15:28:28.692: INFO: stderr: ""
May 14 15:28:28.692: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
May 14 15:28:28.877: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 rolling-update e2e-test-nginx-rc --update-period=1s --image=k8s.gcr.io/nginx-slim-amd64:0.20 --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-tglrq'
May 14 15:28:45.379: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 14 15:28:45.379: INFO: stdout: "Created e2e-test-nginx-rc-431f73289374f60ba56accf756db2368\nScaling up e2e-test-nginx-rc-431f73289374f60ba56accf756db2368 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-431f73289374f60ba56accf756db2368 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-431f73289374f60ba56accf756db2368 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 14 15:28:45.379: INFO: stdout: "Created e2e-test-nginx-rc-431f73289374f60ba56accf756db2368\nScaling up e2e-test-nginx-rc-431f73289374f60ba56accf756db2368 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-431f73289374f60ba56accf756db2368 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-431f73289374f60ba56accf756db2368 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 14 15:28:45.380: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-tglrq'
May 14 15:28:45.669: INFO: stderr: ""
May 14 15:28:45.669: INFO: stdout: "e2e-test-nginx-rc-431f73289374f60ba56accf756db2368-6kzb6 "
May 14 15:28:45.669: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods e2e-test-nginx-rc-431f73289374f60ba56accf756db2368-6kzb6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tglrq'
May 14 15:28:45.982: INFO: stderr: ""
May 14 15:28:45.982: INFO: stdout: "true"
May 14 15:28:45.982: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods e2e-test-nginx-rc-431f73289374f60ba56accf756db2368-6kzb6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tglrq'
May 14 15:28:46.245: INFO: stderr: ""
May 14 15:28:46.245: INFO: stdout: "k8s.gcr.io/nginx-slim-amd64:0.20"
May 14 15:28:46.245: INFO: e2e-test-nginx-rc-431f73289374f60ba56accf756db2368-6kzb6 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1282
May 14 15:28:46.245: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-tglrq'
May 14 15:28:46.586: INFO: stderr: ""
May 14 15:28:46.586: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:28:46.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tglrq" for this suite.
May 14 15:29:08.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:29:11.537: INFO: namespace: e2e-tests-kubectl-tglrq, resource: bindings, ignored listing per whitelist
May 14 15:29:11.802: INFO: namespace e2e-tests-kubectl-tglrq deletion completed in 25.21288334s

• [SLOW TEST:43.755 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support rolling-update to same image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:29:11.803: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 14 15:29:18.233: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-7vp6h PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:29:18.233: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:29:18.402: INFO: Exec stderr: ""
May 14 15:29:18.403: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-7vp6h PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:29:18.403: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:29:18.477: INFO: Exec stderr: ""
May 14 15:29:18.477: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-7vp6h PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:29:18.477: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:29:18.551: INFO: Exec stderr: ""
May 14 15:29:18.551: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-7vp6h PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:29:18.551: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:29:18.606: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 14 15:29:18.607: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-7vp6h PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:29:18.607: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:29:18.675: INFO: Exec stderr: ""
May 14 15:29:18.675: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-7vp6h PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:29:18.675: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:29:18.806: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 14 15:29:18.806: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-7vp6h PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:29:18.806: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:29:18.972: INFO: Exec stderr: ""
May 14 15:29:18.972: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-7vp6h PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:29:18.972: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:29:19.040: INFO: Exec stderr: ""
May 14 15:29:19.040: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-7vp6h PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:29:19.040: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:29:19.112: INFO: Exec stderr: ""
May 14 15:29:19.112: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-7vp6h PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 15:29:19.112: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 15:29:19.184: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:29:19.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-7vp6h" for this suite.
May 14 15:30:11.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:30:13.437: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-7vp6h, resource: bindings, ignored listing per whitelist
May 14 15:30:14.574: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-7vp6h deletion completed in 55.385909409s

• [SLOW TEST:62.772 seconds]
[k8s.io] KubeletManagedEtcHosts
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:30:14.576: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0777 on node default medium
May 14 15:30:14.936: INFO: Waiting up to 5m0s for pod "pod-2bad2c3f-765d-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-wj69z" to be "success or failure"
May 14 15:30:15.029: INFO: Pod "pod-2bad2c3f-765d-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 92.864269ms
May 14 15:30:17.033: INFO: Pod "pod-2bad2c3f-765d-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.096417262s
STEP: Saw pod success
May 14 15:30:17.033: INFO: Pod "pod-2bad2c3f-765d-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:30:17.035: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-2bad2c3f-765d-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:30:17.232: INFO: Waiting for pod pod-2bad2c3f-765d-11e9-96ed-42d4de3e15aa to disappear
May 14 15:30:17.315: INFO: Pod pod-2bad2c3f-765d-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:30:17.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wj69z" for this suite.
May 14 15:30:23.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:30:26.365: INFO: namespace: e2e-tests-emptydir-wj69z, resource: bindings, ignored listing per whitelist
May 14 15:30:26.627: INFO: namespace e2e-tests-emptydir-wj69z deletion completed in 9.160168574s

• [SLOW TEST:12.051 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:30:26.627: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-w9sbn/configmap-test-32cbf1e6-765d-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 15:30:26.972: INFO: Waiting up to 5m0s for pod "pod-configmaps-32d91942-765d-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-configmap-w9sbn" to be "success or failure"
May 14 15:30:27.065: INFO: Pod "pod-configmaps-32d91942-765d-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 93.164247ms
May 14 15:30:29.068: INFO: Pod "pod-configmaps-32d91942-765d-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.096113778s
May 14 15:30:31.071: INFO: Pod "pod-configmaps-32d91942-765d-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.09958435s
STEP: Saw pod success
May 14 15:30:31.071: INFO: Pod "pod-configmaps-32d91942-765d-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:30:31.074: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-configmaps-32d91942-765d-11e9-96ed-42d4de3e15aa container env-test: <nil>
STEP: delete the pod
May 14 15:30:31.293: INFO: Waiting for pod pod-configmaps-32d91942-765d-11e9-96ed-42d4de3e15aa to disappear
May 14 15:30:31.385: INFO: Pod pod-configmaps-32d91942-765d-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:30:31.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-w9sbn" for this suite.
May 14 15:30:37.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:30:39.930: INFO: namespace: e2e-tests-configmap-w9sbn, resource: bindings, ignored listing per whitelist
May 14 15:30:40.783: INFO: namespace e2e-tests-configmap-w9sbn deletion completed in 9.39466758s

• [SLOW TEST:14.157 seconds]
[sig-api-machinery] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:30:40.784: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-3b4298e1-765d-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 15:30:41.172: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3b507789-765d-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-fdgxn" to be "success or failure"
May 14 15:30:41.266: INFO: Pod "pod-projected-configmaps-3b507789-765d-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 93.733546ms
May 14 15:30:43.270: INFO: Pod "pod-projected-configmaps-3b507789-765d-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097502863s
May 14 15:30:45.274: INFO: Pod "pod-projected-configmaps-3b507789-765d-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.101105474s
STEP: Saw pod success
May 14 15:30:45.274: INFO: Pod "pod-projected-configmaps-3b507789-765d-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:30:45.276: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-configmaps-3b507789-765d-11e9-96ed-42d4de3e15aa container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 15:30:45.470: INFO: Waiting for pod pod-projected-configmaps-3b507789-765d-11e9-96ed-42d4de3e15aa to disappear
May 14 15:30:45.556: INFO: Pod pod-projected-configmaps-3b507789-765d-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:30:45.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fdgxn" for this suite.
May 14 15:30:51.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:30:53.056: INFO: namespace: e2e-tests-projected-fdgxn, resource: bindings, ignored listing per whitelist
May 14 15:30:54.893: INFO: namespace e2e-tests-projected-fdgxn deletion completed in 9.331304914s

• [SLOW TEST:14.108 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:30:54.893: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0666 on node default medium
May 14 15:30:55.160: INFO: Waiting up to 5m0s for pod "pod-43a79de2-765d-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-8l64q" to be "success or failure"
May 14 15:30:55.251: INFO: Pod "pod-43a79de2-765d-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 91.637105ms
May 14 15:30:57.254: INFO: Pod "pod-43a79de2-765d-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.094593569s
STEP: Saw pod success
May 14 15:30:57.254: INFO: Pod "pod-43a79de2-765d-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:30:57.256: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-43a79de2-765d-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:30:57.448: INFO: Waiting for pod pod-43a79de2-765d-11e9-96ed-42d4de3e15aa to disappear
May 14 15:30:57.539: INFO: Pod pod-43a79de2-765d-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:30:57.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8l64q" for this suite.
May 14 15:31:03.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:31:08.542: INFO: namespace: e2e-tests-emptydir-8l64q, resource: bindings, ignored listing per whitelist
May 14 15:31:08.977: INFO: namespace e2e-tests-emptydir-8l64q deletion completed in 11.435715022s

• [SLOW TEST:14.084 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:31:08.978: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-ckws4
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-ckws4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-ckws4
May 14 15:31:09.533: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May 14 15:31:19.539: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 14 15:31:19.550: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 15:31:19.952: INFO: stderr: ""
May 14 15:31:19.952: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 15:31:19.952: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 15:31:19.955: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 14 15:31:29.959: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 14 15:31:29.959: INFO: Waiting for statefulset status.replicas updated to 0
May 14 15:31:30.163: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999285s
May 14 15:31:31.167: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.990097014s
May 14 15:31:32.171: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.985661664s
May 14 15:31:33.175: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982061886s
May 14 15:31:34.178: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.978667723s
May 14 15:31:35.182: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.974921624s
May 14 15:31:36.186: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.971042406s
May 14 15:31:37.189: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.967485s
May 14 15:31:38.193: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.96404325s
May 14 15:31:39.197: INFO: Verifying statefulset ss doesn't scale past 1 for another 959.645609ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-ckws4
May 14 15:31:40.201: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:31:40.400: INFO: stderr: ""
May 14 15:31:40.400: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 15:31:40.400: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 15:31:40.405: INFO: Found 1 stateful pods, waiting for 3
May 14 15:31:50.416: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 14 15:31:50.416: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 14 15:31:50.416: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 14 15:31:50.423: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 15:31:50.670: INFO: stderr: ""
May 14 15:31:50.670: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 15:31:50.670: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 15:31:50.670: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 15:31:51.135: INFO: stderr: ""
May 14 15:31:51.135: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 15:31:51.135: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 15:31:51.135: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 15:31:51.641: INFO: stderr: ""
May 14 15:31:51.641: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 15:31:51.641: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 15:31:51.641: INFO: Waiting for statefulset status.replicas updated to 0
May 14 15:31:51.645: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May 14 15:32:01.916: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 14 15:32:01.916: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 14 15:32:01.916: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 14 15:32:02.019: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999947s
May 14 15:32:03.024: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993217873s
May 14 15:32:04.042: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989520923s
May 14 15:32:05.055: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.971667823s
May 14 15:32:06.058: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.95921897s
May 14 15:32:07.062: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.955488337s
May 14 15:32:08.067: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.951175485s
May 14 15:32:09.072: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.946144066s
May 14 15:32:10.081: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.936166343s
May 14 15:32:11.088: INFO: Verifying statefulset ss doesn't scale past 3 for another 931.821841ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-ckws4
May 14 15:32:12.093: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:32:12.575: INFO: stderr: ""
May 14 15:32:12.575: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 15:32:12.575: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 15:32:12.575: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:32:13.094: INFO: stderr: ""
May 14 15:32:13.094: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 15:32:13.094: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 15:32:13.094: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:32:13.622: INFO: rc: 1
May 14 15:32:13.622: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc4210ac2d0 exit status 1 <nil> <nil> true [0xc420902858 0xc4209028f8 0xc420902938] [0xc420902858 0xc4209028f8 0xc420902938] [0xc4209028e0 0xc420902920] [0x8fb1c0 0x8fb1c0] 0xc4219f17a0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

May 14 15:32:23.623: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:32:23.729: INFO: rc: 1
May 14 15:32:23.729: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4210acb10 exit status 1 <nil> <nil> true [0xc420902968 0xc420902a80 0xc420902af0] [0xc420902968 0xc420902a80 0xc420902af0] [0xc4209029f8 0xc420902ad8] [0x8fb1c0 0x8fb1c0] 0xc4219f18c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:32:33.729: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:32:33.832: INFO: rc: 1
May 14 15:32:33.832: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4216e3fb0 exit status 1 <nil> <nil> true [0xc420914b18 0xc420914b38 0xc420914b70] [0xc420914b18 0xc420914b38 0xc420914b70] [0xc420914b30 0xc420914b50] [0x8fb1c0 0x8fb1c0] 0xc421dc5980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:32:43.833: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:32:43.950: INFO: rc: 1
May 14 15:32:43.950: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ac66c0 exit status 1 <nil> <nil> true [0xc420914b88 0xc420914cb0 0xc420914d58] [0xc420914b88 0xc420914cb0 0xc420914d58] [0xc420914bc8 0xc420914d30] [0x8fb1c0 0x8fb1c0] 0xc421dc5b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:32:53.951: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:32:54.133: INFO: rc: 1
May 14 15:32:54.134: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4210ad260 exit status 1 <nil> <nil> true [0xc420902b00 0xc420902b50 0xc420902bb0] [0xc420902b00 0xc420902b50 0xc420902bb0] [0xc420902b38 0xc420902ba0] [0x8fb1c0 0x8fb1c0] 0xc4219f19e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:33:04.134: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:33:04.367: INFO: rc: 1
May 14 15:33:04.367: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421f0ccc0 exit status 1 <nil> <nil> true [0xc42155a1c8 0xc42155a1e0 0xc42155a1f8] [0xc42155a1c8 0xc42155a1e0 0xc42155a1f8] [0xc42155a1d8 0xc42155a1f0] [0x8fb1c0 0x8fb1c0] 0xc42173d200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:33:14.368: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:33:14.480: INFO: rc: 1
May 14 15:33:14.480: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421525ad0 exit status 1 <nil> <nil> true [0xc4200ead90 0xc4200eadc8 0xc4200eae30] [0xc4200ead90 0xc4200eadc8 0xc4200eae30] [0xc4200eadc0 0xc4200eae08] [0x8fb1c0 0x8fb1c0] 0xc42192db00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:33:24.482: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:33:24.687: INFO: rc: 1
May 14 15:33:24.687: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ba2720 exit status 1 <nil> <nil> true [0xc42155a008 0xc42155a020 0xc42155a038] [0xc42155a008 0xc42155a020 0xc42155a038] [0xc42155a018 0xc42155a030] [0x8fb1c0 0x8fb1c0] 0xc42173c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:33:34.687: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:33:34.816: INFO: rc: 1
May 14 15:33:34.816: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ba2f00 exit status 1 <nil> <nil> true [0xc42155a040 0xc42155a058 0xc42155a070] [0xc42155a040 0xc42155a058 0xc42155a070] [0xc42155a050 0xc42155a068] [0x8fb1c0 0x8fb1c0] 0xc42173c1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:33:44.816: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:33:44.916: INFO: rc: 1
May 14 15:33:44.916: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421bea7b0 exit status 1 <nil> <nil> true [0xc420902030 0xc420902100 0xc4209021a0] [0xc420902030 0xc420902100 0xc4209021a0] [0xc4209020b0 0xc420902188] [0x8fb1c0 0x8fb1c0] 0xc4219f0060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:33:54.916: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:33:55.109: INFO: rc: 1
May 14 15:33:55.109: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421beb230 exit status 1 <nil> <nil> true [0xc4209021b8 0xc420902230 0xc420902280] [0xc4209021b8 0xc420902230 0xc420902280] [0xc420902210 0xc420902268] [0x8fb1c0 0x8fb1c0] 0xc4219f0300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:34:05.114: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:34:05.566: INFO: rc: 1
May 14 15:34:05.566: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ba3740 exit status 1 <nil> <nil> true [0xc42155a078 0xc42155a090 0xc42155a0a8] [0xc42155a078 0xc42155a090 0xc42155a0a8] [0xc42155a088 0xc42155a0a0] [0x8fb1c0 0x8fb1c0] 0xc42173c300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:34:15.566: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:34:15.736: INFO: rc: 1
May 14 15:34:15.736: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ba3e60 exit status 1 <nil> <nil> true [0xc42155a0b0 0xc42155a0c8 0xc42155a0f0] [0xc42155a0b0 0xc42155a0c8 0xc42155a0f0] [0xc42155a0c0 0xc42155a0e0] [0x8fb1c0 0x8fb1c0] 0xc42173c420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:34:25.736: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:34:25.855: INFO: rc: 1
May 14 15:34:25.855: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4216e2810 exit status 1 <nil> <nil> true [0xc42155a0f8 0xc42155a110 0xc42155a128] [0xc42155a0f8 0xc42155a110 0xc42155a128] [0xc42155a108 0xc42155a120] [0x8fb1c0 0x8fb1c0] 0xc42173c540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:34:35.855: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:34:35.963: INFO: rc: 1
May 14 15:34:35.963: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4216e2f90 exit status 1 <nil> <nil> true [0xc42155a130 0xc42155a148 0xc42155a160] [0xc42155a130 0xc42155a148 0xc42155a160] [0xc42155a140 0xc42155a158] [0x8fb1c0 0x8fb1c0] 0xc42173c660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:34:45.963: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:34:46.107: INFO: rc: 1
May 14 15:34:46.107: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421efe780 exit status 1 <nil> <nil> true [0xc4209140f8 0xc420914188 0xc420914278] [0xc4209140f8 0xc420914188 0xc420914278] [0xc420914138 0xc4209141e8] [0x8fb1c0 0x8fb1c0] 0xc42192c720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:34:56.107: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:34:56.321: INFO: rc: 1
May 14 15:34:56.321: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421efeea0 exit status 1 <nil> <nil> true [0xc420914298 0xc4209142f0 0xc420914348] [0xc420914298 0xc4209142f0 0xc420914348] [0xc4209142d8 0xc420914340] [0x8fb1c0 0x8fb1c0] 0xc42192c840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:35:06.323: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:35:06.522: INFO: rc: 1
May 14 15:35:06.522: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421beba10 exit status 1 <nil> <nil> true [0xc4209022d0 0xc420902330 0xc4209023a0] [0xc4209022d0 0xc420902330 0xc4209023a0] [0xc420902310 0xc420902390] [0x8fb1c0 0x8fb1c0] 0xc4219f0420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:35:16.522: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:35:16.652: INFO: rc: 1
May 14 15:35:16.652: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421eff6e0 exit status 1 <nil> <nil> true [0xc420914358 0xc420914370 0xc4209143a8] [0xc420914358 0xc420914370 0xc4209143a8] [0xc420914368 0xc420914380] [0x8fb1c0 0x8fb1c0] 0xc42192c960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:35:26.652: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:35:26.749: INFO: rc: 1
May 14 15:35:26.749: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ba2780 exit status 1 <nil> <nil> true [0xc42155a008 0xc42155a020 0xc42155a038] [0xc42155a008 0xc42155a020 0xc42155a038] [0xc42155a018 0xc42155a030] [0x8fb1c0 0x8fb1c0] 0xc42173c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:35:36.750: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:35:36.845: INFO: rc: 1
May 14 15:35:36.845: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421efe7b0 exit status 1 <nil> <nil> true [0xc4209140f8 0xc420914188 0xc420914278] [0xc4209140f8 0xc420914188 0xc420914278] [0xc420914138 0xc4209141e8] [0x8fb1c0 0x8fb1c0] 0xc42192c720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:35:46.846: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:35:46.981: INFO: rc: 1
May 14 15:35:46.981: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421bea7e0 exit status 1 <nil> <nil> true [0xc420902030 0xc420902100 0xc4209021a0] [0xc420902030 0xc420902100 0xc4209021a0] [0xc4209020b0 0xc420902188] [0x8fb1c0 0x8fb1c0] 0xc4219f0060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:35:56.981: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:35:57.152: INFO: rc: 1
May 14 15:35:57.152: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ba2f30 exit status 1 <nil> <nil> true [0xc42155a040 0xc42155a058 0xc42155a070] [0xc42155a040 0xc42155a058 0xc42155a070] [0xc42155a050 0xc42155a068] [0x8fb1c0 0x8fb1c0] 0xc42173c1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:36:07.153: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:36:07.763: INFO: rc: 1
May 14 15:36:07.763: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421efeed0 exit status 1 <nil> <nil> true [0xc420914298 0xc4209142f0 0xc420914348] [0xc420914298 0xc4209142f0 0xc420914348] [0xc4209142d8 0xc420914340] [0x8fb1c0 0x8fb1c0] 0xc42192c840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:36:17.763: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:36:17.894: INFO: rc: 1
May 14 15:36:17.894: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421ba37d0 exit status 1 <nil> <nil> true [0xc42155a078 0xc42155a090 0xc42155a0a8] [0xc42155a078 0xc42155a090 0xc42155a0a8] [0xc42155a088 0xc42155a0a0] [0x8fb1c0 0x8fb1c0] 0xc42173c300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:36:27.894: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:36:27.986: INFO: rc: 1
May 14 15:36:27.986: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421beb2c0 exit status 1 <nil> <nil> true [0xc4209021b8 0xc420902230 0xc420902280] [0xc4209021b8 0xc420902230 0xc420902280] [0xc420902210 0xc420902268] [0x8fb1c0 0x8fb1c0] 0xc4219f0300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:36:37.987: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:36:38.114: INFO: rc: 1
May 14 15:36:38.114: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421eff710 exit status 1 <nil> <nil> true [0xc420914358 0xc420914370 0xc4209143a8] [0xc420914358 0xc420914370 0xc4209143a8] [0xc420914368 0xc420914380] [0x8fb1c0 0x8fb1c0] 0xc42192c960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:36:48.114: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:36:48.301: INFO: rc: 1
May 14 15:36:48.302: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421effe30 exit status 1 <nil> <nil> true [0xc4209143e0 0xc420914420 0xc420914478] [0xc4209143e0 0xc420914420 0xc420914478] [0xc420914418 0xc420914448] [0x8fb1c0 0x8fb1c0] 0xc42192ca80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:36:58.302: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:36:58.547: INFO: rc: 1
May 14 15:36:58.547: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4213d05d0 exit status 1 <nil> <nil> true [0xc4209144b0 0xc4209144d8 0xc4209145b0] [0xc4209144b0 0xc4209144d8 0xc4209145b0] [0xc4209144d0 0xc420914528] [0x8fb1c0 0x8fb1c0] 0xc42192cba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:37:08.548: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:37:08.855: INFO: rc: 1
May 14 15:37:08.855: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421beb9e0 exit status 1 <nil> <nil> true [0xc4209022d0 0xc420902330 0xc4209023a0] [0xc4209022d0 0xc420902330 0xc4209023a0] [0xc420902310 0xc420902390] [0x8fb1c0 0x8fb1c0] 0xc4219f0420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

May 14 15:37:18.856: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-ckws4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 15:37:19.036: INFO: rc: 1
May 14 15:37:19.036: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
May 14 15:37:19.036: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 14 15:37:19.308: INFO: Deleting all statefulset in ns e2e-tests-statefulset-ckws4
May 14 15:37:19.403: INFO: Scaling statefulset ss to 0
May 14 15:37:19.415: INFO: Waiting for statefulset status.replicas updated to 0
May 14 15:37:19.418: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:37:19.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-ckws4" for this suite.
May 14 15:37:25.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:37:28.732: INFO: namespace: e2e-tests-statefulset-ckws4, resource: bindings, ignored listing per whitelist
May 14 15:37:28.733: INFO: namespace e2e-tests-statefulset-ckws4 deletion completed in 8.949836136s

• [SLOW TEST:379.755 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:37:28.733: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap e2e-tests-configmap-db8ww/configmap-test-2e78b82a-765e-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 15:37:29.206: INFO: Waiting up to 5m0s for pod "pod-configmaps-2e86e40f-765e-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-configmap-db8ww" to be "success or failure"
May 14 15:37:29.296: INFO: Pod "pod-configmaps-2e86e40f-765e-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 89.236141ms
May 14 15:37:31.300: INFO: Pod "pod-configmaps-2e86e40f-765e-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.09366356s
May 14 15:37:33.307: INFO: Pod "pod-configmaps-2e86e40f-765e-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.100896746s
STEP: Saw pod success
May 14 15:37:33.307: INFO: Pod "pod-configmaps-2e86e40f-765e-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:37:33.310: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-configmaps-2e86e40f-765e-11e9-96ed-42d4de3e15aa container env-test: <nil>
STEP: delete the pod
May 14 15:37:33.501: INFO: Waiting for pod pod-configmaps-2e86e40f-765e-11e9-96ed-42d4de3e15aa to disappear
May 14 15:37:33.587: INFO: Pod pod-configmaps-2e86e40f-765e-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:37:33.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-db8ww" for this suite.
May 14 15:37:39.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:37:40.076: INFO: namespace: e2e-tests-configmap-db8ww, resource: bindings, ignored listing per whitelist
May 14 15:37:42.943: INFO: namespace e2e-tests-configmap-db8ww deletion completed in 9.352723553s

• [SLOW TEST:14.210 seconds]
[sig-api-machinery] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:29
  should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:37:42.945: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0514 15:37:49.553967     651 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 14 15:37:49.554: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:37:49.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mmjn9" for this suite.
May 14 15:37:55.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:37:58.693: INFO: namespace: e2e-tests-gc-mmjn9, resource: bindings, ignored listing per whitelist
May 14 15:37:58.965: INFO: namespace e2e-tests-gc-mmjn9 deletion completed in 9.405535477s

• [SLOW TEST:16.020 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:37:58.967: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 14 15:38:03.987: INFO: Successfully updated pod "pod-update-activedeadlineseconds-40673f59-765e-11e9-96ed-42d4de3e15aa"
May 14 15:38:03.987: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-40673f59-765e-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-pods-n8sff" to be "terminated due to deadline exceeded"
May 14 15:38:03.990: INFO: Pod "pod-update-activedeadlineseconds-40673f59-765e-11e9-96ed-42d4de3e15aa": Phase="Running", Reason="", readiness=true. Elapsed: 2.638992ms
May 14 15:38:05.993: INFO: Pod "pod-update-activedeadlineseconds-40673f59-765e-11e9-96ed-42d4de3e15aa": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.00581339s
May 14 15:38:05.993: INFO: Pod "pod-update-activedeadlineseconds-40673f59-765e-11e9-96ed-42d4de3e15aa" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:38:05.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-n8sff" for this suite.
May 14 15:38:12.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:38:13.000: INFO: namespace: e2e-tests-pods-n8sff, resource: bindings, ignored listing per whitelist
May 14 15:38:15.108: INFO: namespace e2e-tests-pods-n8sff deletion completed in 9.112062797s

• [SLOW TEST:16.142 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:38:15.109: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
May 14 15:38:19.701: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-4a160089-765e-11e9-96ed-42d4de3e15aa", GenerateName:"", Namespace:"e2e-tests-pods-c24kg", SelfLink:"/api/v1/namespaces/e2e-tests-pods-c24kg/pods/pod-submit-remove-4a160089-765e-11e9-96ed-42d4de3e15aa", UID:"4a3b6f1b-765e-11e9-a4a8-42010a8c006e", ResourceVersion:"7416", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63693445095, loc:(*time.Location)(0x644dee0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"347014455"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-bwwwj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420d00280), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"k8s.gcr.io/nginx-slim-amd64:0.20", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-bwwwj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421d0b6a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4220d33e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421d0b6e0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421d0b700)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421d0b708), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693445095, loc:(*time.Location)(0x644dee0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693445097, loc:(*time.Location)(0x644dee0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693445095, loc:(*time.Location)(0x644dee0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.140.0.68", PodIP:"10.40.1.96", StartTime:(*v1.Time)(0xc421491240), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc421491260), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/nginx-slim-amd64:0.20", ImageID:"docker-pullable://k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b", ContainerID:"docker://104fa1ddb1e9401d350cc93c406b8a7005d61aea50ecc046d489b8ad28f55f3e"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May 14 15:38:24.893: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:38:24.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-c24kg" for this suite.
May 14 15:38:31.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:38:32.936: INFO: namespace: e2e-tests-pods-c24kg, resource: bindings, ignored listing per whitelist
May 14 15:38:34.347: INFO: namespace e2e-tests-pods-c24kg deletion completed in 9.348957177s

• [SLOW TEST:19.238 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:38:34.350: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0514 15:38:45.448628     651 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 14 15:38:45.449: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:38:45.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qfmvk" for this suite.
May 14 15:38:51.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:38:52.279: INFO: namespace: e2e-tests-gc-qfmvk, resource: bindings, ignored listing per whitelist
May 14 15:38:54.762: INFO: namespace e2e-tests-gc-qfmvk deletion completed in 9.310522928s

• [SLOW TEST:20.412 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:38:54.762: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-61b3f2ca-765e-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 15:38:55.167: INFO: Waiting up to 5m0s for pod "pod-configmaps-61c21cea-765e-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-configmap-twxj6" to be "success or failure"
May 14 15:38:55.261: INFO: Pod "pod-configmaps-61c21cea-765e-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 93.982519ms
May 14 15:38:57.265: INFO: Pod "pod-configmaps-61c21cea-765e-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.097503268s
STEP: Saw pod success
May 14 15:38:57.265: INFO: Pod "pod-configmaps-61c21cea-765e-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:38:57.267: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-configmaps-61c21cea-765e-11e9-96ed-42d4de3e15aa container configmap-volume-test: <nil>
STEP: delete the pod
May 14 15:38:57.477: INFO: Waiting for pod pod-configmaps-61c21cea-765e-11e9-96ed-42d4de3e15aa to disappear
May 14 15:38:57.569: INFO: Pod pod-configmaps-61c21cea-765e-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:38:57.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-twxj6" for this suite.
May 14 15:39:03.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:39:05.554: INFO: namespace: e2e-tests-configmap-twxj6, resource: bindings, ignored listing per whitelist
May 14 15:39:06.733: INFO: namespace e2e-tests-configmap-twxj6 deletion completed in 9.160421408s

• [SLOW TEST:11.971 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:39:06.734: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 14 15:39:07.228: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5msl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5msl5/configmaps/e2e-watch-test-configmap-a,UID:6901f08a-765e-11e9-a4a8-42010a8c006e,ResourceVersion:7698,Generation:0,CreationTimestamp:2019-05-14 15:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 14 15:39:07.229: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5msl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5msl5/configmaps/e2e-watch-test-configmap-a,UID:6901f08a-765e-11e9-a4a8-42010a8c006e,ResourceVersion:7698,Generation:0,CreationTimestamp:2019-05-14 15:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 14 15:39:17.411: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5msl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5msl5/configmaps/e2e-watch-test-configmap-a,UID:6901f08a-765e-11e9-a4a8-42010a8c006e,ResourceVersion:7723,Generation:0,CreationTimestamp:2019-05-14 15:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 14 15:39:17.412: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5msl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5msl5/configmaps/e2e-watch-test-configmap-a,UID:6901f08a-765e-11e9-a4a8-42010a8c006e,ResourceVersion:7723,Generation:0,CreationTimestamp:2019-05-14 15:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 14 15:39:27.424: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5msl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5msl5/configmaps/e2e-watch-test-configmap-a,UID:6901f08a-765e-11e9-a4a8-42010a8c006e,ResourceVersion:7748,Generation:0,CreationTimestamp:2019-05-14 15:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 14 15:39:27.425: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5msl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5msl5/configmaps/e2e-watch-test-configmap-a,UID:6901f08a-765e-11e9-a4a8-42010a8c006e,ResourceVersion:7748,Generation:0,CreationTimestamp:2019-05-14 15:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 14 15:39:37.589: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5msl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5msl5/configmaps/e2e-watch-test-configmap-a,UID:6901f08a-765e-11e9-a4a8-42010a8c006e,ResourceVersion:7773,Generation:0,CreationTimestamp:2019-05-14 15:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 14 15:39:37.589: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-5msl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5msl5/configmaps/e2e-watch-test-configmap-a,UID:6901f08a-765e-11e9-a4a8-42010a8c006e,ResourceVersion:7773,Generation:0,CreationTimestamp:2019-05-14 15:39:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 14 15:39:47.594: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-5msl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5msl5/configmaps/e2e-watch-test-configmap-b,UID:81117cec-765e-11e9-a4a8-42010a8c006e,ResourceVersion:7798,Generation:0,CreationTimestamp:2019-05-14 15:39:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 14 15:39:47.595: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-5msl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5msl5/configmaps/e2e-watch-test-configmap-b,UID:81117cec-765e-11e9-a4a8-42010a8c006e,ResourceVersion:7798,Generation:0,CreationTimestamp:2019-05-14 15:39:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 14 15:39:57.692: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-5msl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5msl5/configmaps/e2e-watch-test-configmap-b,UID:81117cec-765e-11e9-a4a8-42010a8c006e,ResourceVersion:7826,Generation:0,CreationTimestamp:2019-05-14 15:39:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 14 15:39:57.692: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-5msl5,SelfLink:/api/v1/namespaces/e2e-tests-watch-5msl5/configmaps/e2e-watch-test-configmap-b,UID:81117cec-765e-11e9-a4a8-42010a8c006e,ResourceVersion:7826,Generation:0,CreationTimestamp:2019-05-14 15:39:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:40:07.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5msl5" for this suite.
May 14 15:40:13.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:40:16.396: INFO: namespace: e2e-tests-watch-5msl5, resource: bindings, ignored listing per whitelist
May 14 15:40:16.912: INFO: namespace e2e-tests-watch-5msl5 deletion completed in 9.214956935s

• [SLOW TEST:70.179 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:40:16.912: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-projected-all-test-volume-92a421d5-765e-11e9-96ed-42d4de3e15aa
STEP: Creating secret with name secret-projected-all-test-volume-92a421c5-765e-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test Check all projections for projected volume plugin
May 14 15:40:17.343: INFO: Waiting up to 5m0s for pod "projected-volume-92a4218f-765e-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-x5m6z" to be "success or failure"
May 14 15:40:17.433: INFO: Pod "projected-volume-92a4218f-765e-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 90.13956ms
May 14 15:40:19.590: INFO: Pod "projected-volume-92a4218f-765e-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.246807602s
STEP: Saw pod success
May 14 15:40:19.590: INFO: Pod "projected-volume-92a4218f-765e-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:40:19.592: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod projected-volume-92a4218f-765e-11e9-96ed-42d4de3e15aa container projected-all-volume-test: <nil>
STEP: delete the pod
May 14 15:40:19.787: INFO: Waiting for pod projected-volume-92a4218f-765e-11e9-96ed-42d4de3e15aa to disappear
May 14 15:40:19.872: INFO: Pod projected-volume-92a4218f-765e-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:40:19.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x5m6z" for this suite.
May 14 15:40:26.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:40:27.299: INFO: namespace: e2e-tests-projected-x5m6z, resource: bindings, ignored listing per whitelist
May 14 15:40:29.135: INFO: namespace e2e-tests-projected-x5m6z deletion completed in 9.164267431s

• [SLOW TEST:12.223 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:40:29.137: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 14 15:40:29.885: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 14 15:40:30.082: INFO: Number of nodes with available pods: 0
May 14 15:40:30.082: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 14 15:40:30.193: INFO: Number of nodes with available pods: 0
May 14 15:40:30.193: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:31.202: INFO: Number of nodes with available pods: 0
May 14 15:40:31.202: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:32.203: INFO: Number of nodes with available pods: 1
May 14 15:40:32.203: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 14 15:40:32.313: INFO: Number of nodes with available pods: 1
May 14 15:40:32.314: INFO: Number of running nodes: 0, number of available pods: 1
May 14 15:40:33.330: INFO: Number of nodes with available pods: 0
May 14 15:40:33.330: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 14 15:40:33.453: INFO: Number of nodes with available pods: 0
May 14 15:40:33.453: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:34.457: INFO: Number of nodes with available pods: 0
May 14 15:40:34.457: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:35.460: INFO: Number of nodes with available pods: 0
May 14 15:40:35.461: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:36.457: INFO: Number of nodes with available pods: 0
May 14 15:40:36.457: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:37.456: INFO: Number of nodes with available pods: 0
May 14 15:40:37.456: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:38.459: INFO: Number of nodes with available pods: 0
May 14 15:40:38.460: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:39.463: INFO: Number of nodes with available pods: 0
May 14 15:40:39.463: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:40.461: INFO: Number of nodes with available pods: 0
May 14 15:40:40.461: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:41.458: INFO: Number of nodes with available pods: 0
May 14 15:40:41.458: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:42.464: INFO: Number of nodes with available pods: 0
May 14 15:40:42.465: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:43.460: INFO: Number of nodes with available pods: 0
May 14 15:40:43.461: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:44.460: INFO: Number of nodes with available pods: 0
May 14 15:40:44.461: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:45.460: INFO: Number of nodes with available pods: 0
May 14 15:40:45.460: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:40:46.457: INFO: Number of nodes with available pods: 1
May 14 15:40:46.457: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-7qml4, will wait for the garbage collector to delete the pods
May 14 15:40:46.783: INFO: Deleting {extensions DaemonSet} daemon-set took: 99.429098ms
May 14 15:40:46.884: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.999077ms
May 14 15:40:54.287: INFO: Number of nodes with available pods: 0
May 14 15:40:54.287: INFO: Number of running nodes: 0, number of available pods: 0
May 14 15:40:54.289: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-7qml4/daemonsets","resourceVersion":"8040"},"items":null}

May 14 15:40:54.291: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-7qml4/pods","resourceVersion":"8040"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:40:54.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-7qml4" for this suite.
May 14 15:41:00.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:41:03.069: INFO: namespace: e2e-tests-daemonsets-7qml4, resource: bindings, ignored listing per whitelist
May 14 15:41:03.333: INFO: namespace e2e-tests-daemonsets-7qml4 deletion completed in 9.020039195s

• [SLOW TEST:34.196 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:41:03.333: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-ae4b8d32-765e-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 15:41:03.665: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ae5a171e-765e-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-bg6xc" to be "success or failure"
May 14 15:41:03.772: INFO: Pod "pod-projected-secrets-ae5a171e-765e-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 106.795242ms
May 14 15:41:05.845: INFO: Pod "pod-projected-secrets-ae5a171e-765e-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.180049085s
May 14 15:41:07.942: INFO: Pod "pod-projected-secrets-ae5a171e-765e-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.276529183s
STEP: Saw pod success
May 14 15:41:07.942: INFO: Pod "pod-projected-secrets-ae5a171e-765e-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:41:08.025: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-secrets-ae5a171e-765e-11e9-96ed-42d4de3e15aa container projected-secret-volume-test: <nil>
STEP: delete the pod
May 14 15:41:08.612: INFO: Waiting for pod pod-projected-secrets-ae5a171e-765e-11e9-96ed-42d4de3e15aa to disappear
May 14 15:41:08.771: INFO: Pod pod-projected-secrets-ae5a171e-765e-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:41:08.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bg6xc" for this suite.
May 14 15:41:14.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:41:17.592: INFO: namespace: e2e-tests-projected-bg6xc, resource: bindings, ignored listing per whitelist
May 14 15:41:17.942: INFO: namespace e2e-tests-projected-bg6xc deletion completed in 9.132093442s

• [SLOW TEST:14.609 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:41:17.942: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0514 15:41:28.523496     651 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 14 15:41:28.523: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:41:28.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l9lbc" for this suite.
May 14 15:41:34.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:41:35.786: INFO: namespace: e2e-tests-gc-l9lbc, resource: bindings, ignored listing per whitelist
May 14 15:41:37.996: INFO: namespace e2e-tests-gc-l9lbc deletion completed in 9.465932427s

• [SLOW TEST:20.054 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:41:37.996: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create a job from an image, then delete the job  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: executing a command with run --rm and attach with stdin
May 14 15:41:38.130: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 --namespace=e2e-tests-kubectl-wjcdh run e2e-test-rm-busybox-job --image=busybox --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 14 15:41:40.723: INFO: stderr: "If you don't see a command prompt, try pressing enter.\n"
May 14 15:41:40.723: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:41:42.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wjcdh" for this suite.
May 14 15:41:48.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:41:51.229: INFO: namespace: e2e-tests-kubectl-wjcdh, resource: bindings, ignored listing per whitelist
May 14 15:41:52.030: INFO: namespace e2e-tests-kubectl-wjcdh deletion completed in 9.294869119s

• [SLOW TEST:14.034 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a job from an image, then delete the job  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:41:52.031: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-zpw69
May 14 15:41:54.373: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-zpw69
STEP: checking the pod's current state and verifying that restartCount is present
May 14 15:41:54.375: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:45:55.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zpw69" for this suite.
May 14 15:46:01.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:46:04.628: INFO: namespace: e2e-tests-container-probe-zpw69, resource: bindings, ignored listing per whitelist
May 14 15:46:04.792: INFO: namespace e2e-tests-container-probe-zpw69 deletion completed in 9.269860235s

• [SLOW TEST:252.761 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:46:04.792: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 14 15:46:08.699: INFO: Successfully updated pod "pod-update-6217b3eb-765f-11e9-96ed-42d4de3e15aa"
STEP: verifying the updated pod is in kubernetes
May 14 15:46:08.865: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:46:08.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-psqgp" for this suite.
May 14 15:46:31.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:46:34.059: INFO: namespace: e2e-tests-pods-psqgp, resource: bindings, ignored listing per whitelist
May 14 15:46:34.407: INFO: namespace e2e-tests-pods-psqgp deletion completed in 25.458435031s

• [SLOW TEST:29.615 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Service endpoints latency
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:46:34.407: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-hkjrm
I0514 15:46:34.735505     651 runners.go:177] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-hkjrm, replica count: 1
I0514 15:46:35.886167     651 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0514 15:46:36.886491     651 runners.go:177] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 14 15:46:37.198: INFO: Created: latency-svc-mhtpd
May 14 15:46:37.205: INFO: Got endpoints: latency-svc-mhtpd [118.244907ms]
May 14 15:46:37.227: INFO: Created: latency-svc-77fnk
May 14 15:46:37.233: INFO: Got endpoints: latency-svc-77fnk [28.047992ms]
May 14 15:46:37.243: INFO: Created: latency-svc-42llq
May 14 15:46:37.252: INFO: Created: latency-svc-b57bf
May 14 15:46:37.260: INFO: Created: latency-svc-8l7r9
May 14 15:46:37.264: INFO: Got endpoints: latency-svc-b57bf [58.393963ms]
May 14 15:46:37.264: INFO: Got endpoints: latency-svc-42llq [58.489403ms]
May 14 15:46:37.275: INFO: Created: latency-svc-dbg4w
May 14 15:46:37.283: INFO: Created: latency-svc-csd4l
May 14 15:46:37.286: INFO: Got endpoints: latency-svc-8l7r9 [80.91667ms]
May 14 15:46:37.295: INFO: Got endpoints: latency-svc-dbg4w [89.82575ms]
May 14 15:46:37.298: INFO: Created: latency-svc-xc7v8
May 14 15:46:37.308: INFO: Created: latency-svc-zk8r4
May 14 15:46:37.318: INFO: Created: latency-svc-2v2fz
May 14 15:46:37.323: INFO: Got endpoints: latency-svc-csd4l [117.635701ms]
May 14 15:46:37.323: INFO: Got endpoints: latency-svc-xc7v8 [117.715194ms]
May 14 15:46:37.332: INFO: Got endpoints: latency-svc-zk8r4 [126.345033ms]
May 14 15:46:37.332: INFO: Created: latency-svc-6d9g4
May 14 15:46:37.334: INFO: Created: latency-svc-gmmqr
May 14 15:46:37.351: INFO: Created: latency-svc-p52qh
May 14 15:46:37.352: INFO: Created: latency-svc-wljwf
May 14 15:46:37.353: INFO: Got endpoints: latency-svc-2v2fz [147.280261ms]
May 14 15:46:37.363: INFO: Created: latency-svc-q9zvc
May 14 15:46:37.365: INFO: Got endpoints: latency-svc-6d9g4 [159.759895ms]
May 14 15:46:37.365: INFO: Got endpoints: latency-svc-gmmqr [159.912089ms]
May 14 15:46:37.397: INFO: Got endpoints: latency-svc-p52qh [191.63653ms]
May 14 15:46:37.397: INFO: Got endpoints: latency-svc-wljwf [191.747405ms]
May 14 15:46:37.397: INFO: Got endpoints: latency-svc-q9zvc [191.750221ms]
May 14 15:46:37.399: INFO: Created: latency-svc-p9dmj
May 14 15:46:37.400: INFO: Created: latency-svc-hk8q5
May 14 15:46:37.401: INFO: Created: latency-svc-qkmcl
May 14 15:46:37.417: INFO: Created: latency-svc-vfk7k
May 14 15:46:37.427: INFO: Got endpoints: latency-svc-p9dmj [194.035117ms]
May 14 15:46:37.431: INFO: Created: latency-svc-82shq
May 14 15:46:37.436: INFO: Got endpoints: latency-svc-hk8q5 [172.468689ms]
May 14 15:46:37.436: INFO: Got endpoints: latency-svc-qkmcl [230.91829ms]
May 14 15:46:37.445: INFO: Got endpoints: latency-svc-vfk7k [180.98565ms]
May 14 15:46:37.449: INFO: Created: latency-svc-w8ww4
May 14 15:46:37.460: INFO: Created: latency-svc-w82ch
May 14 15:46:37.462: INFO: Got endpoints: latency-svc-82shq [65.363563ms]
May 14 15:46:37.477: INFO: Got endpoints: latency-svc-w8ww4 [190.691351ms]
May 14 15:46:37.481: INFO: Created: latency-svc-7wtwg
May 14 15:46:37.490: INFO: Created: latency-svc-vq2zf
May 14 15:46:37.498: INFO: Created: latency-svc-vz952
May 14 15:46:37.504: INFO: Got endpoints: latency-svc-w82ch [209.045914ms]
May 14 15:46:37.518: INFO: Got endpoints: latency-svc-7wtwg [194.919817ms]
May 14 15:46:37.525: INFO: Created: latency-svc-qcsg7
May 14 15:46:37.526: INFO: Created: latency-svc-4vmd2
May 14 15:46:37.542: INFO: Created: latency-svc-x6gtk
May 14 15:46:37.552: INFO: Got endpoints: latency-svc-vq2zf [228.711754ms]
May 14 15:46:37.562: INFO: Created: latency-svc-2tz4v
May 14 15:46:37.574: INFO: Created: latency-svc-sb7lv
May 14 15:46:37.579: INFO: Got endpoints: latency-svc-vz952 [246.932692ms]
May 14 15:46:37.579: INFO: Got endpoints: latency-svc-qcsg7 [213.74676ms]
May 14 15:46:37.590: INFO: Created: latency-svc-wwww6
May 14 15:46:37.595: INFO: Got endpoints: latency-svc-4vmd2 [242.093423ms]
May 14 15:46:37.595: INFO: Got endpoints: latency-svc-x6gtk [229.504083ms]
May 14 15:46:37.614: INFO: Created: latency-svc-bppbt
May 14 15:46:37.618: INFO: Got endpoints: latency-svc-2tz4v [220.602972ms]
May 14 15:46:37.618: INFO: Got endpoints: latency-svc-sb7lv [220.642084ms]
May 14 15:46:37.630: INFO: Created: latency-svc-nghcx
May 14 15:46:37.639: INFO: Created: latency-svc-w2d9g
May 14 15:46:37.646: INFO: Got endpoints: latency-svc-wwww6 [218.303513ms]
May 14 15:46:37.656: INFO: Got endpoints: latency-svc-bppbt [219.969327ms]
May 14 15:46:37.657: INFO: Created: latency-svc-4pd8l
May 14 15:46:37.668: INFO: Got endpoints: latency-svc-nghcx [232.030991ms]
May 14 15:46:37.669: INFO: Created: latency-svc-g62f5
May 14 15:46:37.680: INFO: Created: latency-svc-v9dpt
May 14 15:46:37.681: INFO: Created: latency-svc-fxggh
May 14 15:46:37.683: INFO: Got endpoints: latency-svc-w2d9g [238.040582ms]
May 14 15:46:37.698: INFO: Created: latency-svc-sq9qh
May 14 15:46:37.704: INFO: Got endpoints: latency-svc-4pd8l [241.591224ms]
May 14 15:46:37.716: INFO: Created: latency-svc-gld9m
May 14 15:46:37.716: INFO: Created: latency-svc-9rmtg
May 14 15:46:37.726: INFO: Created: latency-svc-5hjm4
May 14 15:46:37.729: INFO: Got endpoints: latency-svc-fxggh [211.640021ms]
May 14 15:46:37.730: INFO: Got endpoints: latency-svc-v9dpt [225.378931ms]
May 14 15:46:37.730: INFO: Got endpoints: latency-svc-g62f5 [252.599809ms]
May 14 15:46:37.739: INFO: Created: latency-svc-b4tsf
May 14 15:46:37.743: INFO: Got endpoints: latency-svc-sq9qh [191.244212ms]
May 14 15:46:37.754: INFO: Got endpoints: latency-svc-9rmtg [175.234477ms]
May 14 15:46:37.760: INFO: Created: latency-svc-fsrmv
May 14 15:46:37.773: INFO: Created: latency-svc-tqbsv
May 14 15:46:37.774: INFO: Created: latency-svc-8svz7
May 14 15:46:37.782: INFO: Created: latency-svc-fdtgh
May 14 15:46:37.784: INFO: Got endpoints: latency-svc-gld9m [204.86444ms]
May 14 15:46:37.796: INFO: Created: latency-svc-hn89k
May 14 15:46:37.798: INFO: Created: latency-svc-4fjp2
May 14 15:46:37.808: INFO: Created: latency-svc-s6qrn
May 14 15:46:37.817: INFO: Got endpoints: latency-svc-5hjm4 [222.138602ms]
May 14 15:46:37.819: INFO: Created: latency-svc-nn8pg
May 14 15:46:37.831: INFO: Created: latency-svc-hrbpm
May 14 15:46:37.835: INFO: Created: latency-svc-n8tmm
May 14 15:46:37.845: INFO: Created: latency-svc-tzgbf
May 14 15:46:37.865: INFO: Created: latency-svc-64wr5
May 14 15:46:37.874: INFO: Created: latency-svc-tk4h4
May 14 15:46:37.878: INFO: Got endpoints: latency-svc-b4tsf [283.624371ms]
May 14 15:46:37.883: INFO: Created: latency-svc-x65nw
May 14 15:46:37.896: INFO: Created: latency-svc-fcvcw
May 14 15:46:37.901: INFO: Got endpoints: latency-svc-fsrmv [283.035997ms]
May 14 15:46:37.917: INFO: Created: latency-svc-2bptz
May 14 15:46:37.953: INFO: Got endpoints: latency-svc-tqbsv [335.517639ms]
May 14 15:46:37.988: INFO: Created: latency-svc-2nk9s
May 14 15:46:38.003: INFO: Got endpoints: latency-svc-8svz7 [357.770114ms]
May 14 15:46:38.022: INFO: Created: latency-svc-gsh9k
May 14 15:46:38.053: INFO: Got endpoints: latency-svc-fdtgh [396.569715ms]
May 14 15:46:38.068: INFO: Created: latency-svc-bdnbt
May 14 15:46:38.102: INFO: Got endpoints: latency-svc-4fjp2 [419.144903ms]
May 14 15:46:38.118: INFO: Created: latency-svc-x4zqc
May 14 15:46:38.151: INFO: Got endpoints: latency-svc-hn89k [482.47479ms]
May 14 15:46:38.163: INFO: Created: latency-svc-fhsdn
May 14 15:46:38.203: INFO: Got endpoints: latency-svc-s6qrn [498.964006ms]
May 14 15:46:38.215: INFO: Created: latency-svc-5p9lx
May 14 15:46:38.251: INFO: Got endpoints: latency-svc-nn8pg [521.889512ms]
May 14 15:46:38.262: INFO: Created: latency-svc-czzm9
May 14 15:46:38.301: INFO: Got endpoints: latency-svc-hrbpm [571.211461ms]
May 14 15:46:38.314: INFO: Created: latency-svc-xzz9b
May 14 15:46:38.353: INFO: Got endpoints: latency-svc-n8tmm [623.719071ms]
May 14 15:46:38.368: INFO: Created: latency-svc-cfzv6
May 14 15:46:38.404: INFO: Got endpoints: latency-svc-tzgbf [660.953997ms]
May 14 15:46:38.421: INFO: Created: latency-svc-hb74q
May 14 15:46:38.454: INFO: Got endpoints: latency-svc-64wr5 [700.014399ms]
May 14 15:46:38.467: INFO: Created: latency-svc-nsrgl
May 14 15:46:38.500: INFO: Got endpoints: latency-svc-tk4h4 [716.381682ms]
May 14 15:46:38.513: INFO: Created: latency-svc-vghv8
May 14 15:46:38.551: INFO: Got endpoints: latency-svc-x65nw [734.40437ms]
May 14 15:46:38.563: INFO: Created: latency-svc-sdrhh
May 14 15:46:38.603: INFO: Got endpoints: latency-svc-fcvcw [724.411598ms]
May 14 15:46:38.614: INFO: Created: latency-svc-g8rnx
May 14 15:46:38.651: INFO: Got endpoints: latency-svc-2bptz [749.511331ms]
May 14 15:46:38.663: INFO: Created: latency-svc-2z9nj
May 14 15:46:38.702: INFO: Got endpoints: latency-svc-2nk9s [748.506728ms]
May 14 15:46:38.716: INFO: Created: latency-svc-mv8q9
May 14 15:46:38.750: INFO: Got endpoints: latency-svc-gsh9k [746.581818ms]
May 14 15:46:38.759: INFO: Created: latency-svc-hl7lf
May 14 15:46:38.802: INFO: Got endpoints: latency-svc-bdnbt [749.259253ms]
May 14 15:46:38.813: INFO: Created: latency-svc-xt8zn
May 14 15:46:38.852: INFO: Got endpoints: latency-svc-x4zqc [749.959227ms]
May 14 15:46:38.863: INFO: Created: latency-svc-zf2n8
May 14 15:46:38.901: INFO: Got endpoints: latency-svc-fhsdn [750.369121ms]
May 14 15:46:38.923: INFO: Created: latency-svc-hbxd9
May 14 15:46:38.952: INFO: Got endpoints: latency-svc-5p9lx [749.035888ms]
May 14 15:46:38.968: INFO: Created: latency-svc-55wqp
May 14 15:46:39.000: INFO: Got endpoints: latency-svc-czzm9 [748.596292ms]
May 14 15:46:39.013: INFO: Created: latency-svc-bj9xm
May 14 15:46:39.057: INFO: Got endpoints: latency-svc-xzz9b [755.874547ms]
May 14 15:46:39.068: INFO: Created: latency-svc-w9nnh
May 14 15:46:39.103: INFO: Got endpoints: latency-svc-cfzv6 [749.629321ms]
May 14 15:46:39.115: INFO: Created: latency-svc-4c47x
May 14 15:46:39.152: INFO: Got endpoints: latency-svc-hb74q [748.231057ms]
May 14 15:46:39.169: INFO: Created: latency-svc-k7hp5
May 14 15:46:39.202: INFO: Got endpoints: latency-svc-nsrgl [748.037163ms]
May 14 15:46:39.215: INFO: Created: latency-svc-hsp5r
May 14 15:46:39.251: INFO: Got endpoints: latency-svc-vghv8 [750.553479ms]
May 14 15:46:39.262: INFO: Created: latency-svc-8bsv5
May 14 15:46:39.302: INFO: Got endpoints: latency-svc-sdrhh [750.757636ms]
May 14 15:46:39.315: INFO: Created: latency-svc-dc89b
May 14 15:46:39.351: INFO: Got endpoints: latency-svc-g8rnx [748.300324ms]
May 14 15:46:39.364: INFO: Created: latency-svc-xdxpb
May 14 15:46:39.401: INFO: Got endpoints: latency-svc-2z9nj [750.349709ms]
May 14 15:46:39.419: INFO: Created: latency-svc-998gs
May 14 15:46:39.450: INFO: Got endpoints: latency-svc-mv8q9 [747.933314ms]
May 14 15:46:39.463: INFO: Created: latency-svc-5fstp
May 14 15:46:39.502: INFO: Got endpoints: latency-svc-hl7lf [752.256067ms]
May 14 15:46:39.513: INFO: Created: latency-svc-gtb7z
May 14 15:46:39.551: INFO: Got endpoints: latency-svc-xt8zn [748.761651ms]
May 14 15:46:39.562: INFO: Created: latency-svc-fqgwt
May 14 15:46:39.601: INFO: Got endpoints: latency-svc-zf2n8 [749.199699ms]
May 14 15:46:39.626: INFO: Created: latency-svc-qmwrx
May 14 15:46:39.651: INFO: Got endpoints: latency-svc-hbxd9 [749.789524ms]
May 14 15:46:39.663: INFO: Created: latency-svc-9mgd4
May 14 15:46:39.702: INFO: Got endpoints: latency-svc-55wqp [749.811215ms]
May 14 15:46:39.712: INFO: Created: latency-svc-8k4sz
May 14 15:46:39.753: INFO: Got endpoints: latency-svc-bj9xm [752.744282ms]
May 14 15:46:39.763: INFO: Created: latency-svc-mx7pp
May 14 15:46:39.801: INFO: Got endpoints: latency-svc-w9nnh [744.321454ms]
May 14 15:46:39.828: INFO: Created: latency-svc-pdbwb
May 14 15:46:39.852: INFO: Got endpoints: latency-svc-4c47x [749.280233ms]
May 14 15:46:39.895: INFO: Created: latency-svc-bfxr6
May 14 15:46:39.906: INFO: Got endpoints: latency-svc-k7hp5 [753.863451ms]
May 14 15:46:39.920: INFO: Created: latency-svc-vmxff
May 14 15:46:39.951: INFO: Got endpoints: latency-svc-hsp5r [748.233872ms]
May 14 15:46:39.978: INFO: Created: latency-svc-mmf2x
May 14 15:46:40.000: INFO: Got endpoints: latency-svc-8bsv5 [749.119164ms]
May 14 15:46:40.015: INFO: Created: latency-svc-jvc4r
May 14 15:46:40.050: INFO: Got endpoints: latency-svc-dc89b [747.996583ms]
May 14 15:46:40.062: INFO: Created: latency-svc-tv56w
May 14 15:46:40.102: INFO: Got endpoints: latency-svc-xdxpb [750.360503ms]
May 14 15:46:40.117: INFO: Created: latency-svc-mlxc9
May 14 15:46:40.153: INFO: Got endpoints: latency-svc-998gs [751.62996ms]
May 14 15:46:40.165: INFO: Created: latency-svc-hz4qt
May 14 15:46:40.200: INFO: Got endpoints: latency-svc-5fstp [750.37729ms]
May 14 15:46:40.213: INFO: Created: latency-svc-xk6m4
May 14 15:46:40.250: INFO: Got endpoints: latency-svc-gtb7z [747.51527ms]
May 14 15:46:40.262: INFO: Created: latency-svc-gc72x
May 14 15:46:40.301: INFO: Got endpoints: latency-svc-fqgwt [749.880396ms]
May 14 15:46:40.315: INFO: Created: latency-svc-t8dck
May 14 15:46:40.352: INFO: Got endpoints: latency-svc-qmwrx [750.661319ms]
May 14 15:46:40.365: INFO: Created: latency-svc-gccg6
May 14 15:46:40.401: INFO: Got endpoints: latency-svc-9mgd4 [749.733304ms]
May 14 15:46:40.412: INFO: Created: latency-svc-dd5rq
May 14 15:46:40.450: INFO: Got endpoints: latency-svc-8k4sz [747.974194ms]
May 14 15:46:40.463: INFO: Created: latency-svc-d82b8
May 14 15:46:40.503: INFO: Got endpoints: latency-svc-mx7pp [749.572425ms]
May 14 15:46:40.522: INFO: Created: latency-svc-66gts
May 14 15:46:40.554: INFO: Got endpoints: latency-svc-pdbwb [752.474112ms]
May 14 15:46:40.571: INFO: Created: latency-svc-vl6vp
May 14 15:46:40.638: INFO: Got endpoints: latency-svc-bfxr6 [785.535394ms]
May 14 15:46:40.655: INFO: Created: latency-svc-j72cz
May 14 15:46:40.656: INFO: Got endpoints: latency-svc-vmxff [750.253965ms]
May 14 15:46:40.673: INFO: Created: latency-svc-5r489
May 14 15:46:40.701: INFO: Got endpoints: latency-svc-mmf2x [749.766163ms]
May 14 15:46:40.713: INFO: Created: latency-svc-7bl9z
May 14 15:46:40.750: INFO: Got endpoints: latency-svc-jvc4r [750.275101ms]
May 14 15:46:40.762: INFO: Created: latency-svc-h6zbw
May 14 15:46:40.802: INFO: Got endpoints: latency-svc-tv56w [752.12304ms]
May 14 15:46:40.819: INFO: Created: latency-svc-bh99q
May 14 15:46:40.852: INFO: Got endpoints: latency-svc-mlxc9 [750.088305ms]
May 14 15:46:40.862: INFO: Created: latency-svc-qnvxf
May 14 15:46:40.901: INFO: Got endpoints: latency-svc-hz4qt [748.435824ms]
May 14 15:46:40.917: INFO: Created: latency-svc-f6slt
May 14 15:46:40.950: INFO: Got endpoints: latency-svc-xk6m4 [749.083186ms]
May 14 15:46:40.972: INFO: Created: latency-svc-dnt7z
May 14 15:46:41.000: INFO: Got endpoints: latency-svc-gc72x [750.09101ms]
May 14 15:46:41.018: INFO: Created: latency-svc-9tlb2
May 14 15:46:41.051: INFO: Got endpoints: latency-svc-t8dck [749.779998ms]
May 14 15:46:41.067: INFO: Created: latency-svc-7rtk2
May 14 15:46:41.102: INFO: Got endpoints: latency-svc-gccg6 [750.427887ms]
May 14 15:46:41.113: INFO: Created: latency-svc-n225c
May 14 15:46:41.153: INFO: Got endpoints: latency-svc-dd5rq [751.717161ms]
May 14 15:46:41.165: INFO: Created: latency-svc-bnsqq
May 14 15:46:41.200: INFO: Got endpoints: latency-svc-d82b8 [749.518961ms]
May 14 15:46:41.213: INFO: Created: latency-svc-8wcdb
May 14 15:46:41.253: INFO: Got endpoints: latency-svc-66gts [750.58553ms]
May 14 15:46:41.266: INFO: Created: latency-svc-kvzt7
May 14 15:46:41.300: INFO: Got endpoints: latency-svc-vl6vp [746.519371ms]
May 14 15:46:41.314: INFO: Created: latency-svc-s5chx
May 14 15:46:41.353: INFO: Got endpoints: latency-svc-j72cz [714.86634ms]
May 14 15:46:41.367: INFO: Created: latency-svc-fws9v
May 14 15:46:41.401: INFO: Got endpoints: latency-svc-5r489 [744.613885ms]
May 14 15:46:41.415: INFO: Created: latency-svc-225lg
May 14 15:46:41.450: INFO: Got endpoints: latency-svc-7bl9z [749.540204ms]
May 14 15:46:41.466: INFO: Created: latency-svc-9sq88
May 14 15:46:41.502: INFO: Got endpoints: latency-svc-h6zbw [751.305862ms]
May 14 15:46:41.515: INFO: Created: latency-svc-z5t67
May 14 15:46:41.553: INFO: Got endpoints: latency-svc-bh99q [750.026033ms]
May 14 15:46:41.566: INFO: Created: latency-svc-95tsn
May 14 15:46:41.605: INFO: Got endpoints: latency-svc-qnvxf [752.86933ms]
May 14 15:46:41.617: INFO: Created: latency-svc-md6zb
May 14 15:46:41.656: INFO: Got endpoints: latency-svc-f6slt [754.31667ms]
May 14 15:46:41.666: INFO: Created: latency-svc-x5zd5
May 14 15:46:41.753: INFO: Got endpoints: latency-svc-dnt7z [803.525092ms]
May 14 15:46:41.760: INFO: Got endpoints: latency-svc-9tlb2 [759.976456ms]
May 14 15:46:41.766: INFO: Created: latency-svc-756f4
May 14 15:46:41.777: INFO: Created: latency-svc-x8jlr
May 14 15:46:41.801: INFO: Got endpoints: latency-svc-7rtk2 [749.772167ms]
May 14 15:46:41.812: INFO: Created: latency-svc-wh5bf
May 14 15:46:41.851: INFO: Got endpoints: latency-svc-n225c [748.082153ms]
May 14 15:46:41.862: INFO: Created: latency-svc-jr69s
May 14 15:46:41.909: INFO: Got endpoints: latency-svc-bnsqq [755.9058ms]
May 14 15:46:41.924: INFO: Created: latency-svc-ssbsx
May 14 15:46:41.951: INFO: Got endpoints: latency-svc-8wcdb [751.395061ms]
May 14 15:46:41.969: INFO: Created: latency-svc-7cf7l
May 14 15:46:42.001: INFO: Got endpoints: latency-svc-kvzt7 [747.875931ms]
May 14 15:46:42.012: INFO: Created: latency-svc-tlgdd
May 14 15:46:42.051: INFO: Got endpoints: latency-svc-s5chx [750.448601ms]
May 14 15:46:42.064: INFO: Created: latency-svc-b22vd
May 14 15:46:42.100: INFO: Got endpoints: latency-svc-fws9v [747.294936ms]
May 14 15:46:42.111: INFO: Created: latency-svc-6s2sw
May 14 15:46:42.153: INFO: Got endpoints: latency-svc-225lg [751.866157ms]
May 14 15:46:42.166: INFO: Created: latency-svc-vpxrg
May 14 15:46:42.202: INFO: Got endpoints: latency-svc-9sq88 [751.762199ms]
May 14 15:46:42.213: INFO: Created: latency-svc-t4vrw
May 14 15:46:42.251: INFO: Got endpoints: latency-svc-z5t67 [749.311234ms]
May 14 15:46:42.267: INFO: Created: latency-svc-mhzr9
May 14 15:46:42.300: INFO: Got endpoints: latency-svc-95tsn [747.338649ms]
May 14 15:46:42.313: INFO: Created: latency-svc-q9hhh
May 14 15:46:42.350: INFO: Got endpoints: latency-svc-md6zb [745.306965ms]
May 14 15:46:42.361: INFO: Created: latency-svc-sqh5h
May 14 15:46:42.401: INFO: Got endpoints: latency-svc-x5zd5 [745.590089ms]
May 14 15:46:42.414: INFO: Created: latency-svc-kl9tv
May 14 15:46:42.450: INFO: Got endpoints: latency-svc-756f4 [696.869589ms]
May 14 15:46:42.461: INFO: Created: latency-svc-cwkcl
May 14 15:46:42.500: INFO: Got endpoints: latency-svc-x8jlr [739.375397ms]
May 14 15:46:42.511: INFO: Created: latency-svc-9vw2k
May 14 15:46:42.550: INFO: Got endpoints: latency-svc-wh5bf [749.206284ms]
May 14 15:46:42.564: INFO: Created: latency-svc-tdnnz
May 14 15:46:42.600: INFO: Got endpoints: latency-svc-jr69s [748.889615ms]
May 14 15:46:42.617: INFO: Created: latency-svc-mtg57
May 14 15:46:42.651: INFO: Got endpoints: latency-svc-ssbsx [741.95202ms]
May 14 15:46:42.662: INFO: Created: latency-svc-7f967
May 14 15:46:42.701: INFO: Got endpoints: latency-svc-7cf7l [750.31364ms]
May 14 15:46:42.712: INFO: Created: latency-svc-lfghp
May 14 15:46:42.753: INFO: Got endpoints: latency-svc-tlgdd [751.946037ms]
May 14 15:46:42.763: INFO: Created: latency-svc-czkhx
May 14 15:46:42.804: INFO: Got endpoints: latency-svc-b22vd [752.650286ms]
May 14 15:46:42.836: INFO: Created: latency-svc-hsprm
May 14 15:46:42.850: INFO: Got endpoints: latency-svc-6s2sw [749.195765ms]
May 14 15:46:42.860: INFO: Created: latency-svc-9h4hm
May 14 15:46:42.900: INFO: Got endpoints: latency-svc-vpxrg [746.947106ms]
May 14 15:46:42.922: INFO: Created: latency-svc-clr27
May 14 15:46:42.950: INFO: Got endpoints: latency-svc-t4vrw [748.002232ms]
May 14 15:46:42.961: INFO: Created: latency-svc-w6blp
May 14 15:46:43.000: INFO: Got endpoints: latency-svc-mhzr9 [748.706927ms]
May 14 15:46:43.013: INFO: Created: latency-svc-qrvd2
May 14 15:46:43.052: INFO: Got endpoints: latency-svc-q9hhh [751.861321ms]
May 14 15:46:43.063: INFO: Created: latency-svc-2jtn4
May 14 15:46:43.101: INFO: Got endpoints: latency-svc-sqh5h [750.611027ms]
May 14 15:46:43.112: INFO: Created: latency-svc-kg9dx
May 14 15:46:43.151: INFO: Got endpoints: latency-svc-kl9tv [749.048484ms]
May 14 15:46:43.160: INFO: Created: latency-svc-fnjqz
May 14 15:46:43.202: INFO: Got endpoints: latency-svc-cwkcl [751.684708ms]
May 14 15:46:43.214: INFO: Created: latency-svc-h5tjp
May 14 15:46:43.249: INFO: Got endpoints: latency-svc-9vw2k [749.907681ms]
May 14 15:46:43.264: INFO: Created: latency-svc-cgvlt
May 14 15:46:43.301: INFO: Got endpoints: latency-svc-tdnnz [751.14144ms]
May 14 15:46:43.312: INFO: Created: latency-svc-jz2hv
May 14 15:46:43.351: INFO: Got endpoints: latency-svc-mtg57 [751.71413ms]
May 14 15:46:43.364: INFO: Created: latency-svc-842bf
May 14 15:46:43.400: INFO: Got endpoints: latency-svc-7f967 [749.029857ms]
May 14 15:46:43.412: INFO: Created: latency-svc-fllsb
May 14 15:46:43.450: INFO: Got endpoints: latency-svc-lfghp [748.333753ms]
May 14 15:46:43.460: INFO: Created: latency-svc-s9jhn
May 14 15:46:43.501: INFO: Got endpoints: latency-svc-czkhx [747.482275ms]
May 14 15:46:43.512: INFO: Created: latency-svc-4dgng
May 14 15:46:43.551: INFO: Got endpoints: latency-svc-hsprm [747.313127ms]
May 14 15:46:43.563: INFO: Created: latency-svc-cxxrj
May 14 15:46:43.603: INFO: Got endpoints: latency-svc-9h4hm [753.322894ms]
May 14 15:46:43.614: INFO: Created: latency-svc-84t84
May 14 15:46:43.650: INFO: Got endpoints: latency-svc-clr27 [749.740708ms]
May 14 15:46:43.663: INFO: Created: latency-svc-l98mk
May 14 15:46:43.701: INFO: Got endpoints: latency-svc-w6blp [750.904226ms]
May 14 15:46:43.712: INFO: Created: latency-svc-22jxz
May 14 15:46:43.752: INFO: Got endpoints: latency-svc-qrvd2 [751.784054ms]
May 14 15:46:43.763: INFO: Created: latency-svc-lnkz9
May 14 15:46:43.801: INFO: Got endpoints: latency-svc-2jtn4 [748.903417ms]
May 14 15:46:43.815: INFO: Created: latency-svc-866m2
May 14 15:46:43.852: INFO: Got endpoints: latency-svc-kg9dx [750.851793ms]
May 14 15:46:43.865: INFO: Created: latency-svc-p268g
May 14 15:46:43.901: INFO: Got endpoints: latency-svc-fnjqz [749.966296ms]
May 14 15:46:43.915: INFO: Created: latency-svc-7f9g5
May 14 15:46:43.952: INFO: Got endpoints: latency-svc-h5tjp [750.057323ms]
May 14 15:46:43.969: INFO: Created: latency-svc-5cp98
May 14 15:46:44.000: INFO: Got endpoints: latency-svc-cgvlt [750.407026ms]
May 14 15:46:44.013: INFO: Created: latency-svc-z5wbb
May 14 15:46:44.050: INFO: Got endpoints: latency-svc-jz2hv [748.839282ms]
May 14 15:46:44.064: INFO: Created: latency-svc-9zwsf
May 14 15:46:44.101: INFO: Got endpoints: latency-svc-842bf [749.561853ms]
May 14 15:46:44.114: INFO: Created: latency-svc-mrrr8
May 14 15:46:44.150: INFO: Got endpoints: latency-svc-fllsb [749.966546ms]
May 14 15:46:44.164: INFO: Created: latency-svc-k55sk
May 14 15:46:44.200: INFO: Got endpoints: latency-svc-s9jhn [750.277293ms]
May 14 15:46:44.211: INFO: Created: latency-svc-f9x4m
May 14 15:46:44.251: INFO: Got endpoints: latency-svc-4dgng [750.210991ms]
May 14 15:46:44.261: INFO: Created: latency-svc-vmfcs
May 14 15:46:44.300: INFO: Got endpoints: latency-svc-cxxrj [749.147015ms]
May 14 15:46:44.313: INFO: Created: latency-svc-n55x6
May 14 15:46:44.352: INFO: Got endpoints: latency-svc-84t84 [748.57697ms]
May 14 15:46:44.363: INFO: Created: latency-svc-j7pl7
May 14 15:46:44.402: INFO: Got endpoints: latency-svc-l98mk [751.689433ms]
May 14 15:46:44.414: INFO: Created: latency-svc-hnv2v
May 14 15:46:44.451: INFO: Got endpoints: latency-svc-22jxz [750.385344ms]
May 14 15:46:44.461: INFO: Created: latency-svc-hl72g
May 14 15:46:44.502: INFO: Got endpoints: latency-svc-lnkz9 [749.796804ms]
May 14 15:46:44.514: INFO: Created: latency-svc-pkwnx
May 14 15:46:44.554: INFO: Got endpoints: latency-svc-866m2 [753.401981ms]
May 14 15:46:44.564: INFO: Created: latency-svc-mzxmp
May 14 15:46:44.600: INFO: Got endpoints: latency-svc-p268g [748.259269ms]
May 14 15:46:44.613: INFO: Created: latency-svc-4jr4s
May 14 15:46:44.651: INFO: Got endpoints: latency-svc-7f9g5 [749.851403ms]
May 14 15:46:44.661: INFO: Created: latency-svc-wl25p
May 14 15:46:44.701: INFO: Got endpoints: latency-svc-5cp98 [749.218975ms]
May 14 15:46:44.713: INFO: Created: latency-svc-r8d8q
May 14 15:46:44.750: INFO: Got endpoints: latency-svc-z5wbb [749.660876ms]
May 14 15:46:44.762: INFO: Created: latency-svc-pk7dn
May 14 15:46:44.800: INFO: Got endpoints: latency-svc-9zwsf [749.902243ms]
May 14 15:46:44.813: INFO: Created: latency-svc-7pm45
May 14 15:46:44.851: INFO: Got endpoints: latency-svc-mrrr8 [749.927662ms]
May 14 15:46:44.865: INFO: Created: latency-svc-sxmmz
May 14 15:46:44.901: INFO: Got endpoints: latency-svc-k55sk [751.523569ms]
May 14 15:46:44.916: INFO: Created: latency-svc-7zmtn
May 14 15:46:44.954: INFO: Got endpoints: latency-svc-f9x4m [753.351111ms]
May 14 15:46:44.967: INFO: Created: latency-svc-8bx7v
May 14 15:46:45.003: INFO: Got endpoints: latency-svc-vmfcs [751.989209ms]
May 14 15:46:45.013: INFO: Created: latency-svc-v7grx
May 14 15:46:45.050: INFO: Got endpoints: latency-svc-n55x6 [749.955488ms]
May 14 15:46:45.101: INFO: Got endpoints: latency-svc-j7pl7 [749.766153ms]
May 14 15:46:45.152: INFO: Got endpoints: latency-svc-hnv2v [750.326363ms]
May 14 15:46:45.201: INFO: Got endpoints: latency-svc-hl72g [749.291651ms]
May 14 15:46:45.251: INFO: Got endpoints: latency-svc-pkwnx [749.349232ms]
May 14 15:46:45.300: INFO: Got endpoints: latency-svc-mzxmp [745.893599ms]
May 14 15:46:45.352: INFO: Got endpoints: latency-svc-4jr4s [752.30366ms]
May 14 15:46:45.400: INFO: Got endpoints: latency-svc-wl25p [748.791043ms]
May 14 15:46:45.450: INFO: Got endpoints: latency-svc-r8d8q [748.912039ms]
May 14 15:46:45.500: INFO: Got endpoints: latency-svc-pk7dn [750.281039ms]
May 14 15:46:45.550: INFO: Got endpoints: latency-svc-7pm45 [750.128896ms]
May 14 15:46:45.601: INFO: Got endpoints: latency-svc-sxmmz [750.281266ms]
May 14 15:46:45.651: INFO: Got endpoints: latency-svc-7zmtn [748.974151ms]
May 14 15:46:45.700: INFO: Got endpoints: latency-svc-8bx7v [746.825657ms]
May 14 15:46:45.751: INFO: Got endpoints: latency-svc-v7grx [748.227736ms]
May 14 15:46:45.751: INFO: Latencies: [28.047992ms 58.393963ms 58.489403ms 65.363563ms 80.91667ms 89.82575ms 117.635701ms 117.715194ms 126.345033ms 147.280261ms 159.759895ms 159.912089ms 172.468689ms 175.234477ms 180.98565ms 190.691351ms 191.244212ms 191.63653ms 191.747405ms 191.750221ms 194.035117ms 194.919817ms 204.86444ms 209.045914ms 211.640021ms 213.74676ms 218.303513ms 219.969327ms 220.602972ms 220.642084ms 222.138602ms 225.378931ms 228.711754ms 229.504083ms 230.91829ms 232.030991ms 238.040582ms 241.591224ms 242.093423ms 246.932692ms 252.599809ms 283.035997ms 283.624371ms 335.517639ms 357.770114ms 396.569715ms 419.144903ms 482.47479ms 498.964006ms 521.889512ms 571.211461ms 623.719071ms 660.953997ms 696.869589ms 700.014399ms 714.86634ms 716.381682ms 724.411598ms 734.40437ms 739.375397ms 741.95202ms 744.321454ms 744.613885ms 745.306965ms 745.590089ms 745.893599ms 746.519371ms 746.581818ms 746.825657ms 746.947106ms 747.294936ms 747.313127ms 747.338649ms 747.482275ms 747.51527ms 747.875931ms 747.933314ms 747.974194ms 747.996583ms 748.002232ms 748.037163ms 748.082153ms 748.227736ms 748.231057ms 748.233872ms 748.259269ms 748.300324ms 748.333753ms 748.435824ms 748.506728ms 748.57697ms 748.596292ms 748.706927ms 748.761651ms 748.791043ms 748.839282ms 748.889615ms 748.903417ms 748.912039ms 748.974151ms 749.029857ms 749.035888ms 749.048484ms 749.083186ms 749.119164ms 749.147015ms 749.195765ms 749.199699ms 749.206284ms 749.218975ms 749.259253ms 749.280233ms 749.291651ms 749.311234ms 749.349232ms 749.511331ms 749.518961ms 749.540204ms 749.561853ms 749.572425ms 749.629321ms 749.660876ms 749.733304ms 749.740708ms 749.766153ms 749.766163ms 749.772167ms 749.779998ms 749.789524ms 749.796804ms 749.811215ms 749.851403ms 749.880396ms 749.902243ms 749.907681ms 749.927662ms 749.955488ms 749.959227ms 749.966296ms 749.966546ms 750.026033ms 750.057323ms 750.088305ms 750.09101ms 750.128896ms 750.210991ms 750.253965ms 750.275101ms 750.277293ms 750.281039ms 750.281266ms 750.31364ms 750.326363ms 750.349709ms 750.360503ms 750.369121ms 750.37729ms 750.385344ms 750.407026ms 750.427887ms 750.448601ms 750.553479ms 750.58553ms 750.611027ms 750.661319ms 750.757636ms 750.851793ms 750.904226ms 751.14144ms 751.305862ms 751.395061ms 751.523569ms 751.62996ms 751.684708ms 751.689433ms 751.71413ms 751.717161ms 751.762199ms 751.784054ms 751.861321ms 751.866157ms 751.946037ms 751.989209ms 752.12304ms 752.256067ms 752.30366ms 752.474112ms 752.650286ms 752.744282ms 752.86933ms 753.322894ms 753.351111ms 753.401981ms 753.863451ms 754.31667ms 755.874547ms 755.9058ms 759.976456ms 785.535394ms 803.525092ms]
May 14 15:46:45.751: INFO: 50 %ile: 749.029857ms
May 14 15:46:45.751: INFO: 90 %ile: 751.866157ms
May 14 15:46:45.751: INFO: 99 %ile: 785.535394ms
May 14 15:46:45.751: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:46:45.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-hkjrm" for this suite.
May 14 15:46:56.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:46:58.249: INFO: namespace: e2e-tests-svc-latency-hkjrm, resource: bindings, ignored listing per whitelist
May 14 15:46:59.442: INFO: namespace e2e-tests-svc-latency-hkjrm deletion completed in 13.595778017s

• [SLOW TEST:25.035 seconds]
[sig-network] Service endpoints latency
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:46:59.442: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:36
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test hostPath mode
May 14 15:46:59.720: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-t9x94" to be "success or failure"
May 14 15:46:59.816: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 95.872145ms
May 14 15:47:01.819: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.099309367s
STEP: Saw pod success
May 14 15:47:01.819: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 14 15:47:01.821: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 14 15:47:02.019: INFO: Waiting for pod pod-host-path-test to disappear
May 14 15:47:02.110: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:47:02.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-t9x94" for this suite.
May 14 15:47:08.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:47:11.091: INFO: namespace: e2e-tests-hostpath-t9x94, resource: bindings, ignored listing per whitelist
May 14 15:47:11.354: INFO: namespace e2e-tests-hostpath-t9x94 deletion completed in 9.24094744s

• [SLOW TEST:11.912 seconds]
[sig-storage] HostPath
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:33
  should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:47:11.354: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-g6pr6
[It] Should recreate evicted statefulset [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-g6pr6
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-g6pr6
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-g6pr6
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-g6pr6
May 14 15:47:16.026: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-g6pr6, name: ss-0, uid: 8c3500ec-765f-11e9-a4a8-42010a8c006e, status phase: Pending. Waiting for statefulset controller to delete.
May 14 15:47:16.357: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-g6pr6, name: ss-0, uid: 8c3500ec-765f-11e9-a4a8-42010a8c006e, status phase: Failed. Waiting for statefulset controller to delete.
May 14 15:47:16.368: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-g6pr6, name: ss-0, uid: 8c3500ec-765f-11e9-a4a8-42010a8c006e, status phase: Failed. Waiting for statefulset controller to delete.
May 14 15:47:16.371: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-g6pr6
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-g6pr6
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-g6pr6 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 14 15:47:20.563: INFO: Deleting all statefulset in ns e2e-tests-statefulset-g6pr6
May 14 15:47:20.664: INFO: Scaling statefulset ss to 0
May 14 15:47:30.953: INFO: Waiting for statefulset status.replicas updated to 0
May 14 15:47:30.955: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:47:31.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-g6pr6" for this suite.
May 14 15:47:37.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:47:37.747: INFO: namespace: e2e-tests-statefulset-g6pr6, resource: bindings, ignored listing per whitelist
May 14 15:47:40.185: INFO: namespace e2e-tests-statefulset-g6pr6 deletion completed in 8.959164489s

• [SLOW TEST:28.831 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Should recreate evicted statefulset [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:47:40.186: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
May 14 15:47:43.202: INFO: Successfully updated pod "annotationupdate9ad58313-765f-11e9-96ed-42d4de3e15aa"
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:47:47.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-59zlr" for this suite.
May 14 15:48:09.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:48:09.798: INFO: namespace: e2e-tests-projected-59zlr, resource: bindings, ignored listing per whitelist
May 14 15:48:12.566: INFO: namespace e2e-tests-projected-59zlr deletion completed in 25.333781393s

• [SLOW TEST:32.380 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:48:12.566: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if v1 is in available api versions  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: validating api versions
May 14 15:48:12.711: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 api-versions'
May 14 15:48:12.823: INFO: stderr: ""
May 14 15:48:12.823: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncloud.google.com/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscalingpolicy.kope.io/v1alpha1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:48:12.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gvfn7" for this suite.
May 14 15:48:19.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:48:19.118: INFO: namespace: e2e-tests-kubectl-gvfn7, resource: bindings, ignored listing per whitelist
May 14 15:48:22.316: INFO: namespace e2e-tests-kubectl-gvfn7 deletion completed in 9.489983419s

• [SLOW TEST:9.750 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if v1 is in available api versions  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:48:22.316: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 14 15:48:24.876: INFO: Waiting up to 5m0s for pod "client-envvars-b55fac8b-765f-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-pods-rw4r9" to be "success or failure"
May 14 15:48:24.970: INFO: Pod "client-envvars-b55fac8b-765f-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 94.453962ms
May 14 15:48:27.126: INFO: Pod "client-envvars-b55fac8b-765f-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.250605879s
May 14 15:48:29.129: INFO: Pod "client-envvars-b55fac8b-765f-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.253905151s
STEP: Saw pod success
May 14 15:48:29.130: INFO: Pod "client-envvars-b55fac8b-765f-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:48:29.133: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq pod client-envvars-b55fac8b-765f-11e9-96ed-42d4de3e15aa container env3cont: <nil>
STEP: delete the pod
May 14 15:48:29.343: INFO: Waiting for pod client-envvars-b55fac8b-765f-11e9-96ed-42d4de3e15aa to disappear
May 14 15:48:29.434: INFO: Pod client-envvars-b55fac8b-765f-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:48:29.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rw4r9" for this suite.
May 14 15:48:51.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:48:54.677: INFO: namespace: e2e-tests-pods-rw4r9, resource: bindings, ignored listing per whitelist
May 14 15:48:54.763: INFO: namespace e2e-tests-pods-rw4r9 deletion completed in 25.245049958s

• [SLOW TEST:32.447 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:48:54.763: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's args
May 14 15:48:55.106: INFO: Waiting up to 5m0s for pod "var-expansion-c75a11f2-765f-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-var-expansion-tbwvv" to be "success or failure"
May 14 15:48:55.198: INFO: Pod "var-expansion-c75a11f2-765f-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 91.27955ms
May 14 15:48:57.201: INFO: Pod "var-expansion-c75a11f2-765f-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.094668739s
STEP: Saw pod success
May 14 15:48:57.201: INFO: Pod "var-expansion-c75a11f2-765f-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:48:57.203: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod var-expansion-c75a11f2-765f-11e9-96ed-42d4de3e15aa container dapi-container: <nil>
STEP: delete the pod
May 14 15:48:57.396: INFO: Waiting for pod var-expansion-c75a11f2-765f-11e9-96ed-42d4de3e15aa to disappear
May 14 15:48:57.480: INFO: Pod var-expansion-c75a11f2-765f-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:48:57.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-tbwvv" for this suite.
May 14 15:49:03.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:49:05.975: INFO: namespace: e2e-tests-var-expansion-tbwvv, resource: bindings, ignored listing per whitelist
May 14 15:49:06.831: INFO: namespace e2e-tests-var-expansion-tbwvv deletion completed in 9.348805888s

• [SLOW TEST:12.068 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:49:06.832: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test env composition
May 14 15:49:07.102: INFO: Waiting up to 5m0s for pod "var-expansion-ce81d300-765f-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-var-expansion-4ngml" to be "success or failure"
May 14 15:49:07.193: INFO: Pod "var-expansion-ce81d300-765f-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 90.572239ms
May 14 15:49:09.196: INFO: Pod "var-expansion-ce81d300-765f-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.093930448s
STEP: Saw pod success
May 14 15:49:09.196: INFO: Pod "var-expansion-ce81d300-765f-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:49:09.198: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod var-expansion-ce81d300-765f-11e9-96ed-42d4de3e15aa container dapi-container: <nil>
STEP: delete the pod
May 14 15:49:09.392: INFO: Waiting for pod var-expansion-ce81d300-765f-11e9-96ed-42d4de3e15aa to disappear
May 14 15:49:09.479: INFO: Pod var-expansion-ce81d300-765f-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:49:09.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-4ngml" for this suite.
May 14 15:49:15.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:49:17.178: INFO: namespace: e2e-tests-var-expansion-4ngml, resource: bindings, ignored listing per whitelist
May 14 15:49:18.905: INFO: namespace e2e-tests-var-expansion-4ngml deletion completed in 9.411313611s

• [SLOW TEST:12.074 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:49:18.906: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test substitution in container's command
May 14 15:49:19.334: INFO: Waiting up to 5m0s for pod "var-expansion-d5c9c1b5-765f-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-var-expansion-f9dtb" to be "success or failure"
May 14 15:49:19.427: INFO: Pod "var-expansion-d5c9c1b5-765f-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 92.941293ms
May 14 15:49:21.431: INFO: Pod "var-expansion-d5c9c1b5-765f-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.096423257s
STEP: Saw pod success
May 14 15:49:21.431: INFO: Pod "var-expansion-d5c9c1b5-765f-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:49:21.434: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod var-expansion-d5c9c1b5-765f-11e9-96ed-42d4de3e15aa container dapi-container: <nil>
STEP: delete the pod
May 14 15:49:21.639: INFO: Waiting for pod var-expansion-d5c9c1b5-765f-11e9-96ed-42d4de3e15aa to disappear
May 14 15:49:21.734: INFO: Pod var-expansion-d5c9c1b5-765f-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:49:21.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-f9dtb" for this suite.
May 14 15:49:27.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:49:31.042: INFO: namespace: e2e-tests-var-expansion-f9dtb, resource: bindings, ignored listing per whitelist
May 14 15:49:31.042: INFO: namespace e2e-tests-var-expansion-f9dtb deletion completed in 9.304459046s

• [SLOW TEST:12.136 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:49:31.042: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-dcea3f0c-765f-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 15:49:31.375: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dcf88398-765f-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-f7nnd" to be "success or failure"
May 14 15:49:31.468: INFO: Pod "pod-projected-configmaps-dcf88398-765f-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 92.722049ms
May 14 15:49:33.471: INFO: Pod "pod-projected-configmaps-dcf88398-765f-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.096028835s
STEP: Saw pod success
May 14 15:49:33.471: INFO: Pod "pod-projected-configmaps-dcf88398-765f-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:49:33.473: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-configmaps-dcf88398-765f-11e9-96ed-42d4de3e15aa container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 15:49:33.662: INFO: Waiting for pod pod-projected-configmaps-dcf88398-765f-11e9-96ed-42d4de3e15aa to disappear
May 14 15:49:33.751: INFO: Pod pod-projected-configmaps-dcf88398-765f-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:49:33.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f7nnd" for this suite.
May 14 15:49:39.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:49:39.984: INFO: namespace: e2e-tests-projected-f7nnd, resource: bindings, ignored listing per whitelist
May 14 15:49:42.944: INFO: namespace e2e-tests-projected-f7nnd deletion completed in 9.190204973s

• [SLOW TEST:11.902 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:49:42.944: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check is all data is printed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 14 15:49:43.078: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 version'
May 14 15:49:43.187: INFO: stderr: ""
May 14 15:49:43.187: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11+\", GitVersion:\"v1.11.11-beta.0.1+9016740a6ffe91\", GitCommit:\"9016740a6ffe91bb29824f80c34087b993903bd6\", GitTreeState:\"clean\", BuildDate:\"2019-05-01T22:52:44Z\", GoVersion:\"go1.10.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"11+\", GitVersion:\"v1.11.8-gke.6\", GitCommit:\"394ee507d00f15a63cef577a14026096c310698e\", GitTreeState:\"clean\", BuildDate:\"2019-03-30T19:31:43Z\", GoVersion:\"go1.10.8b4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:49:43.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-56zb4" for this suite.
May 14 15:49:49.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:49:49.780: INFO: namespace: e2e-tests-kubectl-56zb4, resource: bindings, ignored listing per whitelist
May 14 15:49:52.414: INFO: namespace e2e-tests-kubectl-56zb4 deletion completed in 9.222771554s

• [SLOW TEST:9.470 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check is all data is printed  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:49:52.414: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
May 14 15:49:52.564: INFO: Waiting up to 1m0s for all nodes to be ready
May 14 15:50:52.670: INFO: Waiting for terminating namespaces to be deleted...
May 14 15:50:52.870: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 14 15:50:53.138: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 14 15:50:53.138: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
May 14 15:50:53.143: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 14 15:50:53.143: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk before test
May 14 15:50:53.240: INFO: prometheus-to-sd-6kt4f from kube-system started at 2019-05-14 15:06:34 +0000 UTC (1 container statuses recorded)
May 14 15:50:53.240: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 15:50:53.240: INFO: metrics-server-v0.2.1-fd596d746-dpxml from kube-system started at 2019-05-14 15:07:03 +0000 UTC (2 container statuses recorded)
May 14 15:50:53.240: INFO: 	Container metrics-server ready: true, restart count 0
May 14 15:50:53.240: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 14 15:50:53.240: INFO: kube-proxy-gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk from kube-system started at <nil> (0 container statuses recorded)
May 14 15:50:53.240: INFO: fluentd-gcp-v3.2.0-2d4fx from kube-system started at 2019-05-14 15:07:05 +0000 UTC (2 container statuses recorded)
May 14 15:50:53.240: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 14 15:50:53.240: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 14 15:50:53.240: INFO: heapster-v1.6.0-beta.1-f7c96fb9f-4lh6l from kube-system started at 2019-05-14 15:07:07 +0000 UTC (3 container statuses recorded)
May 14 15:50:53.240: INFO: 	Container heapster ready: true, restart count 0
May 14 15:50:53.241: INFO: 	Container heapster-nanny ready: true, restart count 0
May 14 15:50:53.241: INFO: 	Container prom-to-sd ready: true, restart count 0
May 14 15:50:53.241: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq before test
May 14 15:50:53.331: INFO: kube-dns-785fdb56c-w2llr from kube-system started at 2019-05-14 15:06:57 +0000 UTC (4 container statuses recorded)
May 14 15:50:53.331: INFO: 	Container dnsmasq ready: true, restart count 0
May 14 15:50:53.331: INFO: 	Container kubedns ready: true, restart count 0
May 14 15:50:53.331: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 15:50:53.331: INFO: 	Container sidecar ready: true, restart count 0
May 14 15:50:53.331: INFO: prometheus-to-sd-gcjjw from kube-system started at 2019-05-14 15:06:36 +0000 UTC (1 container statuses recorded)
May 14 15:50:53.331: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 15:50:53.331: INFO: fluentd-gcp-v3.2.0-kjzgl from kube-system started at 2019-05-14 15:07:05 +0000 UTC (2 container statuses recorded)
May 14 15:50:53.331: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 14 15:50:53.331: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 14 15:50:53.331: INFO: kube-proxy-gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq from kube-system started at <nil> (0 container statuses recorded)
May 14 15:50:53.331: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m before test
May 14 15:50:53.438: INFO: event-exporter-v0.2.3-767cfb76f9-qbjbv from kube-system started at 2019-05-14 15:06:54 +0000 UTC (2 container statuses recorded)
May 14 15:50:53.439: INFO: 	Container event-exporter ready: true, restart count 0
May 14 15:50:53.439: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 14 15:50:53.439: INFO: l7-default-backend-7ff48cffd7-7dcfl from kube-system started at 2019-05-14 15:06:54 +0000 UTC (1 container statuses recorded)
May 14 15:50:53.439: INFO: 	Container default-http-backend ready: true, restart count 0
May 14 15:50:53.439: INFO: fluentd-gcp-v3.2.0-96cdk from kube-system started at 2019-05-14 15:07:10 +0000 UTC (2 container statuses recorded)
May 14 15:50:53.439: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 14 15:50:53.439: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 14 15:50:53.439: INFO: kube-dns-785fdb56c-zq2ht from kube-system started at 2019-05-14 15:06:54 +0000 UTC (4 container statuses recorded)
May 14 15:50:53.439: INFO: 	Container dnsmasq ready: true, restart count 0
May 14 15:50:53.439: INFO: 	Container kubedns ready: true, restart count 0
May 14 15:50:53.439: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 15:50:53.439: INFO: 	Container sidecar ready: true, restart count 0
May 14 15:50:53.439: INFO: kube-dns-autoscaler-67c97c87fb-6fsr5 from kube-system started at 2019-05-14 15:06:54 +0000 UTC (1 container statuses recorded)
May 14 15:50:53.439: INFO: 	Container autoscaler ready: true, restart count 0
May 14 15:50:53.439: INFO: fluentd-gcp-scaler-8b674f786-c4slq from kube-system started at 2019-05-14 15:06:54 +0000 UTC (1 container statuses recorded)
May 14 15:50:53.439: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 14 15:50:53.439: INFO: prometheus-to-sd-cdzjw from kube-system started at 2019-05-14 15:06:34 +0000 UTC (1 container statuses recorded)
May 14 15:50:53.439: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 15:50:53.439: INFO: kube-proxy-gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m from kube-system started at <nil> (0 container statuses recorded)
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: verifying the node has the label node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk
STEP: verifying the node has the label node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq
STEP: verifying the node has the label node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m
May 14 15:50:54.020: INFO: Pod event-exporter-v0.2.3-767cfb76f9-qbjbv requesting resource cpu=0m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m
May 14 15:50:54.020: INFO: Pod fluentd-gcp-scaler-8b674f786-c4slq requesting resource cpu=0m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m
May 14 15:50:54.020: INFO: Pod fluentd-gcp-v3.2.0-2d4fx requesting resource cpu=100m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk
May 14 15:50:54.020: INFO: Pod fluentd-gcp-v3.2.0-96cdk requesting resource cpu=100m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m
May 14 15:50:54.020: INFO: Pod fluentd-gcp-v3.2.0-kjzgl requesting resource cpu=100m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq
May 14 15:50:54.020: INFO: Pod heapster-v1.6.0-beta.1-f7c96fb9f-4lh6l requesting resource cpu=138m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk
May 14 15:50:54.020: INFO: Pod kube-dns-785fdb56c-w2llr requesting resource cpu=260m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq
May 14 15:50:54.020: INFO: Pod kube-dns-785fdb56c-zq2ht requesting resource cpu=260m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m
May 14 15:50:54.020: INFO: Pod kube-dns-autoscaler-67c97c87fb-6fsr5 requesting resource cpu=20m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m
May 14 15:50:54.020: INFO: Pod kube-proxy-gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk requesting resource cpu=100m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk
May 14 15:50:54.020: INFO: Pod kube-proxy-gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq requesting resource cpu=100m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq
May 14 15:50:54.020: INFO: Pod kube-proxy-gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m requesting resource cpu=100m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m
May 14 15:50:54.020: INFO: Pod l7-default-backend-7ff48cffd7-7dcfl requesting resource cpu=10m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m
May 14 15:50:54.020: INFO: Pod metrics-server-v0.2.1-fd596d746-dpxml requesting resource cpu=53m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk
May 14 15:50:54.020: INFO: Pod prometheus-to-sd-6kt4f requesting resource cpu=1m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk
May 14 15:50:54.020: INFO: Pod prometheus-to-sd-cdzjw requesting resource cpu=1m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m
May 14 15:50:54.020: INFO: Pod prometheus-to-sd-gcjjw requesting resource cpu=1m on Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0e4a56b1-7660-11e9-96ed-42d4de3e15aa.159e9775fd0ed377], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-g6dmd/filler-pod-0e4a56b1-7660-11e9-96ed-42d4de3e15aa to gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0e4a56b1-7660-11e9-96ed-42d4de3e15aa.159e97764d9f31c2], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0e4a56b1-7660-11e9-96ed-42d4de3e15aa.159e97765036f100], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0e4a56b1-7660-11e9-96ed-42d4de3e15aa.159e977659769996], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0e59c736-7660-11e9-96ed-42d4de3e15aa.159e9775fe554b20], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-g6dmd/filler-pod-0e59c736-7660-11e9-96ed-42d4de3e15aa to gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0e59c736-7660-11e9-96ed-42d4de3e15aa.159e97762a8bfcf0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0e59c736-7660-11e9-96ed-42d4de3e15aa.159e97762d231b97], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0e59c736-7660-11e9-96ed-42d4de3e15aa.159e9776338076e3], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0e5c1915-7660-11e9-96ed-42d4de3e15aa.159e9775ff1992fb], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-g6dmd/filler-pod-0e5c1915-7660-11e9-96ed-42d4de3e15aa to gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0e5c1915-7660-11e9-96ed-42d4de3e15aa.159e977633341448], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0e5c1915-7660-11e9-96ed-42d4de3e15aa.159e977635947b87], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0e5c1915-7660-11e9-96ed-42d4de3e15aa.159e977639d193d3], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.159e977707ed2d1f], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:50:59.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-g6dmd" for this suite.
May 14 15:51:10.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:51:11.139: INFO: namespace: e2e-tests-sched-pred-g6dmd, resource: bindings, ignored listing per whitelist
May 14 15:51:13.234: INFO: namespace e2e-tests-sched-pred-g6dmd deletion completed in 13.264985346s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

• [SLOW TEST:80.820 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:51:13.234: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-19e39b1e-7660-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 15:51:13.664: INFO: Waiting up to 5m0s for pod "pod-configmaps-19f10da3-7660-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-configmap-cxb94" to be "success or failure"
May 14 15:51:13.749: INFO: Pod "pod-configmaps-19f10da3-7660-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 85.456394ms
May 14 15:51:15.753: INFO: Pod "pod-configmaps-19f10da3-7660-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.089315926s
STEP: Saw pod success
May 14 15:51:15.753: INFO: Pod "pod-configmaps-19f10da3-7660-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:51:15.756: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-configmaps-19f10da3-7660-11e9-96ed-42d4de3e15aa container configmap-volume-test: <nil>
STEP: delete the pod
May 14 15:51:15.977: INFO: Waiting for pod pod-configmaps-19f10da3-7660-11e9-96ed-42d4de3e15aa to disappear
May 14 15:51:16.075: INFO: Pod pod-configmaps-19f10da3-7660-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:51:16.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cxb94" for this suite.
May 14 15:51:22.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:51:23.913: INFO: namespace: e2e-tests-configmap-cxb94, resource: bindings, ignored listing per whitelist
May 14 15:51:25.344: INFO: namespace e2e-tests-configmap-cxb94 deletion completed in 9.265700829s

• [SLOW TEST:12.110 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:51:25.344: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on node default medium
May 14 15:51:25.594: INFO: Waiting up to 5m0s for pod "pod-210bb765-7660-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-8q567" to be "success or failure"
May 14 15:51:25.682: INFO: Pod "pod-210bb765-7660-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 88.132203ms
May 14 15:51:27.687: INFO: Pod "pod-210bb765-7660-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.09284372s
STEP: Saw pod success
May 14 15:51:27.687: INFO: Pod "pod-210bb765-7660-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:51:27.690: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-210bb765-7660-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:51:27.897: INFO: Waiting for pod pod-210bb765-7660-11e9-96ed-42d4de3e15aa to disappear
May 14 15:51:27.988: INFO: Pod pod-210bb765-7660-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:51:27.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8q567" for this suite.
May 14 15:51:34.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:51:36.352: INFO: namespace: e2e-tests-emptydir-8q567, resource: bindings, ignored listing per whitelist
May 14 15:51:37.388: INFO: namespace e2e-tests-emptydir-8q567 deletion completed in 9.396232705s

• [SLOW TEST:12.044 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:51:37.388: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:51:37.733: INFO: Waiting up to 5m0s for pod "downwardapi-volume-284826de-7660-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-9bp5x" to be "success or failure"
May 14 15:51:37.826: INFO: Pod "downwardapi-volume-284826de-7660-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 93.117792ms
May 14 15:51:39.832: INFO: Pod "downwardapi-volume-284826de-7660-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.098921806s
STEP: Saw pod success
May 14 15:51:39.832: INFO: Pod "downwardapi-volume-284826de-7660-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:51:39.834: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-284826de-7660-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:51:40.035: INFO: Waiting for pod downwardapi-volume-284826de-7660-11e9-96ed-42d4de3e15aa to disappear
May 14 15:51:40.127: INFO: Pod downwardapi-volume-284826de-7660-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:51:40.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9bp5x" for this suite.
May 14 15:51:46.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:51:48.857: INFO: namespace: e2e-tests-downward-api-9bp5x, resource: bindings, ignored listing per whitelist
May 14 15:51:49.353: INFO: namespace e2e-tests-downward-api-9bp5x deletion completed in 9.222435334s

• [SLOW TEST:11.965 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:51:49.354: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with configMap that has name projected-configmap-test-upd-2f5b2fb0-7660-11e9-96ed-42d4de3e15aa
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-2f5b2fb0-7660-11e9-96ed-42d4de3e15aa
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:53:04.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6mrf2" for this suite.
May 14 15:53:26.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:53:29.578: INFO: namespace: e2e-tests-projected-6mrf2, resource: bindings, ignored listing per whitelist
May 14 15:53:29.906: INFO: namespace e2e-tests-projected-6mrf2 deletion completed in 25.233153925s

• [SLOW TEST:100.553 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:53:29.907: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-6b59b7a2-7660-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 15:53:30.336: INFO: Waiting up to 5m0s for pod "pod-configmaps-6b66fec8-7660-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-configmap-h49zm" to be "success or failure"
May 14 15:53:30.425: INFO: Pod "pod-configmaps-6b66fec8-7660-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 89.328224ms
May 14 15:53:32.429: INFO: Pod "pod-configmaps-6b66fec8-7660-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.093517546s
STEP: Saw pod success
May 14 15:53:32.429: INFO: Pod "pod-configmaps-6b66fec8-7660-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:53:32.434: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-configmaps-6b66fec8-7660-11e9-96ed-42d4de3e15aa container configmap-volume-test: <nil>
STEP: delete the pod
May 14 15:53:32.643: INFO: Waiting for pod pod-configmaps-6b66fec8-7660-11e9-96ed-42d4de3e15aa to disappear
May 14 15:53:32.735: INFO: Pod pod-configmaps-6b66fec8-7660-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:53:32.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-h49zm" for this suite.
May 14 15:53:38.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:53:40.573: INFO: namespace: e2e-tests-configmap-h49zm, resource: bindings, ignored listing per whitelist
May 14 15:53:41.953: INFO: namespace e2e-tests-configmap-h49zm deletion completed in 9.213427608s

• [SLOW TEST:12.045 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:53:41.953: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 14 15:53:42.652: INFO: Create a RollingUpdate DaemonSet
May 14 15:53:42.763: INFO: Check that daemon pods launch on every node of the cluster
May 14 15:53:42.856: INFO: Number of nodes with available pods: 0
May 14 15:53:42.856: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:53:43.862: INFO: Number of nodes with available pods: 1
May 14 15:53:43.862: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 15:53:44.862: INFO: Number of nodes with available pods: 3
May 14 15:53:44.862: INFO: Number of running nodes: 3, number of available pods: 3
May 14 15:53:44.862: INFO: Update the DaemonSet to trigger a rollout
May 14 15:53:45.047: INFO: Updating DaemonSet daemon-set
May 14 15:53:48.060: INFO: Roll back the DaemonSet before rollout is complete
May 14 15:53:48.068: INFO: Updating DaemonSet daemon-set
May 14 15:53:48.068: INFO: Make sure DaemonSet rollback is complete
May 14 15:53:48.075: INFO: Wrong image for pod: daemon-set-sdzpv. Expected: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0, got: foo:non-existent.
May 14 15:53:48.075: INFO: Pod daemon-set-sdzpv is not available
May 14 15:53:49.082: INFO: Wrong image for pod: daemon-set-sdzpv. Expected: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0, got: foo:non-existent.
May 14 15:53:49.082: INFO: Pod daemon-set-sdzpv is not available
May 14 15:53:50.082: INFO: Pod daemon-set-ft8f9 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-8lqj2, will wait for the garbage collector to delete the pods
May 14 15:53:50.406: INFO: Deleting {extensions DaemonSet} daemon-set took: 93.144948ms
May 14 15:53:50.506: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.311233ms
May 14 15:53:54.313: INFO: Number of nodes with available pods: 0
May 14 15:53:54.313: INFO: Number of running nodes: 0, number of available pods: 0
May 14 15:53:54.315: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8lqj2/daemonsets","resourceVersion":"12080"},"items":null}

May 14 15:53:54.317: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8lqj2/pods","resourceVersion":"12080"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:53:54.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8lqj2" for this suite.
May 14 15:54:00.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:54:02.624: INFO: namespace: e2e-tests-daemonsets-8lqj2, resource: bindings, ignored listing per whitelist
May 14 15:54:03.521: INFO: namespace e2e-tests-daemonsets-8lqj2 deletion completed in 9.1903656s

• [SLOW TEST:21.568 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:54:03.521: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:54:03.781: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f535e9f-7660-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-qz2z2" to be "success or failure"
May 14 15:54:03.872: INFO: Pod "downwardapi-volume-7f535e9f-7660-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 91.315761ms
May 14 15:54:05.876: INFO: Pod "downwardapi-volume-7f535e9f-7660-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0945508s
STEP: Saw pod success
May 14 15:54:05.876: INFO: Pod "downwardapi-volume-7f535e9f-7660-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:54:05.878: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-7f535e9f-7660-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:54:06.079: INFO: Waiting for pod downwardapi-volume-7f535e9f-7660-11e9-96ed-42d4de3e15aa to disappear
May 14 15:54:06.171: INFO: Pod downwardapi-volume-7f535e9f-7660-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:54:06.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qz2z2" for this suite.
May 14 15:54:12.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:54:13.927: INFO: namespace: e2e-tests-downward-api-qz2z2, resource: bindings, ignored listing per whitelist
May 14 15:54:15.484: INFO: namespace e2e-tests-downward-api-qz2z2 deletion completed in 9.307601261s

• [SLOW TEST:11.963 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:54:15.484: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-2gmgg
May 14 15:54:17.835: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-2gmgg
STEP: checking the pod's current state and verifying that restartCount is present
May 14 15:54:17.837: INFO: Initial restart count of pod liveness-exec is 0
May 14 15:55:04.080: INFO: Restart count of pod e2e-tests-container-probe-2gmgg/liveness-exec is now 1 (46.243447807s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:55:04.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2gmgg" for this suite.
May 14 15:55:10.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:55:10.707: INFO: namespace: e2e-tests-container-probe-2gmgg, resource: bindings, ignored listing per whitelist
May 14 15:55:13.803: INFO: namespace e2e-tests-container-probe-2gmgg deletion completed in 9.520776569s

• [SLOW TEST:58.319 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:55:13.804: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir volume type on tmpfs
May 14 15:55:14.135: INFO: Waiting up to 5m0s for pod "pod-a9458995-7660-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-7r76c" to be "success or failure"
May 14 15:55:14.221: INFO: Pod "pod-a9458995-7660-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 86.136184ms
May 14 15:55:16.224: INFO: Pod "pod-a9458995-7660-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.089356106s
STEP: Saw pod success
May 14 15:55:16.224: INFO: Pod "pod-a9458995-7660-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:55:16.226: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-a9458995-7660-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:55:16.425: INFO: Waiting for pod pod-a9458995-7660-11e9-96ed-42d4de3e15aa to disappear
May 14 15:55:16.523: INFO: Pod pod-a9458995-7660-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:55:16.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7r76c" for this suite.
May 14 15:55:22.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:55:24.025: INFO: namespace: e2e-tests-emptydir-7r76c, resource: bindings, ignored listing per whitelist
May 14 15:55:25.795: INFO: namespace e2e-tests-emptydir-7r76c deletion completed in 9.268443736s

• [SLOW TEST:11.991 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:55:25.795: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:199
[It] should be submitted and removed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:55:26.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qxs4p" for this suite.
May 14 15:55:48.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:55:50.469: INFO: namespace: e2e-tests-pods-qxs4p, resource: bindings, ignored listing per whitelist
May 14 15:55:51.612: INFO: namespace e2e-tests-pods-qxs4p deletion completed in 25.486569768s

• [SLOW TEST:25.817 seconds]
[k8s.io] [sig-node] Pods Extended
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  [k8s.io] Pods Set QOS Class
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be submitted and removed  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:55:51.612: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test override all
May 14 15:55:51.886: INFO: Waiting up to 5m0s for pod "client-containers-bfc5e3d1-7660-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-containers-2rdkq" to be "success or failure"
May 14 15:55:51.984: INFO: Pod "client-containers-bfc5e3d1-7660-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 97.515124ms
May 14 15:55:53.987: INFO: Pod "client-containers-bfc5e3d1-7660-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.100623873s
STEP: Saw pod success
May 14 15:55:53.987: INFO: Pod "client-containers-bfc5e3d1-7660-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:55:53.991: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod client-containers-bfc5e3d1-7660-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:55:54.237: INFO: Waiting for pod client-containers-bfc5e3d1-7660-11e9-96ed-42d4de3e15aa to disappear
May 14 15:55:54.322: INFO: Pod client-containers-bfc5e3d1-7660-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:55:54.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2rdkq" for this suite.
May 14 15:56:00.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:56:02.948: INFO: namespace: e2e-tests-containers-2rdkq, resource: bindings, ignored listing per whitelist
May 14 15:56:03.727: INFO: namespace e2e-tests-containers-2rdkq deletion completed in 9.396505234s

• [SLOW TEST:12.116 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:56:03.727: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
May 14 15:56:04.660: INFO: Waiting up to 5m0s for pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-f2nc2" in namespace "e2e-tests-svcaccounts-8dcrp" to be "success or failure"
May 14 15:56:04.753: INFO: Pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-f2nc2": Phase="Pending", Reason="", readiness=false. Elapsed: 92.908737ms
May 14 15:56:06.825: INFO: Pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-f2nc2": Phase="Running", Reason="", readiness=false. Elapsed: 2.164892643s
May 14 15:56:08.830: INFO: Pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-f2nc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.169647634s
STEP: Saw pod success
May 14 15:56:08.830: INFO: Pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-f2nc2" satisfied condition "success or failure"
May 14 15:56:08.832: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-f2nc2 container token-test: <nil>
STEP: delete the pod
May 14 15:56:09.033: INFO: Waiting for pod pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-f2nc2 to disappear
May 14 15:56:09.122: INFO: Pod pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-f2nc2 no longer exists
STEP: Creating a pod to test consume service account root CA
May 14 15:56:09.134: INFO: Waiting up to 5m0s for pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-mx5tn" in namespace "e2e-tests-svcaccounts-8dcrp" to be "success or failure"
May 14 15:56:09.230: INFO: Pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-mx5tn": Phase="Pending", Reason="", readiness=false. Elapsed: 95.820751ms
May 14 15:56:11.233: INFO: Pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-mx5tn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.099013791s
STEP: Saw pod success
May 14 15:56:11.233: INFO: Pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-mx5tn" satisfied condition "success or failure"
May 14 15:56:11.235: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq pod pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-mx5tn container root-ca-test: <nil>
STEP: delete the pod
May 14 15:56:11.438: INFO: Waiting for pod pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-mx5tn to disappear
May 14 15:56:11.441: INFO: Pod pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-mx5tn no longer exists
STEP: Creating a pod to test consume service account namespace
May 14 15:56:11.449: INFO: Waiting up to 5m0s for pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-ds667" in namespace "e2e-tests-svcaccounts-8dcrp" to be "success or failure"
May 14 15:56:11.584: INFO: Pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-ds667": Phase="Pending", Reason="", readiness=false. Elapsed: 134.508046ms
May 14 15:56:13.586: INFO: Pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-ds667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.137244524s
STEP: Saw pod success
May 14 15:56:13.586: INFO: Pod "pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-ds667" satisfied condition "success or failure"
May 14 15:56:13.592: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-ds667 container namespace-test: <nil>
STEP: delete the pod
May 14 15:56:13.802: INFO: Waiting for pod pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-ds667 to disappear
May 14 15:56:13.804: INFO: Pod pod-service-account-c762ca44-7660-11e9-96ed-42d4de3e15aa-ds667 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:56:13.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-8dcrp" for this suite.
May 14 15:56:19.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:56:22.472: INFO: namespace: e2e-tests-svcaccounts-8dcrp, resource: bindings, ignored listing per whitelist
May 14 15:56:23.063: INFO: namespace e2e-tests-svcaccounts-8dcrp deletion completed in 9.255753426s

• [SLOW TEST:19.335 seconds]
[sig-auth] ServiceAccounts
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:56:23.063: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0514 15:56:54.020327     651 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 14 15:56:54.020: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:56:54.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4pjvb" for this suite.
May 14 15:57:00.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:57:00.326: INFO: namespace: e2e-tests-gc-4pjvb, resource: bindings, ignored listing per whitelist
May 14 15:57:02.935: INFO: namespace e2e-tests-gc-4pjvb deletion completed in 8.912116527s

• [SLOW TEST:39.872 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:57:02.935: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test use defaults
May 14 15:57:03.262: INFO: Waiting up to 5m0s for pod "client-containers-ea519382-7660-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-containers-b68th" to be "success or failure"
May 14 15:57:03.350: INFO: Pod "client-containers-ea519382-7660-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 87.627845ms
May 14 15:57:05.353: INFO: Pod "client-containers-ea519382-7660-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.090574029s
STEP: Saw pod success
May 14 15:57:05.353: INFO: Pod "client-containers-ea519382-7660-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:57:05.355: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod client-containers-ea519382-7660-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 15:57:05.549: INFO: Waiting for pod client-containers-ea519382-7660-11e9-96ed-42d4de3e15aa to disappear
May 14 15:57:05.639: INFO: Pod client-containers-ea519382-7660-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:57:05.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-b68th" for this suite.
May 14 15:57:11.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:57:13.718: INFO: namespace: e2e-tests-containers-b68th, resource: bindings, ignored listing per whitelist
May 14 15:57:14.981: INFO: namespace e2e-tests-containers-b68th deletion completed in 9.339272776s

• [SLOW TEST:12.046 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:57:14.982: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
May 14 15:57:15.228: INFO: Waiting up to 5m0s for pod "downward-api-f1732fe7-7660-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-wmsdg" to be "success or failure"
May 14 15:57:15.324: INFO: Pod "downward-api-f1732fe7-7660-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 95.758625ms
May 14 15:57:17.328: INFO: Pod "downward-api-f1732fe7-7660-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.099640768s
STEP: Saw pod success
May 14 15:57:17.328: INFO: Pod "downward-api-f1732fe7-7660-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:57:17.331: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downward-api-f1732fe7-7660-11e9-96ed-42d4de3e15aa container dapi-container: <nil>
STEP: delete the pod
May 14 15:57:17.532: INFO: Waiting for pod downward-api-f1732fe7-7660-11e9-96ed-42d4de3e15aa to disappear
May 14 15:57:17.624: INFO: Pod downward-api-f1732fe7-7660-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:57:17.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wmsdg" for this suite.
May 14 15:57:23.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:57:25.665: INFO: namespace: e2e-tests-downward-api-wmsdg, resource: bindings, ignored listing per whitelist
May 14 15:57:27.000: INFO: namespace e2e-tests-downward-api-wmsdg deletion completed in 9.37304483s

• [SLOW TEST:12.019 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:57:27.000: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-f89b81e5-7660-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 15:57:27.333: INFO: Waiting up to 5m0s for pod "pod-secrets-f8a9c75f-7660-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-secrets-tnpnp" to be "success or failure"
May 14 15:57:27.422: INFO: Pod "pod-secrets-f8a9c75f-7660-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 88.863552ms
May 14 15:57:29.425: INFO: Pod "pod-secrets-f8a9c75f-7660-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0923655s
STEP: Saw pod success
May 14 15:57:29.425: INFO: Pod "pod-secrets-f8a9c75f-7660-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:57:29.427: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-secrets-f8a9c75f-7660-11e9-96ed-42d4de3e15aa container secret-volume-test: <nil>
STEP: delete the pod
May 14 15:57:29.624: INFO: Waiting for pod pod-secrets-f8a9c75f-7660-11e9-96ed-42d4de3e15aa to disappear
May 14 15:57:29.716: INFO: Pod pod-secrets-f8a9c75f-7660-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:57:29.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tnpnp" for this suite.
May 14 15:57:35.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:57:37.616: INFO: namespace: e2e-tests-secrets-tnpnp, resource: bindings, ignored listing per whitelist
May 14 15:57:38.918: INFO: namespace e2e-tests-secrets-tnpnp deletion completed in 9.197512852s

• [SLOW TEST:11.917 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:57:38.918: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
May 14 15:57:39.060: INFO: Waiting up to 1m0s for all nodes to be ready
May 14 15:58:39.163: INFO: Waiting for terminating namespaces to be deleted...
May 14 15:58:39.348: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 14 15:58:39.647: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 14 15:58:39.647: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
May 14 15:58:39.651: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 14 15:58:39.651: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk before test
May 14 15:58:39.744: INFO: prometheus-to-sd-6kt4f from kube-system started at 2019-05-14 15:06:34 +0000 UTC (1 container statuses recorded)
May 14 15:58:39.744: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 15:58:39.744: INFO: metrics-server-v0.2.1-fd596d746-dpxml from kube-system started at 2019-05-14 15:07:03 +0000 UTC (2 container statuses recorded)
May 14 15:58:39.744: INFO: 	Container metrics-server ready: true, restart count 0
May 14 15:58:39.744: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 14 15:58:39.744: INFO: kube-proxy-gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk from kube-system started at <nil> (0 container statuses recorded)
May 14 15:58:39.744: INFO: fluentd-gcp-v3.2.0-2d4fx from kube-system started at 2019-05-14 15:07:05 +0000 UTC (2 container statuses recorded)
May 14 15:58:39.744: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 14 15:58:39.744: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 14 15:58:39.744: INFO: heapster-v1.6.0-beta.1-f7c96fb9f-4lh6l from kube-system started at 2019-05-14 15:07:07 +0000 UTC (3 container statuses recorded)
May 14 15:58:39.744: INFO: 	Container heapster ready: true, restart count 0
May 14 15:58:39.744: INFO: 	Container heapster-nanny ready: true, restart count 0
May 14 15:58:39.744: INFO: 	Container prom-to-sd ready: true, restart count 0
May 14 15:58:39.744: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq before test
May 14 15:58:39.838: INFO: prometheus-to-sd-gcjjw from kube-system started at 2019-05-14 15:06:36 +0000 UTC (1 container statuses recorded)
May 14 15:58:39.838: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 15:58:39.838: INFO: fluentd-gcp-v3.2.0-kjzgl from kube-system started at 2019-05-14 15:07:05 +0000 UTC (2 container statuses recorded)
May 14 15:58:39.838: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 14 15:58:39.838: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 14 15:58:39.838: INFO: kube-proxy-gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq from kube-system started at <nil> (0 container statuses recorded)
May 14 15:58:39.838: INFO: kube-dns-785fdb56c-w2llr from kube-system started at 2019-05-14 15:06:57 +0000 UTC (4 container statuses recorded)
May 14 15:58:39.838: INFO: 	Container dnsmasq ready: true, restart count 0
May 14 15:58:39.838: INFO: 	Container kubedns ready: true, restart count 0
May 14 15:58:39.838: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 15:58:39.838: INFO: 	Container sidecar ready: true, restart count 0
May 14 15:58:39.838: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m before test
May 14 15:58:39.935: INFO: event-exporter-v0.2.3-767cfb76f9-qbjbv from kube-system started at 2019-05-14 15:06:54 +0000 UTC (2 container statuses recorded)
May 14 15:58:39.935: INFO: 	Container event-exporter ready: true, restart count 0
May 14 15:58:39.936: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 14 15:58:39.936: INFO: l7-default-backend-7ff48cffd7-7dcfl from kube-system started at 2019-05-14 15:06:54 +0000 UTC (1 container statuses recorded)
May 14 15:58:39.936: INFO: 	Container default-http-backend ready: true, restart count 0
May 14 15:58:39.936: INFO: fluentd-gcp-v3.2.0-96cdk from kube-system started at 2019-05-14 15:07:10 +0000 UTC (2 container statuses recorded)
May 14 15:58:39.936: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 14 15:58:39.936: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 14 15:58:39.936: INFO: kube-dns-autoscaler-67c97c87fb-6fsr5 from kube-system started at 2019-05-14 15:06:54 +0000 UTC (1 container statuses recorded)
May 14 15:58:39.936: INFO: 	Container autoscaler ready: true, restart count 0
May 14 15:58:39.936: INFO: fluentd-gcp-scaler-8b674f786-c4slq from kube-system started at 2019-05-14 15:06:54 +0000 UTC (1 container statuses recorded)
May 14 15:58:39.936: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 14 15:58:39.936: INFO: prometheus-to-sd-cdzjw from kube-system started at 2019-05-14 15:06:34 +0000 UTC (1 container statuses recorded)
May 14 15:58:39.936: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 15:58:39.936: INFO: kube-proxy-gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m from kube-system started at <nil> (0 container statuses recorded)
May 14 15:58:39.936: INFO: kube-dns-785fdb56c-zq2ht from kube-system started at 2019-05-14 15:06:54 +0000 UTC (4 container statuses recorded)
May 14 15:58:39.936: INFO: 	Container dnsmasq ready: true, restart count 0
May 14 15:58:39.936: INFO: 	Container kubedns ready: true, restart count 0
May 14 15:58:39.936: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 15:58:39.936: INFO: 	Container sidecar ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-255e9057-7661-11e9-96ed-42d4de3e15aa 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-255e9057-7661-11e9-96ed-42d4de3e15aa off the node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk
STEP: verifying the node doesn't have the label kubernetes.io/e2e-255e9057-7661-11e9-96ed-42d4de3e15aa
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:58:44.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-26njz" for this suite.
May 14 15:58:54.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:58:55.115: INFO: namespace: e2e-tests-sched-pred-26njz, resource: bindings, ignored listing per whitelist
May 14 15:58:57.872: INFO: namespace e2e-tests-sched-pred-26njz deletion completed in 13.233567523s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

• [SLOW TEST:78.954 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:58:57.872: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 15:58:58.114: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2ec5b432-7661-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-tt4p7" to be "success or failure"
May 14 15:58:58.204: INFO: Pod "downwardapi-volume-2ec5b432-7661-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 90.488403ms
May 14 15:59:00.207: INFO: Pod "downwardapi-volume-2ec5b432-7661-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.09365381s
STEP: Saw pod success
May 14 15:59:00.208: INFO: Pod "downwardapi-volume-2ec5b432-7661-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 15:59:00.211: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-2ec5b432-7661-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 15:59:00.407: INFO: Waiting for pod downwardapi-volume-2ec5b432-7661-11e9-96ed-42d4de3e15aa to disappear
May 14 15:59:00.510: INFO: Pod downwardapi-volume-2ec5b432-7661-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:59:00.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tt4p7" for this suite.
May 14 15:59:06.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:59:09.367: INFO: namespace: e2e-tests-projected-tt4p7, resource: bindings, ignored listing per whitelist
May 14 15:59:09.617: INFO: namespace e2e-tests-projected-tt4p7 deletion completed in 9.103656807s

• [SLOW TEST:11.745 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:59:09.617: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-xtdsz
May 14 15:59:14.057: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-xtdsz
STEP: checking the pod's current state and verifying that restartCount is present
May 14 15:59:14.059: INFO: Initial restart count of pod liveness-http is 0
May 14 15:59:36.099: INFO: Restart count of pod e2e-tests-container-probe-xtdsz/liveness-http is now 1 (22.040422785s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:59:36.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xtdsz" for this suite.
May 14 15:59:42.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 15:59:44.251: INFO: namespace: e2e-tests-container-probe-xtdsz, resource: bindings, ignored listing per whitelist
May 14 15:59:45.698: INFO: namespace e2e-tests-container-probe-xtdsz deletion completed in 9.391355581s

• [SLOW TEST:36.081 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 15:59:45.698: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should add annotations for pods in rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating Redis RC
May 14 15:59:45.857: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-cc45h'
May 14 15:59:46.446: INFO: stderr: ""
May 14 15:59:46.446: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 14 15:59:47.552: INFO: Selector matched 1 pods for map[app:redis]
May 14 15:59:47.552: INFO: Found 0 / 1
May 14 15:59:48.450: INFO: Selector matched 1 pods for map[app:redis]
May 14 15:59:48.450: INFO: Found 0 / 1
May 14 15:59:49.449: INFO: Selector matched 1 pods for map[app:redis]
May 14 15:59:49.450: INFO: Found 1 / 1
May 14 15:59:49.450: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 14 15:59:49.452: INFO: Selector matched 1 pods for map[app:redis]
May 14 15:59:49.452: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 14 15:59:49.452: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 patch pod redis-master-2rdl2 --namespace=e2e-tests-kubectl-cc45h -p {"metadata":{"annotations":{"x":"y"}}}'
May 14 15:59:49.766: INFO: stderr: ""
May 14 15:59:49.766: INFO: stdout: "pod/redis-master-2rdl2 patched\n"
STEP: checking annotations
May 14 15:59:49.769: INFO: Selector matched 1 pods for map[app:redis]
May 14 15:59:49.769: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 15:59:49.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cc45h" for this suite.
May 14 16:00:11.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:00:12.817: INFO: namespace: e2e-tests-kubectl-cc45h, resource: bindings, ignored listing per whitelist
May 14 16:00:14.895: INFO: namespace e2e-tests-kubectl-cc45h deletion completed in 25.122627873s

• [SLOW TEST:29.197 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should add annotations for pods in rc  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:00:14.895: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72
STEP: Creating service test in namespace e2e-tests-statefulset-gjd6p
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-gjd6p
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-gjd6p
May 14 16:00:15.350: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May 14 16:00:25.354: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 14 16:00:25.357: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-gjd6p ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 16:00:25.722: INFO: stderr: ""
May 14 16:00:25.722: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 16:00:25.722: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 16:00:25.726: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 14 16:00:35.731: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 14 16:00:35.731: INFO: Waiting for statefulset status.replicas updated to 0
May 14 16:00:35.941: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 14 16:00:35.941: INFO: ss-0  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:15 +0000 UTC  }]
May 14 16:00:35.942: INFO: 
May 14 16:00:35.942: INFO: StatefulSet ss has not reached scale 3, at 1
May 14 16:00:36.946: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993776081s
May 14 16:00:37.950: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989469118s
May 14 16:00:38.955: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985661883s
May 14 16:00:39.959: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979920187s
May 14 16:00:40.963: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976155526s
May 14 16:00:41.969: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972387036s
May 14 16:00:42.972: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966590939s
May 14 16:00:43.980: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962904349s
May 14 16:00:44.984: INFO: Verifying statefulset ss doesn't scale past 3 for another 955.332794ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-gjd6p
May 14 16:00:45.988: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-gjd6p ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 16:00:46.161: INFO: stderr: ""
May 14 16:00:46.161: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 14 16:00:46.161: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 14 16:00:46.161: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-gjd6p ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 16:00:46.519: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
May 14 16:00:46.519: INFO: stdout: ""
May 14 16:00:46.519: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
May 14 16:00:46.520: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-gjd6p ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 14 16:00:46.896: INFO: stderr: "mv: cannot stat '/tmp/index.html': No such file or directory\n"
May 14 16:00:46.896: INFO: stdout: ""
May 14 16:00:46.896: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
May 14 16:00:46.899: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
May 14 16:00:56.904: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 14 16:00:56.904: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 14 16:00:56.904: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 14 16:00:56.907: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-gjd6p ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 16:00:57.090: INFO: stderr: ""
May 14 16:00:57.090: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 16:00:57.090: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 16:00:57.090: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-gjd6p ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 16:00:57.252: INFO: stderr: ""
May 14 16:00:57.252: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 16:00:57.252: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 16:00:57.252: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 exec --namespace=e2e-tests-statefulset-gjd6p ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 14 16:00:57.432: INFO: stderr: ""
May 14 16:00:57.432: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 14 16:00:57.432: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 14 16:00:57.432: INFO: Waiting for statefulset status.replicas updated to 0
May 14 16:00:57.435: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May 14 16:01:07.865: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 14 16:01:07.865: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 14 16:01:07.865: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 14 16:01:08.252: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 14 16:01:08.253: INFO: ss-0  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:15 +0000 UTC  }]
May 14 16:01:08.253: INFO: ss-1  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:35 +0000 UTC  }]
May 14 16:01:08.253: INFO: ss-2  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:36 +0000 UTC  }]
May 14 16:01:08.253: INFO: 
May 14 16:01:08.253: INFO: StatefulSet ss has not reached scale 0, at 3
May 14 16:01:09.257: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 14 16:01:09.257: INFO: ss-0  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:15 +0000 UTC  }]
May 14 16:01:09.257: INFO: ss-1  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:35 +0000 UTC  }]
May 14 16:01:09.257: INFO: ss-2  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:36 +0000 UTC  }]
May 14 16:01:09.257: INFO: 
May 14 16:01:09.257: INFO: StatefulSet ss has not reached scale 0, at 3
May 14 16:01:10.261: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 14 16:01:10.261: INFO: ss-0  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:15 +0000 UTC  }]
May 14 16:01:10.261: INFO: ss-1  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:35 +0000 UTC  }]
May 14 16:01:10.261: INFO: ss-2  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:36 +0000 UTC  }]
May 14 16:01:10.261: INFO: 
May 14 16:01:10.261: INFO: StatefulSet ss has not reached scale 0, at 3
May 14 16:01:11.265: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 14 16:01:11.265: INFO: ss-2  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:36 +0000 UTC  }]
May 14 16:01:11.265: INFO: 
May 14 16:01:11.265: INFO: StatefulSet ss has not reached scale 0, at 1
May 14 16:01:12.270: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 14 16:01:12.270: INFO: ss-2  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:36 +0000 UTC  }]
May 14 16:01:12.270: INFO: 
May 14 16:01:12.270: INFO: StatefulSet ss has not reached scale 0, at 1
May 14 16:01:13.275: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
May 14 16:01:13.275: INFO: ss-2  gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-14 16:00:36 +0000 UTC  }]
May 14 16:01:13.275: INFO: 
May 14 16:01:13.275: INFO: StatefulSet ss has not reached scale 0, at 1
May 14 16:01:14.279: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.866516347s
May 14 16:01:15.283: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.862545565s
May 14 16:01:16.287: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.858480674s
May 14 16:01:17.291: INFO: Verifying statefulset ss doesn't scale past 0 for another 854.447629ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-gjd6p
May 14 16:01:18.295: INFO: Scaling statefulset ss to 0
May 14 16:01:18.302: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:83
May 14 16:01:18.305: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gjd6p
May 14 16:01:18.408: INFO: Scaling statefulset ss to 0
May 14 16:01:18.416: INFO: Waiting for statefulset status.replicas updated to 0
May 14 16:01:18.418: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:01:18.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gjd6p" for this suite.
May 14 16:01:24.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:01:25.959: INFO: namespace: e2e-tests-statefulset-gjd6p, resource: bindings, ignored listing per whitelist
May 14 16:01:27.832: INFO: namespace e2e-tests-statefulset-gjd6p deletion completed in 9.044893602s

• [SLOW TEST:72.937 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:01:27.832: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 16:01:28.273: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8845dfbd-7661-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-rwkmf" to be "success or failure"
May 14 16:01:28.361: INFO: Pod "downwardapi-volume-8845dfbd-7661-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 88.450682ms
May 14 16:01:30.365: INFO: Pod "downwardapi-volume-8845dfbd-7661-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092065393s
May 14 16:01:32.368: INFO: Pod "downwardapi-volume-8845dfbd-7661-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.095713739s
STEP: Saw pod success
May 14 16:01:32.368: INFO: Pod "downwardapi-volume-8845dfbd-7661-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:01:32.370: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-8845dfbd-7661-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 16:01:32.580: INFO: Waiting for pod downwardapi-volume-8845dfbd-7661-11e9-96ed-42d4de3e15aa to disappear
May 14 16:01:32.668: INFO: Pod downwardapi-volume-8845dfbd-7661-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:01:32.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rwkmf" for this suite.
May 14 16:01:39.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:01:46.182: INFO: namespace: e2e-tests-downward-api-rwkmf, resource: bindings, ignored listing per whitelist
May 14 16:01:49.557: INFO: namespace e2e-tests-downward-api-rwkmf deletion completed in 16.885736805s

• [SLOW TEST:21.725 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:01:49.557: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support --unix-socket=/path  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Starting the proxy
May 14 16:01:49.790: INFO: Asynchronously running '/workspace/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 proxy --unix-socket=/tmp/kubectl-proxy-unix235947063/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:01:49.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qwnlf" for this suite.
May 14 16:01:56.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:01:58.589: INFO: namespace: e2e-tests-kubectl-qwnlf, resource: bindings, ignored listing per whitelist
May 14 16:01:59.311: INFO: namespace e2e-tests-kubectl-qwnlf deletion completed in 9.344656301s

• [SLOW TEST:9.754 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support --unix-socket=/path  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:01:59.312: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: validating cluster-info
May 14 16:01:59.469: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 cluster-info'
May 14 16:01:59.680: INFO: stderr: ""
May 14 16:01:59.680: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://35.230.205.166\x1b[0m\n\x1b[0;32mGLBCDefaultBackend\x1b[0m is running at \x1b[0;33mhttps://35.230.205.166/api/v1/namespaces/kube-system/services/default-http-backend:http/proxy\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://35.230.205.166/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://35.230.205.166/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://35.230.205.166/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:01:59.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d857d" for this suite.
May 14 16:02:05.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:02:06.793: INFO: namespace: e2e-tests-kubectl-d857d, resource: bindings, ignored listing per whitelist
May 14 16:02:08.940: INFO: namespace e2e-tests-kubectl-d857d deletion completed in 9.256928825s

• [SLOW TEST:9.629 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:02:08.940: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(dig +notcp +noall +answer +search google.com A)" && echo OK > /results/wheezy_udp@google.com;test -n "$$(dig +tcp +noall +answer +search google.com A)" && echo OK > /results/wheezy_tcp@google.com;test -n "$$(dig +notcp +noall +answer +search metadata A)" && echo OK > /results/wheezy_udp@metadata;test -n "$$(dig +tcp +noall +answer +search metadata A)" && echo OK > /results/wheezy_tcp@metadata;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-zj9mh.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-zj9mh.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-zj9mh.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(dig +notcp +noall +answer +search google.com A)" && echo OK > /results/jessie_udp@google.com;test -n "$$(dig +tcp +noall +answer +search google.com A)" && echo OK > /results/jessie_tcp@google.com;test -n "$$(dig +notcp +noall +answer +search metadata A)" && echo OK > /results/jessie_udp@metadata;test -n "$$(dig +tcp +noall +answer +search metadata A)" && echo OK > /results/jessie_tcp@metadata;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-zj9mh.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-zj9mh.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-zj9mh.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 14 16:02:31.493: INFO: DNS probes using dns-test-a0ac075f-7661-11e9-96ed-42d4de3e15aa succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:02:31.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-zj9mh" for this suite.
May 14 16:02:37.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:02:38.591: INFO: namespace: e2e-tests-dns-zj9mh, resource: bindings, ignored listing per whitelist
May 14 16:02:41.049: INFO: namespace e2e-tests-dns-zj9mh deletion completed in 9.447803426s

• [SLOW TEST:32.109 seconds]
[sig-network] DNS
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:02:41.049: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name cm-test-opt-del-b3cd3b26-7661-11e9-96ed-42d4de3e15aa
STEP: Creating configMap with name cm-test-opt-upd-b3cd3b62-7661-11e9-96ed-42d4de3e15aa
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b3cd3b26-7661-11e9-96ed-42d4de3e15aa
STEP: Updating configmap cm-test-opt-upd-b3cd3b62-7661-11e9-96ed-42d4de3e15aa
STEP: Creating configMap with name cm-test-opt-create-b3cd3b7a-7661-11e9-96ed-42d4de3e15aa
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:03:52.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8x5fm" for this suite.
May 14 16:04:14.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:04:16.371: INFO: namespace: e2e-tests-configmap-8x5fm, resource: bindings, ignored listing per whitelist
May 14 16:04:17.834: INFO: namespace e2e-tests-configmap-8x5fm deletion completed in 25.263866345s

• [SLOW TEST:96.785 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:04:17.834: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:84
[It] should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-lpxb8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lpxb8 to expose endpoints map[]
May 14 16:04:18.264: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lpxb8 exposes endpoints map[] (97.570385ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-lpxb8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lpxb8 to expose endpoints map[pod1:[100]]
May 14 16:04:20.473: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lpxb8 exposes endpoints map[pod1:[100]] (2.103926229s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-lpxb8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lpxb8 to expose endpoints map[pod1:[100] pod2:[101]]
May 14 16:04:22.613: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lpxb8 exposes endpoints map[pod1:[100] pod2:[101]] (2.130699008s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-lpxb8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lpxb8 to expose endpoints map[pod2:[101]]
May 14 16:04:23.718: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lpxb8 exposes endpoints map[pod2:[101]] (1.014163533s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-lpxb8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lpxb8 to expose endpoints map[]
May 14 16:04:23.813: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lpxb8 exposes endpoints map[] (7.979231ms elapsed)
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:04:23.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-lpxb8" for this suite.
May 14 16:04:30.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:04:30.583: INFO: namespace: e2e-tests-services-lpxb8, resource: bindings, ignored listing per whitelist
May 14 16:04:33.196: INFO: namespace e2e-tests-services-lpxb8 deletion completed in 9.269631185s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:89

• [SLOW TEST:15.362 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:04:33.196: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 14 16:04:33.440: INFO: (0) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 91.486717ms)
May 14 16:04:33.444: INFO: (1) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.740182ms)
May 14 16:04:33.448: INFO: (2) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.645026ms)
May 14 16:04:33.452: INFO: (3) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.814464ms)
May 14 16:04:33.456: INFO: (4) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.435296ms)
May 14 16:04:33.459: INFO: (5) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.525045ms)
May 14 16:04:33.463: INFO: (6) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.43349ms)
May 14 16:04:33.466: INFO: (7) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.393704ms)
May 14 16:04:33.470: INFO: (8) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.443391ms)
May 14 16:04:33.473: INFO: (9) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.182517ms)
May 14 16:04:33.476: INFO: (10) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.266525ms)
May 14 16:04:33.482: INFO: (11) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.480827ms)
May 14 16:04:33.486: INFO: (12) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.119273ms)
May 14 16:04:33.490: INFO: (13) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.46442ms)
May 14 16:04:33.493: INFO: (14) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.812809ms)
May 14 16:04:33.498: INFO: (15) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.274208ms)
May 14 16:04:33.501: INFO: (16) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.526025ms)
May 14 16:04:33.505: INFO: (17) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.725758ms)
May 14 16:04:33.508: INFO: (18) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.373192ms)
May 14 16:04:33.513: INFO: (19) /api/v1/nodes/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.179442ms)
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:04:33.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-prgb6" for this suite.
May 14 16:04:39.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:04:40.345: INFO: namespace: e2e-tests-proxy-prgb6, resource: bindings, ignored listing per whitelist
May 14 16:04:43.118: INFO: namespace e2e-tests-proxy-prgb6 deletion completed in 9.602132866s

• [SLOW TEST:9.921 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:04:43.118: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1180
[It] should create an rc or deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 14 16:04:43.257: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 run e2e-test-nginx-deployment --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-bpb8m'
May 14 16:04:43.482: INFO: stderr: ""
May 14 16:04:43.482: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1186
May 14 16:04:43.623: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-bpb8m'
May 14 16:04:43.960: INFO: stderr: ""
May 14 16:04:43.960: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:04:43.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bpb8m" for this suite.
May 14 16:04:50.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:04:51.929: INFO: namespace: e2e-tests-kubectl-bpb8m, resource: bindings, ignored listing per whitelist
May 14 16:04:53.430: INFO: namespace e2e-tests-kubectl-bpb8m deletion completed in 9.462443794s

• [SLOW TEST:10.313 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create an rc or deployment from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:04:53.432: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-map-02bb491f-7662-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 16:04:53.849: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-02cc5512-7662-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-4v65j" to be "success or failure"
May 14 16:04:53.940: INFO: Pod "pod-projected-secrets-02cc5512-7662-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 91.351181ms
May 14 16:04:55.951: INFO: Pod "pod-projected-secrets-02cc5512-7662-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.102383089s
STEP: Saw pod success
May 14 16:04:55.951: INFO: Pod "pod-projected-secrets-02cc5512-7662-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:04:55.957: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-secrets-02cc5512-7662-11e9-96ed-42d4de3e15aa container projected-secret-volume-test: <nil>
STEP: delete the pod
May 14 16:04:56.176: INFO: Waiting for pod pod-projected-secrets-02cc5512-7662-11e9-96ed-42d4de3e15aa to disappear
May 14 16:04:56.266: INFO: Pod pod-projected-secrets-02cc5512-7662-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:04:56.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4v65j" for this suite.
May 14 16:05:02.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:05:05.067: INFO: namespace: e2e-tests-projected-4v65j, resource: bindings, ignored listing per whitelist
May 14 16:05:05.740: INFO: namespace e2e-tests-projected-4v65j deletion completed in 9.471520106s

• [SLOW TEST:12.309 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:05:05.740: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5sp54
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 14 16:05:05.940: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 14 16:05:28.588: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.1.164:8080/dial?request=hostName&protocol=http&host=10.40.1.163&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-5sp54 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 16:05:28.588: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 16:05:28.751: INFO: Waiting for endpoints: map[]
May 14 16:05:28.756: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.1.164:8080/dial?request=hostName&protocol=http&host=10.40.2.40&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-5sp54 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 16:05:28.756: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 16:05:28.874: INFO: Waiting for endpoints: map[]
May 14 16:05:28.877: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.1.164:8080/dial?request=hostName&protocol=http&host=10.40.0.29&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-5sp54 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 16:05:28.877: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 16:05:28.941: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:05:28.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5sp54" for this suite.
May 14 16:05:51.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:05:53.129: INFO: namespace: e2e-tests-pod-network-test-5sp54, resource: bindings, ignored listing per whitelist
May 14 16:05:54.866: INFO: namespace e2e-tests-pod-network-test-5sp54 deletion completed in 25.920885347s

• [SLOW TEST:49.126 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:05:54.867: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
May 14 16:05:55.317: INFO: Waiting up to 5m0s for pod "downward-api-2772267e-7662-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-tdz7c" to be "success or failure"
May 14 16:05:55.415: INFO: Pod "downward-api-2772267e-7662-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 98.105486ms
May 14 16:05:57.419: INFO: Pod "downward-api-2772267e-7662-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.102034379s
STEP: Saw pod success
May 14 16:05:57.419: INFO: Pod "downward-api-2772267e-7662-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:05:57.421: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downward-api-2772267e-7662-11e9-96ed-42d4de3e15aa container dapi-container: <nil>
STEP: delete the pod
May 14 16:05:57.625: INFO: Waiting for pod downward-api-2772267e-7662-11e9-96ed-42d4de3e15aa to disappear
May 14 16:05:57.736: INFO: Pod downward-api-2772267e-7662-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:05:57.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tdz7c" for this suite.
May 14 16:06:04.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:06:06.750: INFO: namespace: e2e-tests-downward-api-tdz7c, resource: bindings, ignored listing per whitelist
May 14 16:06:09.122: INFO: namespace e2e-tests-downward-api-tdz7c deletion completed in 11.290872305s

• [SLOW TEST:14.255 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:06:09.123: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-2fdf0411-7662-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 16:06:09.557: INFO: Waiting up to 5m0s for pod "pod-configmaps-2feea542-7662-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-configmap-4ddgc" to be "success or failure"
May 14 16:06:09.675: INFO: Pod "pod-configmaps-2feea542-7662-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 117.648116ms
May 14 16:06:11.678: INFO: Pod "pod-configmaps-2feea542-7662-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.12069311s
May 14 16:06:13.683: INFO: Pod "pod-configmaps-2feea542-7662-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.124954283s
STEP: Saw pod success
May 14 16:06:13.683: INFO: Pod "pod-configmaps-2feea542-7662-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:06:13.685: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-configmaps-2feea542-7662-11e9-96ed-42d4de3e15aa container configmap-volume-test: <nil>
STEP: delete the pod
May 14 16:06:13.881: INFO: Waiting for pod pod-configmaps-2feea542-7662-11e9-96ed-42d4de3e15aa to disappear
May 14 16:06:13.972: INFO: Pod pod-configmaps-2feea542-7662-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:06:13.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4ddgc" for this suite.
May 14 16:06:20.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:06:20.381: INFO: namespace: e2e-tests-configmap-4ddgc, resource: bindings, ignored listing per whitelist
May 14 16:06:23.331: INFO: namespace e2e-tests-configmap-4ddgc deletion completed in 9.354621385s

• [SLOW TEST:14.209 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:06:23.332: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-kpgv8 in namespace e2e-tests-proxy-j5rcj
I0514 16:06:23.729876     651 runners.go:177] Created replication controller with name: proxy-service-kpgv8, namespace: e2e-tests-proxy-j5rcj, replica count: 1
I0514 16:06:24.830522     651 runners.go:177] proxy-service-kpgv8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0514 16:06:25.830865     651 runners.go:177] proxy-service-kpgv8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0514 16:06:26.831183     651 runners.go:177] proxy-service-kpgv8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0514 16:06:27.831505     651 runners.go:177] proxy-service-kpgv8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0514 16:06:28.831839     651 runners.go:177] proxy-service-kpgv8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0514 16:06:29.832089     651 runners.go:177] proxy-service-kpgv8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0514 16:06:30.832349     651 runners.go:177] proxy-service-kpgv8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0514 16:06:31.832584     651 runners.go:177] proxy-service-kpgv8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0514 16:06:32.832818     651 runners.go:177] proxy-service-kpgv8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0514 16:06:33.833070     651 runners.go:177] proxy-service-kpgv8 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 14 16:06:33.928: INFO: setup took 10.41946808s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 14 16:06:34.035: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 106.755754ms)
May 14 16:06:34.036: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 108.013239ms)
May 14 16:06:34.037: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 109.00891ms)
May 14 16:06:34.053: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 124.730708ms)
May 14 16:06:34.065: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 136.568922ms)
May 14 16:06:34.067: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 138.95429ms)
May 14 16:06:34.067: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 138.911613ms)
May 14 16:06:34.075: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 146.055413ms)
May 14 16:06:34.078: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 149.066277ms)
May 14 16:06:34.081: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 152.801871ms)
May 14 16:06:34.101: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 172.830264ms)
May 14 16:06:34.110: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 181.116147ms)
May 14 16:06:34.110: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 181.170878ms)
May 14 16:06:34.111: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 182.772249ms)
May 14 16:06:34.112: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 183.218764ms)
May 14 16:06:34.117: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 189.092295ms)
May 14 16:06:34.132: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 14.66939ms)
May 14 16:06:34.138: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 20.339365ms)
May 14 16:06:34.139: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 21.184577ms)
May 14 16:06:34.142: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 24.536115ms)
May 14 16:06:34.143: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 25.116439ms)
May 14 16:06:34.143: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 25.354153ms)
May 14 16:06:34.144: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 26.558917ms)
May 14 16:06:34.144: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 26.469204ms)
May 14 16:06:34.144: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 26.563009ms)
May 14 16:06:34.145: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 26.768088ms)
May 14 16:06:34.145: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 27.339399ms)
May 14 16:06:34.145: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 27.143536ms)
May 14 16:06:34.145: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 27.045852ms)
May 14 16:06:34.147: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 28.75462ms)
May 14 16:06:34.147: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 29.313415ms)
May 14 16:06:34.148: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 30.59519ms)
May 14 16:06:34.165: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 16.626421ms)
May 14 16:06:34.166: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 17.079691ms)
May 14 16:06:34.169: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 20.073617ms)
May 14 16:06:34.169: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 20.760087ms)
May 14 16:06:34.169: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 20.574092ms)
May 14 16:06:34.175: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 26.397332ms)
May 14 16:06:34.175: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 26.783541ms)
May 14 16:06:34.176: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 27.418831ms)
May 14 16:06:34.176: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 27.295745ms)
May 14 16:06:34.176: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 27.252278ms)
May 14 16:06:34.176: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 27.351042ms)
May 14 16:06:34.176: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 27.200886ms)
May 14 16:06:34.176: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 27.314408ms)
May 14 16:06:34.177: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 27.945872ms)
May 14 16:06:34.177: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 28.445945ms)
May 14 16:06:34.178: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 28.90062ms)
May 14 16:06:34.196: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 17.877841ms)
May 14 16:06:34.196: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 18.147786ms)
May 14 16:06:34.196: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 18.612741ms)
May 14 16:06:34.197: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 19.042302ms)
May 14 16:06:34.200: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 21.425913ms)
May 14 16:06:34.200: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 21.787214ms)
May 14 16:06:34.200: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 22.04348ms)
May 14 16:06:34.200: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 21.369282ms)
May 14 16:06:34.205: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 26.166701ms)
May 14 16:06:34.205: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 27.289135ms)
May 14 16:06:34.205: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 26.833134ms)
May 14 16:06:34.206: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 27.125245ms)
May 14 16:06:34.207: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 28.542968ms)
May 14 16:06:34.207: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 28.841502ms)
May 14 16:06:34.207: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 28.422178ms)
May 14 16:06:34.207: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 28.487308ms)
May 14 16:06:34.228: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 21.13152ms)
May 14 16:06:34.229: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 21.422885ms)
May 14 16:06:34.229: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 20.694173ms)
May 14 16:06:34.229: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 21.298521ms)
May 14 16:06:34.230: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 22.469266ms)
May 14 16:06:34.230: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 22.684027ms)
May 14 16:06:34.231: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 22.76727ms)
May 14 16:06:34.231: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 23.256281ms)
May 14 16:06:34.234: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 25.68317ms)
May 14 16:06:34.234: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 26.005587ms)
May 14 16:06:34.234: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 26.466165ms)
May 14 16:06:34.234: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 25.84697ms)
May 14 16:06:34.235: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 26.536507ms)
May 14 16:06:34.238: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 30.433822ms)
May 14 16:06:34.239: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 30.528561ms)
May 14 16:06:34.239: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 31.904191ms)
May 14 16:06:34.257: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 17.561042ms)
May 14 16:06:34.258: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 17.994395ms)
May 14 16:06:34.260: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 20.007264ms)
May 14 16:06:34.260: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 20.203603ms)
May 14 16:06:34.261: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 20.560028ms)
May 14 16:06:34.264: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 23.913937ms)
May 14 16:06:34.264: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 24.481099ms)
May 14 16:06:34.265: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 24.953413ms)
May 14 16:06:34.265: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 25.18002ms)
May 14 16:06:34.265: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 24.94393ms)
May 14 16:06:34.266: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 25.719867ms)
May 14 16:06:34.267: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 27.351015ms)
May 14 16:06:34.267: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 27.310684ms)
May 14 16:06:34.267: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 27.322441ms)
May 14 16:06:34.268: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 28.255527ms)
May 14 16:06:34.268: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 28.103299ms)
May 14 16:06:34.289: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 20.828994ms)
May 14 16:06:34.289: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 20.847762ms)
May 14 16:06:34.291: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 22.581561ms)
May 14 16:06:34.292: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 23.440611ms)
May 14 16:06:34.293: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 25.043137ms)
May 14 16:06:34.293: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 24.614149ms)
May 14 16:06:34.294: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 25.279247ms)
May 14 16:06:34.294: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 25.364295ms)
May 14 16:06:34.296: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 28.005117ms)
May 14 16:06:34.297: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 28.284211ms)
May 14 16:06:34.297: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 28.326986ms)
May 14 16:06:34.297: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 28.376077ms)
May 14 16:06:34.297: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 28.531304ms)
May 14 16:06:34.297: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 28.513641ms)
May 14 16:06:34.297: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 28.61753ms)
May 14 16:06:34.297: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 28.725439ms)
May 14 16:06:34.313: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 16.183515ms)
May 14 16:06:34.315: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 17.89429ms)
May 14 16:06:34.318: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 20.112343ms)
May 14 16:06:34.318: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 20.228011ms)
May 14 16:06:34.324: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 26.561397ms)
May 14 16:06:34.325: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 27.927101ms)
May 14 16:06:34.326: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 28.098803ms)
May 14 16:06:34.326: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 28.000926ms)
May 14 16:06:34.326: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 28.501828ms)
May 14 16:06:34.326: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 28.239123ms)
May 14 16:06:34.326: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 28.096082ms)
May 14 16:06:34.327: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 29.503809ms)
May 14 16:06:34.327: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 29.36058ms)
May 14 16:06:34.329: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 31.130976ms)
May 14 16:06:34.329: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 31.362318ms)
May 14 16:06:34.329: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 31.141584ms)
May 14 16:06:34.344: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 15.220591ms)
May 14 16:06:34.348: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 18.503471ms)
May 14 16:06:34.348: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 19.122533ms)
May 14 16:06:34.348: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 19.311507ms)
May 14 16:06:34.348: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 18.880614ms)
May 14 16:06:34.348: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 19.110552ms)
May 14 16:06:34.350: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 20.924808ms)
May 14 16:06:34.351: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 22.033988ms)
May 14 16:06:34.351: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 22.421486ms)
May 14 16:06:34.355: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 25.715807ms)
May 14 16:06:34.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 26.507089ms)
May 14 16:06:34.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 26.723323ms)
May 14 16:06:34.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 26.852297ms)
May 14 16:06:34.356: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 26.780497ms)
May 14 16:06:34.357: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 28.098138ms)
May 14 16:06:34.357: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 28.029093ms)
May 14 16:06:34.377: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 20.179758ms)
May 14 16:06:34.377: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 19.887913ms)
May 14 16:06:34.377: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 20.032611ms)
May 14 16:06:34.377: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 19.814022ms)
May 14 16:06:34.380: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 22.61277ms)
May 14 16:06:34.381: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 23.193687ms)
May 14 16:06:34.381: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 23.582178ms)
May 14 16:06:34.381: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 23.413617ms)
May 14 16:06:34.381: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 23.518447ms)
May 14 16:06:34.382: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 24.300223ms)
May 14 16:06:34.382: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 24.419547ms)
May 14 16:06:34.382: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 24.653612ms)
May 14 16:06:34.382: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 24.634913ms)
May 14 16:06:34.386: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 28.440251ms)
May 14 16:06:34.386: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 28.746874ms)
May 14 16:06:34.387: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 29.564501ms)
May 14 16:06:34.402: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 15.053259ms)
May 14 16:06:34.407: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 19.787889ms)
May 14 16:06:34.407: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 19.948865ms)
May 14 16:06:34.407: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 20.16482ms)
May 14 16:06:34.410: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 22.905369ms)
May 14 16:06:34.411: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 24.271316ms)
May 14 16:06:34.411: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 24.360682ms)
May 14 16:06:34.411: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 24.23349ms)
May 14 16:06:34.411: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 24.269607ms)
May 14 16:06:34.412: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 24.664162ms)
May 14 16:06:34.412: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 24.788807ms)
May 14 16:06:34.412: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 24.586918ms)
May 14 16:06:34.412: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 24.637702ms)
May 14 16:06:34.412: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 25.361447ms)
May 14 16:06:34.413: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 25.684379ms)
May 14 16:06:34.413: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 25.967724ms)
May 14 16:06:34.429: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 16.151216ms)
May 14 16:06:34.438: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 24.772269ms)
May 14 16:06:34.440: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 27.28558ms)
May 14 16:06:34.440: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 27.201032ms)
May 14 16:06:34.441: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 27.201782ms)
May 14 16:06:34.440: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 27.308729ms)
May 14 16:06:34.441: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 27.895968ms)
May 14 16:06:34.441: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 27.773865ms)
May 14 16:06:34.441: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 27.769939ms)
May 14 16:06:34.441: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 27.907407ms)
May 14 16:06:34.441: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 27.708479ms)
May 14 16:06:34.442: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 28.354651ms)
May 14 16:06:34.443: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 30.093685ms)
May 14 16:06:34.443: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 29.969712ms)
May 14 16:06:34.444: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 30.347174ms)
May 14 16:06:34.484: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 71.112051ms)
May 14 16:06:34.504: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 19.547607ms)
May 14 16:06:34.504: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 19.466365ms)
May 14 16:06:34.506: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 21.710484ms)
May 14 16:06:34.508: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 23.18545ms)
May 14 16:06:34.514: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 28.581344ms)
May 14 16:06:34.514: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 29.198335ms)
May 14 16:06:34.515: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 30.425121ms)
May 14 16:06:34.515: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 30.721121ms)
May 14 16:06:34.516: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 30.700295ms)
May 14 16:06:34.516: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 30.729376ms)
May 14 16:06:34.516: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 30.836293ms)
May 14 16:06:34.516: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 31.003658ms)
May 14 16:06:34.516: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 31.324014ms)
May 14 16:06:34.517: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 32.110204ms)
May 14 16:06:34.518: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 33.782462ms)
May 14 16:06:34.518: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 33.808111ms)
May 14 16:06:34.535: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 16.631625ms)
May 14 16:06:34.537: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 18.229191ms)
May 14 16:06:34.541: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 21.960617ms)
May 14 16:06:34.542: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 22.87895ms)
May 14 16:06:34.545: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 25.892509ms)
May 14 16:06:34.545: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 26.376849ms)
May 14 16:06:34.545: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 26.185413ms)
May 14 16:06:34.545: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 26.256966ms)
May 14 16:06:34.545: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 26.104721ms)
May 14 16:06:34.545: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 26.387151ms)
May 14 16:06:34.546: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 26.613841ms)
May 14 16:06:34.548: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 28.920299ms)
May 14 16:06:34.548: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 29.085793ms)
May 14 16:06:34.548: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 28.732249ms)
May 14 16:06:34.548: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 28.858535ms)
May 14 16:06:34.548: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 28.760762ms)
May 14 16:06:34.564: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 15.578435ms)
May 14 16:06:34.565: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 17.089329ms)
May 14 16:06:34.565: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 17.077734ms)
May 14 16:06:34.566: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 17.933479ms)
May 14 16:06:34.570: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 21.547374ms)
May 14 16:06:34.570: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 21.628738ms)
May 14 16:06:34.570: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 21.782785ms)
May 14 16:06:34.571: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 22.811938ms)
May 14 16:06:34.573: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 24.752543ms)
May 14 16:06:34.573: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 24.945771ms)
May 14 16:06:34.573: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 24.832371ms)
May 14 16:06:34.573: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 25.084363ms)
May 14 16:06:34.574: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 25.63435ms)
May 14 16:06:34.577: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 29.125792ms)
May 14 16:06:34.578: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 30.318807ms)
May 14 16:06:34.579: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 30.395932ms)
May 14 16:06:34.599: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 19.94489ms)
May 14 16:06:34.599: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 19.666459ms)
May 14 16:06:34.601: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 21.743058ms)
May 14 16:06:34.602: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 23.142448ms)
May 14 16:06:34.602: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 23.398897ms)
May 14 16:06:34.602: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 23.406281ms)
May 14 16:06:34.603: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 24.367856ms)
May 14 16:06:34.603: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 24.52868ms)
May 14 16:06:34.603: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 24.71075ms)
May 14 16:06:34.603: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 24.587826ms)
May 14 16:06:34.603: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 24.407658ms)
May 14 16:06:34.604: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 25.091435ms)
May 14 16:06:34.604: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 25.397234ms)
May 14 16:06:34.604: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 25.289952ms)
May 14 16:06:34.605: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 26.261852ms)
May 14 16:06:34.605: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 26.408879ms)
May 14 16:06:34.627: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 21.915544ms)
May 14 16:06:34.627: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 21.989461ms)
May 14 16:06:34.627: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 22.145564ms)
May 14 16:06:34.628: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 22.032402ms)
May 14 16:06:34.628: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 22.001533ms)
May 14 16:06:34.629: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 23.706379ms)
May 14 16:06:34.632: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 26.862908ms)
May 14 16:06:34.632: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 26.947778ms)
May 14 16:06:34.632: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 26.668445ms)
May 14 16:06:34.633: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 27.433936ms)
May 14 16:06:34.633: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 27.707349ms)
May 14 16:06:34.634: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 28.071462ms)
May 14 16:06:34.634: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 28.299661ms)
May 14 16:06:34.634: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 28.376416ms)
May 14 16:06:34.635: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 28.821704ms)
May 14 16:06:34.635: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 29.338545ms)
May 14 16:06:34.661: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 25.732318ms)
May 14 16:06:34.661: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 25.840831ms)
May 14 16:06:34.664: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 28.643667ms)
May 14 16:06:34.664: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 28.43347ms)
May 14 16:06:34.669: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 33.944537ms)
May 14 16:06:34.669: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 34.229977ms)
May 14 16:06:34.670: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 34.670401ms)
May 14 16:06:34.670: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 34.755579ms)
May 14 16:06:34.670: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 34.735049ms)
May 14 16:06:34.670: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 34.825533ms)
May 14 16:06:34.670: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 34.814863ms)
May 14 16:06:34.671: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 35.611344ms)
May 14 16:06:34.671: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 35.655785ms)
May 14 16:06:34.672: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 37.013634ms)
May 14 16:06:34.672: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 37.225379ms)
May 14 16:06:34.673: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 38.182971ms)
May 14 16:06:34.691: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 17.077954ms)
May 14 16:06:34.691: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 17.504409ms)
May 14 16:06:34.693: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 19.348757ms)
May 14 16:06:34.693: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 19.31888ms)
May 14 16:06:34.696: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 22.996044ms)
May 14 16:06:34.697: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 23.199699ms)
May 14 16:06:34.700: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 26.09451ms)
May 14 16:06:34.700: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 26.316582ms)
May 14 16:06:34.700: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 26.308987ms)
May 14 16:06:34.700: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 25.99669ms)
May 14 16:06:34.700: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 26.138517ms)
May 14 16:06:34.701: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 27.649501ms)
May 14 16:06:34.702: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 28.163202ms)
May 14 16:06:34.702: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 28.439957ms)
May 14 16:06:34.702: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 28.117228ms)
May 14 16:06:34.702: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 28.697994ms)
May 14 16:06:34.718: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl/proxy/rewriteme"... (200; 15.733453ms)
May 14 16:06:34.722: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 19.6082ms)
May 14 16:06:34.722: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:443/proxy/... (200; 19.728157ms)
May 14 16:06:34.722: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 19.975471ms)
May 14 16:06:34.722: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:162/proxy/: bar (200; 19.976821ms)
May 14 16:06:34.725: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:1080/proxy/... (200; 22.650759ms)
May 14 16:06:34.725: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:462/proxy/: tls qux (200; 22.776721ms)
May 14 16:06:34.725: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/https:proxy-service-kpgv8-xr9tl:460/proxy/: tls baz (200; 22.840878ms)
May 14 16:06:34.725: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/proxy-service-kpgv8-xr9tl:1080/proxy/rewri... (200; 22.715352ms)
May 14 16:06:34.726: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname2/proxy/: tls qux (200; 23.651866ms)
May 14 16:06:34.726: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/https:proxy-service-kpgv8:tlsportname1/proxy/: tls baz (200; 23.713592ms)
May 14 16:06:34.726: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname2/proxy/: bar (200; 23.962793ms)
May 14 16:06:34.730: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname1/proxy/: foo (200; 28.257152ms)
May 14 16:06:34.730: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/http:proxy-service-kpgv8:portname2/proxy/: bar (200; 28.180756ms)
May 14 16:06:34.731: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/services/proxy-service-kpgv8:portname1/proxy/: foo (200; 28.662274ms)
May 14 16:06:34.731: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-j5rcj/pods/http:proxy-service-kpgv8-xr9tl:160/proxy/: foo (200; 28.570363ms)
STEP: deleting { ReplicationController} proxy-service-kpgv8 in namespace e2e-tests-proxy-j5rcj, will wait for the garbage collector to delete the pods
May 14 16:06:34.964: INFO: Deleting { ReplicationController} proxy-service-kpgv8 took: 91.494215ms
May 14 16:06:35.064: INFO: Terminating { ReplicationController} proxy-service-kpgv8 pods took: 100.277716ms
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:06:36.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-j5rcj" for this suite.
May 14 16:06:42.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:06:43.983: INFO: namespace: e2e-tests-proxy-j5rcj, resource: bindings, ignored listing per whitelist
May 14 16:06:45.800: INFO: namespace e2e-tests-proxy-j5rcj deletion completed in 9.331101569s

• [SLOW TEST:22.469 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:06:45.801: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0514 16:07:26.471726     651 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 14 16:07:26.471: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:07:26.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mddwz" for this suite.
May 14 16:07:32.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:07:33.414: INFO: namespace: e2e-tests-gc-mddwz, resource: bindings, ignored listing per whitelist
May 14 16:07:35.671: INFO: namespace e2e-tests-gc-mddwz deletion completed in 9.196771561s

• [SLOW TEST:49.870 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:07:35.671: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-fvlsg A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-fvlsg;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-fvlsg A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-fvlsg;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-fvlsg.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-fvlsg.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-fvlsg.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-fvlsg.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-fvlsg.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-fvlsg.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-fvlsg.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fvlsg.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-fvlsg.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-fvlsg.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-fvlsg.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-fvlsg.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-fvlsg.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 236.252.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.252.236_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 236.252.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.252.236_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-fvlsg A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-fvlsg;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-fvlsg A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-fvlsg;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-fvlsg.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-fvlsg.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-fvlsg.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-fvlsg.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-fvlsg.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-fvlsg.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-fvlsg.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-fvlsg.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-fvlsg.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-fvlsg.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-fvlsg.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-fvlsg.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-fvlsg.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 236.252.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.252.236_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 236.252.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.252.236_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 14 16:07:58.443: INFO: DNS probes using dns-test-637c711f-7662-11e9-96ed-42d4de3e15aa succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:07:58.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-fvlsg" for this suite.
May 14 16:08:05.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:08:06.204: INFO: namespace: e2e-tests-dns-fvlsg, resource: bindings, ignored listing per whitelist
May 14 16:08:08.229: INFO: namespace e2e-tests-dns-fvlsg deletion completed in 9.340989864s

• [SLOW TEST:32.558 seconds]
[sig-network] DNS
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:08:08.229: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1053
STEP: creating an rc
May 14 16:08:08.455: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-qblhz'
May 14 16:08:08.782: INFO: stderr: ""
May 14 16:08:08.782: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Waiting for Redis master to start.
May 14 16:08:09.869: INFO: Selector matched 1 pods for map[app:redis]
May 14 16:08:09.869: INFO: Found 0 / 1
May 14 16:08:10.786: INFO: Selector matched 1 pods for map[app:redis]
May 14 16:08:10.786: INFO: Found 1 / 1
May 14 16:08:10.786: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 14 16:08:10.788: INFO: Selector matched 1 pods for map[app:redis]
May 14 16:08:10.788: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 14 16:08:10.788: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 logs redis-master-p8tsj redis-master --namespace=e2e-tests-kubectl-qblhz'
May 14 16:08:11.098: INFO: stderr: ""
May 14 16:08:11.098: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 May 16:08:09.844 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 May 16:08:09.845 # Server started, Redis version 3.2.12\n1:M 14 May 16:08:09.845 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 May 16:08:09.845 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 14 16:08:11.098: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 log redis-master-p8tsj redis-master --namespace=e2e-tests-kubectl-qblhz --tail=1'
May 14 16:08:11.227: INFO: stderr: ""
May 14 16:08:11.227: INFO: stdout: "1:M 14 May 16:08:09.845 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 14 16:08:11.227: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 log redis-master-p8tsj redis-master --namespace=e2e-tests-kubectl-qblhz --limit-bytes=1'
May 14 16:08:11.352: INFO: stderr: ""
May 14 16:08:11.352: INFO: stdout: " "
STEP: exposing timestamps
May 14 16:08:11.352: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 log redis-master-p8tsj redis-master --namespace=e2e-tests-kubectl-qblhz --tail=1 --timestamps'
May 14 16:08:11.579: INFO: stderr: ""
May 14 16:08:11.579: INFO: stdout: "2019-05-14T16:08:09.846058884Z 1:M 14 May 16:08:09.845 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 14 16:08:14.080: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 log redis-master-p8tsj redis-master --namespace=e2e-tests-kubectl-qblhz --since=1s'
May 14 16:08:14.201: INFO: stderr: ""
May 14 16:08:14.201: INFO: stdout: ""
May 14 16:08:14.201: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 log redis-master-p8tsj redis-master --namespace=e2e-tests-kubectl-qblhz --since=24h'
May 14 16:08:14.329: INFO: stderr: ""
May 14 16:08:14.329: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 May 16:08:09.844 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 May 16:08:09.845 # Server started, Redis version 3.2.12\n1:M 14 May 16:08:09.845 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 May 16:08:09.845 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1058
STEP: using delete to clean up resources
May 14 16:08:14.329: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qblhz'
May 14 16:08:14.619: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 16:08:14.619: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 14 16:08:14.619: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-qblhz'
May 14 16:08:14.900: INFO: stderr: "No resources found.\n"
May 14 16:08:14.900: INFO: stdout: ""
May 14 16:08:14.900: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -l name=nginx --namespace=e2e-tests-kubectl-qblhz -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 14 16:08:15.006: INFO: stderr: ""
May 14 16:08:15.006: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:08:15.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qblhz" for this suite.
May 14 16:08:37.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:08:38.204: INFO: namespace: e2e-tests-kubectl-qblhz, resource: bindings, ignored listing per whitelist
May 14 16:08:40.091: INFO: namespace e2e-tests-kubectl-qblhz deletion completed in 25.081213384s

• [SLOW TEST:31.862 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should be able to retrieve and filter logs  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:08:40.091: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 16:08:40.332: INFO: Waiting up to 5m0s for pod "downwardapi-volume-89cdea62-7662-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-z9mnx" to be "success or failure"
May 14 16:08:40.424: INFO: Pod "downwardapi-volume-89cdea62-7662-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 92.052641ms
May 14 16:08:42.428: INFO: Pod "downwardapi-volume-89cdea62-7662-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.096008473s
STEP: Saw pod success
May 14 16:08:42.428: INFO: Pod "downwardapi-volume-89cdea62-7662-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:08:42.433: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-89cdea62-7662-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 16:08:42.654: INFO: Waiting for pod downwardapi-volume-89cdea62-7662-11e9-96ed-42d4de3e15aa to disappear
May 14 16:08:42.751: INFO: Pod downwardapi-volume-89cdea62-7662-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:08:42.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-z9mnx" for this suite.
May 14 16:08:48.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:08:49.311: INFO: namespace: e2e-tests-downward-api-z9mnx, resource: bindings, ignored listing per whitelist
May 14 16:08:52.217: INFO: namespace e2e-tests-downward-api-z9mnx deletion completed in 9.461532363s

• [SLOW TEST:12.126 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:08:52.217: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1012
STEP: creating the pod
May 14 16:08:52.368: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-w746n'
May 14 16:08:52.737: INFO: stderr: ""
May 14 16:08:52.737: INFO: stdout: "pod/pause created\n"
May 14 16:08:52.737: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 14 16:08:52.737: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-w746n" to be "running and ready"
May 14 16:08:52.844: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 107.271908ms
May 14 16:08:54.848: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.111481287s
May 14 16:08:54.848: INFO: Pod "pause" satisfied condition "running and ready"
May 14 16:08:54.848: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: adding the label testing-label with value testing-label-value to a pod
May 14 16:08:54.848: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-w746n'
May 14 16:08:55.044: INFO: stderr: ""
May 14 16:08:55.044: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 14 16:08:55.044: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pod pause -L testing-label --namespace=e2e-tests-kubectl-w746n'
May 14 16:08:55.173: INFO: stderr: ""
May 14 16:08:55.174: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          3s        testing-label-value\n"
STEP: removing the label testing-label of a pod
May 14 16:08:55.174: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 label pods pause testing-label- --namespace=e2e-tests-kubectl-w746n'
May 14 16:08:55.285: INFO: stderr: ""
May 14 16:08:55.285: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 14 16:08:55.285: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pod pause -L testing-label --namespace=e2e-tests-kubectl-w746n'
May 14 16:08:55.385: INFO: stderr: ""
May 14 16:08:55.385: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          3s        \n"
[AfterEach] [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1018
STEP: using delete to clean up resources
May 14 16:08:55.386: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w746n'
May 14 16:08:55.681: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 16:08:55.681: INFO: stdout: "pod \"pause\" force deleted\n"
May 14 16:08:55.681: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-w746n'
May 14 16:08:55.997: INFO: stderr: "No resources found.\n"
May 14 16:08:55.997: INFO: stdout: ""
May 14 16:08:55.997: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pods -l name=pause --namespace=e2e-tests-kubectl-w746n -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 14 16:08:56.173: INFO: stderr: ""
May 14 16:08:56.173: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:08:56.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w746n" for this suite.
May 14 16:09:02.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:09:03.928: INFO: namespace: e2e-tests-kubectl-w746n, resource: bindings, ignored listing per whitelist
May 14 16:09:05.320: INFO: namespace e2e-tests-kubectl-w746n deletion completed in 9.142926317s

• [SLOW TEST:13.103 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should update the label on a resource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:09:05.320: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 14 16:09:05.563: INFO: Waiting up to 5m0s for pod "pod-98d72fbc-7662-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-29kpv" to be "success or failure"
May 14 16:09:05.654: INFO: Pod "pod-98d72fbc-7662-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 91.226188ms
May 14 16:09:07.659: INFO: Pod "pod-98d72fbc-7662-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.095893271s
STEP: Saw pod success
May 14 16:09:07.659: INFO: Pod "pod-98d72fbc-7662-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:09:07.661: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-98d72fbc-7662-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 16:09:07.860: INFO: Waiting for pod pod-98d72fbc-7662-11e9-96ed-42d4de3e15aa to disappear
May 14 16:09:07.946: INFO: Pod pod-98d72fbc-7662-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:09:07.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-29kpv" for this suite.
May 14 16:09:14.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:09:14.319: INFO: namespace: e2e-tests-emptydir-29kpv, resource: bindings, ignored listing per whitelist
May 14 16:09:17.338: INFO: namespace e2e-tests-emptydir-29kpv deletion completed in 9.389488042s

• [SLOW TEST:12.018 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:09:17.339: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-map-9fffe4ca-7662-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 16:09:17.662: INFO: Waiting up to 5m0s for pod "pod-secrets-a00d39aa-7662-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-secrets-vwgcv" to be "success or failure"
May 14 16:09:17.754: INFO: Pod "pod-secrets-a00d39aa-7662-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 92.209398ms
May 14 16:09:19.760: INFO: Pod "pod-secrets-a00d39aa-7662-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.097895094s
STEP: Saw pod success
May 14 16:09:19.760: INFO: Pod "pod-secrets-a00d39aa-7662-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:09:19.763: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-secrets-a00d39aa-7662-11e9-96ed-42d4de3e15aa container secret-volume-test: <nil>
STEP: delete the pod
May 14 16:09:19.983: INFO: Waiting for pod pod-secrets-a00d39aa-7662-11e9-96ed-42d4de3e15aa to disappear
May 14 16:09:20.077: INFO: Pod pod-secrets-a00d39aa-7662-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:09:20.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vwgcv" for this suite.
May 14 16:09:26.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:09:29.628: INFO: namespace: e2e-tests-secrets-vwgcv, resource: bindings, ignored listing per whitelist
May 14 16:09:29.628: INFO: namespace e2e-tests-secrets-vwgcv deletion completed in 9.548224713s

• [SLOW TEST:12.290 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:09:29.629: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
May 14 16:09:29.862: INFO: Waiting up to 5m0s for pod "downward-api-a753a984-7662-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-gw8r4" to be "success or failure"
May 14 16:09:29.968: INFO: Pod "downward-api-a753a984-7662-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 106.394105ms
May 14 16:09:31.971: INFO: Pod "downward-api-a753a984-7662-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.109821481s
STEP: Saw pod success
May 14 16:09:31.972: INFO: Pod "downward-api-a753a984-7662-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:09:31.975: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downward-api-a753a984-7662-11e9-96ed-42d4de3e15aa container dapi-container: <nil>
STEP: delete the pod
May 14 16:09:32.170: INFO: Waiting for pod downward-api-a753a984-7662-11e9-96ed-42d4de3e15aa to disappear
May 14 16:09:32.256: INFO: Pod downward-api-a753a984-7662-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:09:32.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gw8r4" for this suite.
May 14 16:09:38.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:09:40.409: INFO: namespace: e2e-tests-downward-api-gw8r4, resource: bindings, ignored listing per whitelist
May 14 16:09:41.470: INFO: namespace e2e-tests-downward-api-gw8r4 deletion completed in 9.210715995s

• [SLOW TEST:11.842 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:09:41.470: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 16:09:41.834: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ae7269e7-7662-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-qk67m" to be "success or failure"
May 14 16:09:41.924: INFO: Pod "downwardapi-volume-ae7269e7-7662-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 90.230423ms
May 14 16:09:43.932: INFO: Pod "downwardapi-volume-ae7269e7-7662-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.098055998s
STEP: Saw pod success
May 14 16:09:43.932: INFO: Pod "downwardapi-volume-ae7269e7-7662-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:09:43.935: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-ae7269e7-7662-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 16:09:44.152: INFO: Waiting for pod downwardapi-volume-ae7269e7-7662-11e9-96ed-42d4de3e15aa to disappear
May 14 16:09:44.245: INFO: Pod downwardapi-volume-ae7269e7-7662-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:09:44.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qk67m" for this suite.
May 14 16:09:50.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:09:52.114: INFO: namespace: e2e-tests-downward-api-qk67m, resource: bindings, ignored listing per whitelist
May 14 16:09:53.438: INFO: namespace e2e-tests-downward-api-qk67m deletion completed in 9.189220247s

• [SLOW TEST:11.968 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:09:53.438: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:10:53.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jv765" for this suite.
May 14 16:11:15.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:11:19.209: INFO: namespace: e2e-tests-container-probe-jv765, resource: bindings, ignored listing per whitelist
May 14 16:11:19.377: INFO: namespace e2e-tests-container-probe-jv765 deletion completed in 25.596764129s

• [SLOW TEST:85.939 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:11:19.378: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
[It] should update a single-container pod's image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 14 16:11:19.624: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 run e2e-test-nginx-pod --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-ldc4d'
May 14 16:11:20.089: INFO: stderr: ""
May 14 16:11:20.090: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 14 16:11:25.190: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-ldc4d -o json'
May 14 16:11:25.393: INFO: stderr: ""
May 14 16:11:25.393: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-05-14T16:11:20Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-ldc4d\",\n        \"resourceVersion\": \"15755\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-ldc4d/pods/e2e-test-nginx-pod\",\n        \"uid\": \"e911c7f0-7662-11e9-a4a8-42010a8c006e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/nginx-slim-amd64:0.20\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-pxtpw\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-pxtpw\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-pxtpw\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-14T16:11:20Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-14T16:11:21Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": null,\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-14T16:11:20Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f1df395b05fc641f485c21e0a789320312cee4f4341c297508510e315346d26b\",\n                \"image\": \"k8s.gcr.io/nginx-slim-amd64:0.20\",\n                \"imageID\": \"docker-pullable://k8s.gcr.io/nginx-slim-amd64@sha256:6654db6d4028756062edac466454ee5c9cf9b20ef79e35a81e3c840031eb1e2b\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-14T16:11:21Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.140.0.68\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.40.1.185\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-14T16:11:20Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 14 16:11:25.393: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 replace -f - --namespace=e2e-tests-kubectl-ldc4d'
May 14 16:11:25.733: INFO: stderr: ""
May 14 16:11:25.733: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image busybox
[AfterEach] [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1485
May 14 16:11:25.735: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-ldc4d'
May 14 16:11:34.273: INFO: stderr: ""
May 14 16:11:34.273: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:11:34.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ldc4d" for this suite.
May 14 16:11:40.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:11:42.997: INFO: namespace: e2e-tests-kubectl-ldc4d, resource: bindings, ignored listing per whitelist
May 14 16:11:43.802: INFO: namespace e2e-tests-kubectl-ldc4d deletion completed in 9.517532947s

• [SLOW TEST:24.425 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should update a single-container pod's image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:11:43.802: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should support proxy with --port 0  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: starting the proxy server
May 14 16:11:43.957: INFO: Asynchronously running '/workspace/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:11:44.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rgnvc" for this suite.
May 14 16:11:50.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:11:53.363: INFO: namespace: e2e-tests-kubectl-rgnvc, resource: bindings, ignored listing per whitelist
May 14 16:11:53.632: INFO: namespace e2e-tests-kubectl-rgnvc deletion completed in 9.574058563s

• [SLOW TEST:9.829 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should support proxy with --port 0  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:11:53.632: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating secret with name secret-test-fd322576-7662-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 16:11:54.022: INFO: Waiting up to 5m0s for pod "pod-secrets-fd40452d-7662-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-secrets-82cbg" to be "success or failure"
May 14 16:11:54.116: INFO: Pod "pod-secrets-fd40452d-7662-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 93.333008ms
May 14 16:11:56.119: INFO: Pod "pod-secrets-fd40452d-7662-11e9-96ed-42d4de3e15aa": Phase="Running", Reason="", readiness=true. Elapsed: 2.096951832s
May 14 16:11:58.123: INFO: Pod "pod-secrets-fd40452d-7662-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.100863267s
STEP: Saw pod success
May 14 16:11:58.123: INFO: Pod "pod-secrets-fd40452d-7662-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:11:58.126: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-secrets-fd40452d-7662-11e9-96ed-42d4de3e15aa container secret-volume-test: <nil>
STEP: delete the pod
May 14 16:11:58.324: INFO: Waiting for pod pod-secrets-fd40452d-7662-11e9-96ed-42d4de3e15aa to disappear
May 14 16:11:58.416: INFO: Pod pod-secrets-fd40452d-7662-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:11:58.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-82cbg" for this suite.
May 14 16:12:04.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:12:06.392: INFO: namespace: e2e-tests-secrets-82cbg, resource: bindings, ignored listing per whitelist
May 14 16:12:07.782: INFO: namespace e2e-tests-secrets-82cbg deletion completed in 9.361587138s

• [SLOW TEST:14.150 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:12:07.782: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:80
May 14 16:12:07.924: INFO: Waiting up to 1m0s for all nodes to be ready
May 14 16:13:08.029: INFO: Waiting for terminating namespaces to be deleted...
May 14 16:13:08.227: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 14 16:13:08.504: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 14 16:13:08.504: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
May 14 16:13:08.507: INFO: Waiting for pods to enter Success, but no pods in "kube-system" match label map[name:e2e-image-puller]
May 14 16:13:08.507: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk before test
May 14 16:13:08.606: INFO: heapster-v1.6.0-beta.1-f7c96fb9f-4lh6l from kube-system started at 2019-05-14 15:07:07 +0000 UTC (3 container statuses recorded)
May 14 16:13:08.606: INFO: 	Container heapster ready: true, restart count 0
May 14 16:13:08.607: INFO: 	Container heapster-nanny ready: true, restart count 0
May 14 16:13:08.607: INFO: 	Container prom-to-sd ready: true, restart count 0
May 14 16:13:08.607: INFO: prometheus-to-sd-6kt4f from kube-system started at 2019-05-14 15:06:34 +0000 UTC (1 container statuses recorded)
May 14 16:13:08.607: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 16:13:08.607: INFO: metrics-server-v0.2.1-fd596d746-dpxml from kube-system started at 2019-05-14 15:07:03 +0000 UTC (2 container statuses recorded)
May 14 16:13:08.607: INFO: 	Container metrics-server ready: true, restart count 0
May 14 16:13:08.607: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 14 16:13:08.607: INFO: kube-proxy-gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk from kube-system started at <nil> (0 container statuses recorded)
May 14 16:13:08.607: INFO: fluentd-gcp-v3.2.0-2d4fx from kube-system started at 2019-05-14 15:07:05 +0000 UTC (2 container statuses recorded)
May 14 16:13:08.607: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 14 16:13:08.607: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 14 16:13:08.607: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq before test
May 14 16:13:08.704: INFO: prometheus-to-sd-gcjjw from kube-system started at 2019-05-14 15:06:36 +0000 UTC (1 container statuses recorded)
May 14 16:13:08.704: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 16:13:08.704: INFO: fluentd-gcp-v3.2.0-kjzgl from kube-system started at 2019-05-14 15:07:05 +0000 UTC (2 container statuses recorded)
May 14 16:13:08.704: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 14 16:13:08.704: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 14 16:13:08.704: INFO: kube-proxy-gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq from kube-system started at <nil> (0 container statuses recorded)
May 14 16:13:08.704: INFO: kube-dns-785fdb56c-w2llr from kube-system started at 2019-05-14 15:06:57 +0000 UTC (4 container statuses recorded)
May 14 16:13:08.704: INFO: 	Container dnsmasq ready: true, restart count 0
May 14 16:13:08.704: INFO: 	Container kubedns ready: true, restart count 0
May 14 16:13:08.704: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 16:13:08.704: INFO: 	Container sidecar ready: true, restart count 0
May 14 16:13:08.704: INFO: 
Logging pods the kubelet thinks is on node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m before test
May 14 16:13:08.801: INFO: fluentd-gcp-v3.2.0-96cdk from kube-system started at 2019-05-14 15:07:10 +0000 UTC (2 container statuses recorded)
May 14 16:13:08.801: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 14 16:13:08.801: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 14 16:13:08.801: INFO: event-exporter-v0.2.3-767cfb76f9-qbjbv from kube-system started at 2019-05-14 15:06:54 +0000 UTC (2 container statuses recorded)
May 14 16:13:08.801: INFO: 	Container event-exporter ready: true, restart count 0
May 14 16:13:08.801: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 14 16:13:08.801: INFO: l7-default-backend-7ff48cffd7-7dcfl from kube-system started at 2019-05-14 15:06:54 +0000 UTC (1 container statuses recorded)
May 14 16:13:08.801: INFO: 	Container default-http-backend ready: true, restart count 0
May 14 16:13:08.801: INFO: prometheus-to-sd-cdzjw from kube-system started at 2019-05-14 15:06:34 +0000 UTC (1 container statuses recorded)
May 14 16:13:08.801: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 16:13:08.801: INFO: kube-proxy-gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-m00m from kube-system started at <nil> (0 container statuses recorded)
May 14 16:13:08.801: INFO: kube-dns-785fdb56c-zq2ht from kube-system started at 2019-05-14 15:06:54 +0000 UTC (4 container statuses recorded)
May 14 16:13:08.801: INFO: 	Container dnsmasq ready: true, restart count 0
May 14 16:13:08.801: INFO: 	Container kubedns ready: true, restart count 0
May 14 16:13:08.801: INFO: 	Container prometheus-to-sd ready: true, restart count 0
May 14 16:13:08.801: INFO: 	Container sidecar ready: true, restart count 0
May 14 16:13:08.801: INFO: kube-dns-autoscaler-67c97c87fb-6fsr5 from kube-system started at 2019-05-14 15:06:54 +0000 UTC (1 container statuses recorded)
May 14 16:13:08.801: INFO: 	Container autoscaler ready: true, restart count 0
May 14 16:13:08.801: INFO: fluentd-gcp-scaler-8b674f786-c4slq from kube-system started at 2019-05-14 15:06:54 +0000 UTC (1 container statuses recorded)
May 14 16:13:08.801: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.159e98acce0f65f5], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:13:10.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-ktjxg" for this suite.
May 14 16:13:16.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:13:18.178: INFO: namespace: e2e-tests-sched-pred-ktjxg, resource: bindings, ignored listing per whitelist
May 14 16:13:19.561: INFO: namespace e2e-tests-sched-pred-ktjxg deletion completed in 9.475049563s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:71

• [SLOW TEST:71.780 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:13:19.562: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-lb42p
May 14 16:13:22.061: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-lb42p
STEP: checking the pod's current state and verifying that restartCount is present
May 14 16:13:22.063: INFO: Initial restart count of pod liveness-http is 0
May 14 16:13:36.089: INFO: Restart count of pod e2e-tests-container-probe-lb42p/liveness-http is now 1 (14.026174192s elapsed)
May 14 16:13:56.128: INFO: Restart count of pod e2e-tests-container-probe-lb42p/liveness-http is now 2 (34.064527756s elapsed)
May 14 16:14:16.356: INFO: Restart count of pod e2e-tests-container-probe-lb42p/liveness-http is now 3 (54.293137571s elapsed)
May 14 16:14:36.393: INFO: Restart count of pod e2e-tests-container-probe-lb42p/liveness-http is now 4 (1m14.330247619s elapsed)
May 14 16:15:48.521: INFO: Restart count of pod e2e-tests-container-probe-lb42p/liveness-http is now 5 (2m26.458271309s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:15:48.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lb42p" for this suite.
May 14 16:15:54.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:15:57.346: INFO: namespace: e2e-tests-container-probe-lb42p, resource: bindings, ignored listing per whitelist
May 14 16:15:58.132: INFO: namespace e2e-tests-container-probe-lb42p deletion completed in 9.425671872s

• [SLOW TEST:158.570 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:15:58.132: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-map-8ef24d6c-7663-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 16:15:58.614: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8f0029e2-7663-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-j6dqz" to be "success or failure"
May 14 16:15:58.703: INFO: Pod "pod-projected-configmaps-8f0029e2-7663-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 89.210197ms
May 14 16:16:00.707: INFO: Pod "pod-projected-configmaps-8f0029e2-7663-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.092418112s
STEP: Saw pod success
May 14 16:16:00.707: INFO: Pod "pod-projected-configmaps-8f0029e2-7663-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:16:00.710: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-configmaps-8f0029e2-7663-11e9-96ed-42d4de3e15aa container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 16:16:00.915: INFO: Waiting for pod pod-projected-configmaps-8f0029e2-7663-11e9-96ed-42d4de3e15aa to disappear
May 14 16:16:01.015: INFO: Pod pod-projected-configmaps-8f0029e2-7663-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:16:01.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j6dqz" for this suite.
May 14 16:16:09.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:16:09.331: INFO: namespace: e2e-tests-projected-j6dqz, resource: bindings, ignored listing per whitelist
May 14 16:16:12.628: INFO: namespace e2e-tests-projected-j6dqz deletion completed in 11.609828011s

• [SLOW TEST:14.496 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:16:12.629: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1371
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 14 16:16:12.788: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-x92mj'
May 14 16:16:12.998: INFO: stderr: ""
May 14 16:16:12.998: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1376
May 14 16:16:13.095: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-x92mj'
May 14 16:16:13.421: INFO: stderr: ""
May 14 16:16:13.421: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:16:13.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x92mj" for this suite.
May 14 16:16:19.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:16:23.049: INFO: namespace: e2e-tests-kubectl-x92mj, resource: bindings, ignored listing per whitelist
May 14 16:16:23.049: INFO: namespace e2e-tests-kubectl-x92mj deletion completed in 9.62296431s

• [SLOW TEST:10.421 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a job from an image when restart is OnFailure  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:16:23.049: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create services for rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating Redis RC
May 14 16:16:23.302: INFO: namespace e2e-tests-kubectl-cs7sb
May 14 16:16:23.302: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-cs7sb'
May 14 16:16:23.620: INFO: stderr: ""
May 14 16:16:23.620: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 14 16:16:24.708: INFO: Selector matched 1 pods for map[app:redis]
May 14 16:16:24.708: INFO: Found 0 / 1
May 14 16:16:25.625: INFO: Selector matched 1 pods for map[app:redis]
May 14 16:16:25.625: INFO: Found 1 / 1
May 14 16:16:25.625: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 14 16:16:25.627: INFO: Selector matched 1 pods for map[app:redis]
May 14 16:16:25.627: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 14 16:16:25.627: INFO: wait on redis-master startup in e2e-tests-kubectl-cs7sb 
May 14 16:16:25.627: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 logs redis-master-n2k5l redis-master --namespace=e2e-tests-kubectl-cs7sb'
May 14 16:16:25.959: INFO: stderr: ""
May 14 16:16:25.959: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 May 16:16:25.372 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 May 16:16:25.372 # Server started, Redis version 3.2.12\n1:M 14 May 16:16:25.372 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 May 16:16:25.372 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 14 16:16:25.959: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-cs7sb'
May 14 16:16:26.308: INFO: stderr: ""
May 14 16:16:26.308: INFO: stdout: "service/rm2 exposed\n"
May 14 16:16:26.404: INFO: Service rm2 in namespace e2e-tests-kubectl-cs7sb found.
STEP: exposing service
May 14 16:16:28.509: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-cs7sb'
May 14 16:16:28.640: INFO: stderr: ""
May 14 16:16:28.640: INFO: stdout: "service/rm3 exposed\n"
May 14 16:16:28.734: INFO: Service rm3 in namespace e2e-tests-kubectl-cs7sb found.
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:16:30.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cs7sb" for this suite.
May 14 16:16:53.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:16:55.738: INFO: namespace: e2e-tests-kubectl-cs7sb, resource: bindings, ignored listing per whitelist
May 14 16:16:56.387: INFO: namespace e2e-tests-kubectl-cs7sb deletion completed in 25.442742767s

• [SLOW TEST:33.337 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create services for rc  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:16:56.387: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 14 16:16:56.549: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:16:58.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-2k9ws" for this suite.
May 14 16:17:04.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:17:06.670: INFO: namespace: e2e-tests-custom-resource-definition-2k9ws, resource: bindings, ignored listing per whitelist
May 14 16:17:07.430: INFO: namespace e2e-tests-custom-resource-definition-2k9ws deletion completed in 9.356059473s

• [SLOW TEST:11.043 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:17:07.430: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating projection with secret that has name projected-secret-test-b8335c39-7663-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 16:17:07.767: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b8423444-7663-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-6qxn8" to be "success or failure"
May 14 16:17:07.873: INFO: Pod "pod-projected-secrets-b8423444-7663-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 105.822766ms
May 14 16:17:09.876: INFO: Pod "pod-projected-secrets-b8423444-7663-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.108840366s
STEP: Saw pod success
May 14 16:17:09.876: INFO: Pod "pod-projected-secrets-b8423444-7663-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:17:09.878: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-secrets-b8423444-7663-11e9-96ed-42d4de3e15aa container projected-secret-volume-test: <nil>
STEP: delete the pod
May 14 16:17:10.105: INFO: Waiting for pod pod-projected-secrets-b8423444-7663-11e9-96ed-42d4de3e15aa to disappear
May 14 16:17:10.199: INFO: Pod pod-projected-secrets-b8423444-7663-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:17:10.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6qxn8" for this suite.
May 14 16:17:16.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:17:18.428: INFO: namespace: e2e-tests-projected-6qxn8, resource: bindings, ignored listing per whitelist
May 14 16:17:20.268: INFO: namespace e2e-tests-projected-6qxn8 deletion completed in 10.06586166s

• [SLOW TEST:12.838 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:17:20.268: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 14 16:17:20.936: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 14 16:17:21.159: INFO: Number of nodes with available pods: 0
May 14 16:17:21.159: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 16:17:22.170: INFO: Number of nodes with available pods: 0
May 14 16:17:22.170: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 16:17:23.166: INFO: Number of nodes with available pods: 2
May 14 16:17:23.166: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq is running more than one daemon pod
May 14 16:17:24.166: INFO: Number of nodes with available pods: 3
May 14 16:17:24.166: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 14 16:17:24.552: INFO: Wrong image for pod: daemon-set-fr7c5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:24.552: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:24.552: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:25.560: INFO: Wrong image for pod: daemon-set-fr7c5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:25.560: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:25.560: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:26.561: INFO: Wrong image for pod: daemon-set-fr7c5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:26.561: INFO: Pod daemon-set-fr7c5 is not available
May 14 16:17:26.561: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:26.561: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:27.561: INFO: Wrong image for pod: daemon-set-fr7c5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:27.561: INFO: Pod daemon-set-fr7c5 is not available
May 14 16:17:27.561: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:27.561: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:28.560: INFO: Wrong image for pod: daemon-set-fr7c5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:28.561: INFO: Pod daemon-set-fr7c5 is not available
May 14 16:17:28.561: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:28.561: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:29.562: INFO: Wrong image for pod: daemon-set-fr7c5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:29.562: INFO: Pod daemon-set-fr7c5 is not available
May 14 16:17:29.562: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:29.562: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:30.562: INFO: Wrong image for pod: daemon-set-fr7c5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:30.563: INFO: Pod daemon-set-fr7c5 is not available
May 14 16:17:30.563: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:30.563: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:31.565: INFO: Wrong image for pod: daemon-set-fr7c5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:31.566: INFO: Pod daemon-set-fr7c5 is not available
May 14 16:17:31.566: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:31.566: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:32.561: INFO: Wrong image for pod: daemon-set-fr7c5. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:32.562: INFO: Pod daemon-set-fr7c5 is not available
May 14 16:17:32.562: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:32.562: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:33.568: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:33.568: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:34.560: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:34.561: INFO: Pod daemon-set-r289z is not available
May 14 16:17:34.561: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:35.561: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:35.561: INFO: Pod daemon-set-r289z is not available
May 14 16:17:35.561: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:36.560: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:36.561: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:36.561: INFO: Pod daemon-set-tx675 is not available
May 14 16:17:37.560: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:37.560: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:37.560: INFO: Pod daemon-set-tx675 is not available
May 14 16:17:38.560: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:38.560: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:38.560: INFO: Pod daemon-set-tx675 is not available
May 14 16:17:39.560: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:39.560: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:39.560: INFO: Pod daemon-set-tx675 is not available
May 14 16:17:40.560: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:40.560: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:40.560: INFO: Pod daemon-set-tx675 is not available
May 14 16:17:41.588: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:41.588: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:41.588: INFO: Pod daemon-set-tx675 is not available
May 14 16:17:42.561: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:42.561: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:42.561: INFO: Pod daemon-set-tx675 is not available
May 14 16:17:43.561: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:43.561: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:43.561: INFO: Pod daemon-set-tx675 is not available
May 14 16:17:44.561: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:44.561: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:44.561: INFO: Pod daemon-set-tx675 is not available
May 14 16:17:45.562: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:45.562: INFO: Wrong image for pod: daemon-set-tx675. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:45.562: INFO: Pod daemon-set-tx675 is not available
May 14 16:17:46.561: INFO: Pod daemon-set-8tkb6 is not available
May 14 16:17:46.561: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:47.562: INFO: Pod daemon-set-8tkb6 is not available
May 14 16:17:47.563: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:48.563: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:49.560: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:49.560: INFO: Pod daemon-set-jpzs9 is not available
May 14 16:17:50.562: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:50.562: INFO: Pod daemon-set-jpzs9 is not available
May 14 16:17:51.569: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:51.570: INFO: Pod daemon-set-jpzs9 is not available
May 14 16:17:52.561: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:52.561: INFO: Pod daemon-set-jpzs9 is not available
May 14 16:17:53.561: INFO: Wrong image for pod: daemon-set-jpzs9. Expected: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname-amd64:1.0.
May 14 16:17:53.561: INFO: Pod daemon-set-jpzs9 is not available
May 14 16:17:54.561: INFO: Pod daemon-set-dlhjv is not available
STEP: Check that daemon pods are still running on every node of the cluster.
May 14 16:17:54.579: INFO: Number of nodes with available pods: 2
May 14 16:17:54.579: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 16:17:55.590: INFO: Number of nodes with available pods: 2
May 14 16:17:55.590: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 16:17:56.588: INFO: Number of nodes with available pods: 2
May 14 16:17:56.588: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 16:17:57.590: INFO: Number of nodes with available pods: 3
May 14 16:17:57.591: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-9d6hp, will wait for the garbage collector to delete the pods
May 14 16:17:57.948: INFO: Deleting {extensions DaemonSet} daemon-set took: 99.211956ms
May 14 16:17:58.049: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.764262ms
May 14 16:18:05.854: INFO: Number of nodes with available pods: 0
May 14 16:18:05.854: INFO: Number of running nodes: 0, number of available pods: 0
May 14 16:18:05.856: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9d6hp/daemonsets","resourceVersion":"17062"},"items":null}

May 14 16:18:05.858: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9d6hp/pods","resourceVersion":"17062"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:18:05.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9d6hp" for this suite.
May 14 16:18:11.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:18:14.690: INFO: namespace: e2e-tests-daemonsets-9d6hp, resource: bindings, ignored listing per whitelist
May 14 16:18:14.947: INFO: namespace e2e-tests-daemonsets-9d6hp deletion completed in 9.077575887s

• [SLOW TEST:54.679 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:18:14.948: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[It] should create and stop a working application  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating all guestbook components
May 14 16:18:15.082: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 14 16:18:15.082: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-dw2tw'
May 14 16:18:15.785: INFO: stderr: ""
May 14 16:18:15.785: INFO: stdout: "service/redis-slave created\n"
May 14 16:18:15.785: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 14 16:18:15.785: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-dw2tw'
May 14 16:18:16.220: INFO: stderr: ""
May 14 16:18:16.220: INFO: stdout: "service/redis-master created\n"
May 14 16:18:16.220: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 14 16:18:16.220: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-dw2tw'
May 14 16:18:16.763: INFO: stderr: ""
May 14 16:18:16.763: INFO: stdout: "service/frontend created\n"
May 14 16:18:16.763: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend-amd64:v5
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 14 16:18:16.763: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-dw2tw'
May 14 16:18:17.298: INFO: stderr: ""
May 14 16:18:17.298: INFO: stdout: "deployment.extensions/frontend created\n"
May 14 16:18:17.298: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis-amd64:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 14 16:18:17.298: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-dw2tw'
May 14 16:18:17.710: INFO: stderr: ""
May 14 16:18:17.710: INFO: stdout: "deployment.extensions/redis-master created\n"
May 14 16:18:17.710: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave-amd64:v2
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 14 16:18:17.710: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 create -f - --namespace=e2e-tests-kubectl-dw2tw'
May 14 16:18:18.065: INFO: stderr: ""
May 14 16:18:18.065: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
May 14 16:18:18.065: INFO: Waiting for all frontend pods to be Running.
May 14 16:18:38.171: INFO: Waiting for frontend to serve content.
May 14 16:18:38.378: INFO: Trying to add a new entry to the guestbook.
May 14 16:18:38.388: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May 14 16:18:38.404: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dw2tw'
May 14 16:18:38.900: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 16:18:38.900: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 14 16:18:38.900: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dw2tw'
May 14 16:18:39.354: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 16:18:39.354: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 14 16:18:39.354: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dw2tw'
May 14 16:18:39.818: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 16:18:39.818: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 14 16:18:39.818: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dw2tw'
May 14 16:18:40.264: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 16:18:40.264: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 14 16:18:40.264: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dw2tw'
May 14 16:18:40.662: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 16:18:40.662: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 14 16:18:40.662: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dw2tw'
May 14 16:18:41.102: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 14 16:18:41.102: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:18:41.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dw2tw" for this suite.
May 14 16:19:19.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:19:21.149: INFO: namespace: e2e-tests-kubectl-dw2tw, resource: bindings, ignored listing per whitelist
May 14 16:19:22.557: INFO: namespace e2e-tests-kubectl-dw2tw deletion completed in 41.360814168s

• [SLOW TEST:67.610 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create and stop a working application  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:19:22.559: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: getting the auto-created API token
May 14 16:19:23.684: INFO: created pod pod-service-account-defaultsa
May 14 16:19:23.685: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 14 16:19:23.706: INFO: created pod pod-service-account-mountsa
May 14 16:19:23.706: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 14 16:19:23.722: INFO: created pod pod-service-account-nomountsa
May 14 16:19:23.723: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 14 16:19:23.740: INFO: created pod pod-service-account-defaultsa-mountspec
May 14 16:19:23.741: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 14 16:19:23.762: INFO: created pod pod-service-account-mountsa-mountspec
May 14 16:19:23.763: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 14 16:19:23.788: INFO: created pod pod-service-account-nomountsa-mountspec
May 14 16:19:23.789: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 14 16:19:23.810: INFO: created pod pod-service-account-defaultsa-nomountspec
May 14 16:19:23.811: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 14 16:19:23.840: INFO: created pod pod-service-account-mountsa-nomountspec
May 14 16:19:23.840: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 14 16:19:23.860: INFO: created pod pod-service-account-nomountsa-nomountspec
May 14 16:19:23.861: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:19:23.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-f5zhs" for this suite.
May 14 16:19:30.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:19:32.286: INFO: namespace: e2e-tests-svcaccounts-f5zhs, resource: bindings, ignored listing per whitelist
May 14 16:19:33.161: INFO: namespace e2e-tests-svcaccounts-f5zhs deletion completed in 9.291374298s

• [SLOW TEST:10.603 seconds]
[sig-auth] ServiceAccounts
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:19:33.162: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:244
[BeforeEach] [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
[It] should create a pod from an image when restart is Never  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: running the image k8s.gcr.io/nginx-slim-amd64:0.20
May 14 16:19:33.317: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=k8s.gcr.io/nginx-slim-amd64:0.20 --namespace=e2e-tests-kubectl-h9bpl'
May 14 16:19:33.652: INFO: stderr: ""
May 14 16:19:33.652: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1449
May 14 16:19:33.741: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.230.205.166 --kubeconfig=/tmp/gke-kubecfg055961731 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-h9bpl'
May 14 16:19:34.458: INFO: stderr: ""
May 14 16:19:34.458: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:19:34.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h9bpl" for this suite.
May 14 16:19:40.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:19:43.572: INFO: namespace: e2e-tests-kubectl-h9bpl, resource: bindings, ignored listing per whitelist
May 14 16:19:44.014: INFO: namespace e2e-tests-kubectl-h9bpl deletion completed in 9.552304426s

• [SLOW TEST:10.852 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
    should create a pod from an image when restart is Never  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:19:44.014: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 16:19:44.327: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1592bae6-7664-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-x7lf8" to be "success or failure"
May 14 16:19:44.452: INFO: Pod "downwardapi-volume-1592bae6-7664-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 124.578167ms
May 14 16:19:46.458: INFO: Pod "downwardapi-volume-1592bae6-7664-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.130789656s
STEP: Saw pod success
May 14 16:19:46.459: INFO: Pod "downwardapi-volume-1592bae6-7664-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:19:46.462: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-1592bae6-7664-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 16:19:46.713: INFO: Waiting for pod downwardapi-volume-1592bae6-7664-11e9-96ed-42d4de3e15aa to disappear
May 14 16:19:46.803: INFO: Pod downwardapi-volume-1592bae6-7664-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:19:46.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x7lf8" for this suite.
May 14 16:19:52.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:19:53.203: INFO: namespace: e2e-tests-projected-x7lf8, resource: bindings, ignored listing per whitelist
May 14 16:19:56.082: INFO: namespace e2e-tests-projected-x7lf8 deletion completed in 9.274567818s

• [SLOW TEST:12.068 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:19:56.082: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 14 16:19:56.922: INFO: Number of nodes with available pods: 0
May 14 16:19:56.922: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 16:19:57.933: INFO: Number of nodes with available pods: 0
May 14 16:19:57.934: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk is running more than one daemon pod
May 14 16:19:58.946: INFO: Number of nodes with available pods: 3
May 14 16:19:58.946: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 14 16:19:59.215: INFO: Number of nodes with available pods: 2
May 14 16:19:59.215: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq is running more than one daemon pod
May 14 16:20:00.227: INFO: Number of nodes with available pods: 2
May 14 16:20:00.228: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq is running more than one daemon pod
May 14 16:20:01.228: INFO: Number of nodes with available pods: 2
May 14 16:20:01.229: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq is running more than one daemon pod
May 14 16:20:02.237: INFO: Number of nodes with available pods: 2
May 14 16:20:02.238: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq is running more than one daemon pod
May 14 16:20:03.229: INFO: Number of nodes with available pods: 2
May 14 16:20:03.230: INFO: Node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-bkjq is running more than one daemon pod
May 14 16:20:04.222: INFO: Number of nodes with available pods: 3
May 14 16:20:04.222: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-xln6z, will wait for the garbage collector to delete the pods
May 14 16:20:04.548: INFO: Deleting {extensions DaemonSet} daemon-set took: 93.35994ms
May 14 16:20:04.649: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.289207ms
May 14 16:20:15.852: INFO: Number of nodes with available pods: 0
May 14 16:20:15.852: INFO: Number of running nodes: 0, number of available pods: 0
May 14 16:20:15.854: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-xln6z/daemonsets","resourceVersion":"17717"},"items":null}

May 14 16:20:15.856: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-xln6z/pods","resourceVersion":"17717"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:20:15.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-xln6z" for this suite.
May 14 16:20:21.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:20:22.128: INFO: namespace: e2e-tests-daemonsets-xln6z, resource: bindings, ignored listing per whitelist
May 14 16:20:25.085: INFO: namespace e2e-tests-daemonsets-xln6z deletion completed in 9.218266838s

• [SLOW TEST:29.003 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:20:25.086: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name projected-configmap-test-volume-2e042920-7664-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 16:20:25.441: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2e141c36-7664-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-sn2gw" to be "success or failure"
May 14 16:20:25.545: INFO: Pod "pod-projected-configmaps-2e141c36-7664-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 104.053594ms
May 14 16:20:27.549: INFO: Pod "pod-projected-configmaps-2e141c36-7664-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.107507348s
STEP: Saw pod success
May 14 16:20:27.549: INFO: Pod "pod-projected-configmaps-2e141c36-7664-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:20:27.551: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-projected-configmaps-2e141c36-7664-11e9-96ed-42d4de3e15aa container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 14 16:20:27.776: INFO: Waiting for pod pod-projected-configmaps-2e141c36-7664-11e9-96ed-42d4de3e15aa to disappear
May 14 16:20:27.865: INFO: Pod pod-projected-configmaps-2e141c36-7664-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:20:27.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sn2gw" for this suite.
May 14 16:20:34.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:20:36.915: INFO: namespace: e2e-tests-projected-sn2gw, resource: bindings, ignored listing per whitelist
May 14 16:20:43.492: INFO: namespace e2e-tests-projected-sn2gw deletion completed in 15.623994757s

• [SLOW TEST:18.407 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:20:43.495: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-390fb3fb-7664-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 16:20:44.221: INFO: Waiting up to 5m0s for pod "pod-configmaps-391ec9ce-7664-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-configmap-288wj" to be "success or failure"
May 14 16:20:44.458: INFO: Pod "pod-configmaps-391ec9ce-7664-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 236.713966ms
May 14 16:20:46.466: INFO: Pod "pod-configmaps-391ec9ce-7664-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.244741308s
STEP: Saw pod success
May 14 16:20:46.467: INFO: Pod "pod-configmaps-391ec9ce-7664-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:20:46.470: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-configmaps-391ec9ce-7664-11e9-96ed-42d4de3e15aa container configmap-volume-test: <nil>
STEP: delete the pod
May 14 16:20:46.679: INFO: Waiting for pod pod-configmaps-391ec9ce-7664-11e9-96ed-42d4de3e15aa to disappear
May 14 16:20:46.800: INFO: Pod pod-configmaps-391ec9ce-7664-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:20:46.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-288wj" for this suite.
May 14 16:20:53.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:20:55.929: INFO: namespace: e2e-tests-configmap-288wj, resource: bindings, ignored listing per whitelist
May 14 16:20:56.537: INFO: namespace e2e-tests-configmap-288wj deletion completed in 9.734065047s

• [SLOW TEST:13.043 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:20:56.537: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name cm-test-opt-del-40e16f2e-7664-11e9-96ed-42d4de3e15aa
STEP: Creating configMap with name cm-test-opt-upd-40e16f8b-7664-11e9-96ed-42d4de3e15aa
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-40e16f2e-7664-11e9-96ed-42d4de3e15aa
STEP: Updating configmap cm-test-opt-upd-40e16f8b-7664-11e9-96ed-42d4de3e15aa
STEP: Creating configMap with name cm-test-opt-create-40e16fa4-7664-11e9-96ed-42d4de3e15aa
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:21:01.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zxvf7" for this suite.
May 14 16:21:25.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:21:28.989: INFO: namespace: e2e-tests-projected-zxvf7, resource: bindings, ignored listing per whitelist
May 14 16:21:29.243: INFO: namespace e2e-tests-projected-zxvf7 deletion completed in 27.604516846s

• [SLOW TEST:32.706 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:21:29.245: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
May 14 16:21:29.510: INFO: Waiting up to 5m0s for pod "downward-api-544575dc-7664-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-427f4" to be "success or failure"
May 14 16:21:29.606: INFO: Pod "downward-api-544575dc-7664-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 95.441091ms
May 14 16:21:31.609: INFO: Pod "downward-api-544575dc-7664-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.09876251s
May 14 16:21:33.613: INFO: Pod "downward-api-544575dc-7664-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.102081149s
STEP: Saw pod success
May 14 16:21:33.613: INFO: Pod "downward-api-544575dc-7664-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:21:33.614: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downward-api-544575dc-7664-11e9-96ed-42d4de3e15aa container dapi-container: <nil>
STEP: delete the pod
May 14 16:21:33.838: INFO: Waiting for pod downward-api-544575dc-7664-11e9-96ed-42d4de3e15aa to disappear
May 14 16:21:33.974: INFO: Pod downward-api-544575dc-7664-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:21:33.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-427f4" for this suite.
May 14 16:21:40.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:21:42.370: INFO: namespace: e2e-tests-downward-api-427f4, resource: bindings, ignored listing per whitelist
May 14 16:21:43.527: INFO: namespace e2e-tests-downward-api-427f4 deletion completed in 9.548625373s

• [SLOW TEST:14.283 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:21:43.528: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating secret e2e-tests-secrets-fmqtb/secret-test-5cc4d2d8-7664-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume secrets
May 14 16:21:43.876: INFO: Waiting up to 5m0s for pod "pod-configmaps-5cd523f8-7664-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-secrets-fmqtb" to be "success or failure"
May 14 16:21:43.975: INFO: Pod "pod-configmaps-5cd523f8-7664-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 98.950233ms
May 14 16:21:45.978: INFO: Pod "pod-configmaps-5cd523f8-7664-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.10208762s
May 14 16:21:47.981: INFO: Pod "pod-configmaps-5cd523f8-7664-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.105199322s
STEP: Saw pod success
May 14 16:21:47.981: INFO: Pod "pod-configmaps-5cd523f8-7664-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:21:47.985: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-configmaps-5cd523f8-7664-11e9-96ed-42d4de3e15aa container env-test: <nil>
STEP: delete the pod
May 14 16:21:48.193: INFO: Waiting for pod pod-configmaps-5cd523f8-7664-11e9-96ed-42d4de3e15aa to disappear
May 14 16:21:48.280: INFO: Pod pod-configmaps-5cd523f8-7664-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:21:48.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fmqtb" for this suite.
May 14 16:21:54.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:21:56.416: INFO: namespace: e2e-tests-secrets-fmqtb, resource: bindings, ignored listing per whitelist
May 14 16:21:57.600: INFO: namespace e2e-tests-secrets-fmqtb deletion completed in 9.316860673s

• [SLOW TEST:14.073 seconds]
[sig-api-machinery] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:21:57.600: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0514 16:21:58.761858     651 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 14 16:21:58.761: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:21:58.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5pl85" for this suite.
May 14 16:22:04.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:22:07.345: INFO: namespace: e2e-tests-gc-5pl85, resource: bindings, ignored listing per whitelist
May 14 16:22:07.990: INFO: namespace e2e-tests-gc-5pl85 deletion completed in 9.226080473s

• [SLOW TEST:10.390 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:22:07.991: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on node default medium
May 14 16:22:08.253: INFO: Waiting up to 5m0s for pod "pod-6b5b5be9-7664-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-6458x" to be "success or failure"
May 14 16:22:08.340: INFO: Pod "pod-6b5b5be9-7664-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 87.08626ms
May 14 16:22:10.344: INFO: Pod "pod-6b5b5be9-7664-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090836534s
May 14 16:22:12.347: INFO: Pod "pod-6b5b5be9-7664-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.093980928s
STEP: Saw pod success
May 14 16:22:12.347: INFO: Pod "pod-6b5b5be9-7664-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:22:12.349: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-6b5b5be9-7664-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 16:22:12.548: INFO: Waiting for pod pod-6b5b5be9-7664-11e9-96ed-42d4de3e15aa to disappear
May 14 16:22:12.640: INFO: Pod pod-6b5b5be9-7664-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:22:12.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6458x" for this suite.
May 14 16:22:18.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:22:21.440: INFO: namespace: e2e-tests-emptydir-6458x, resource: bindings, ignored listing per whitelist
May 14 16:22:21.877: INFO: namespace e2e-tests-emptydir-6458x deletion completed in 9.233530265s

• [SLOW TEST:13.886 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:22:21.877: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-m67fl
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 14 16:22:22.018: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 14 16:22:46.693: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.1.219:8080/dial?request=hostName&protocol=udp&host=10.40.2.56&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-m67fl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 16:22:46.693: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 16:22:46.870: INFO: Waiting for endpoints: map[]
May 14 16:22:46.872: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.1.219:8080/dial?request=hostName&protocol=udp&host=10.40.0.38&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-m67fl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 16:22:46.873: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 16:22:46.938: INFO: Waiting for endpoints: map[]
May 14 16:22:46.941: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.1.219:8080/dial?request=hostName&protocol=udp&host=10.40.1.218&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-m67fl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 14 16:22:46.941: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
May 14 16:22:47.008: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:22:47.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-m67fl" for this suite.
May 14 16:23:09.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:23:09.977: INFO: namespace: e2e-tests-pod-network-test-m67fl, resource: bindings, ignored listing per whitelist
May 14 16:23:12.483: INFO: namespace e2e-tests-pod-network-test-m67fl deletion completed in 25.471831025s

• [SLOW TEST:50.607 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:23:12.484: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:84
[It] should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:23:12.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-q6m6w" for this suite.
May 14 16:23:19.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:23:21.530: INFO: namespace: e2e-tests-services-q6m6w, resource: bindings, ignored listing per whitelist
May 14 16:23:22.374: INFO: namespace e2e-tests-services-q6m6w deletion completed in 9.445906223s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:89

• [SLOW TEST:9.891 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:23:22.375: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward api env vars
May 14 16:23:22.634: INFO: Waiting up to 5m0s for pod "downward-api-97b12b28-7664-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-downward-api-c26cx" to be "success or failure"
May 14 16:23:22.748: INFO: Pod "downward-api-97b12b28-7664-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 113.46032ms
May 14 16:23:24.751: INFO: Pod "downward-api-97b12b28-7664-11e9-96ed-42d4de3e15aa": Phase="Running", Reason="", readiness=true. Elapsed: 2.116839375s
May 14 16:23:26.762: INFO: Pod "downward-api-97b12b28-7664-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.128036054s
STEP: Saw pod success
May 14 16:23:26.762: INFO: Pod "downward-api-97b12b28-7664-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:23:26.776: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downward-api-97b12b28-7664-11e9-96ed-42d4de3e15aa container dapi-container: <nil>
STEP: delete the pod
May 14 16:23:26.987: INFO: Waiting for pod downward-api-97b12b28-7664-11e9-96ed-42d4de3e15aa to disappear
May 14 16:23:27.075: INFO: Pod downward-api-97b12b28-7664-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:23:27.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c26cx" for this suite.
May 14 16:23:33.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:23:34.022: INFO: namespace: e2e-tests-downward-api-c26cx, resource: bindings, ignored listing per whitelist
May 14 16:23:36.533: INFO: namespace e2e-tests-downward-api-c26cx deletion completed in 9.453603559s

• [SLOW TEST:14.159 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:23:36.534: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
May 14 16:23:36.674: INFO: Creating ReplicaSet my-hostname-basic-a01f9297-7664-11e9-96ed-42d4de3e15aa
May 14 16:23:36.873: INFO: Pod name my-hostname-basic-a01f9297-7664-11e9-96ed-42d4de3e15aa: Found 1 pods out of 1
May 14 16:23:36.873: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-a01f9297-7664-11e9-96ed-42d4de3e15aa" is running
May 14 16:23:38.989: INFO: Pod "my-hostname-basic-a01f9297-7664-11e9-96ed-42d4de3e15aa-r6h97" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 16:23:36 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 16:23:36 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-a01f9297-7664-11e9-96ed-42d4de3e15aa]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:0001-01-01 00:00:00 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-a01f9297-7664-11e9-96ed-42d4de3e15aa]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-14 16:23:36 +0000 UTC Reason: Message:}])
May 14 16:23:38.989: INFO: Trying to dial the pod
May 14 16:23:44.133: INFO: Controller my-hostname-basic-a01f9297-7664-11e9-96ed-42d4de3e15aa: Got expected result from replica 1 [my-hostname-basic-a01f9297-7664-11e9-96ed-42d4de3e15aa-r6h97]: "my-hostname-basic-a01f9297-7664-11e9-96ed-42d4de3e15aa-r6h97", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:23:44.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-ddvqd" for this suite.
May 14 16:23:50.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:23:52.121: INFO: namespace: e2e-tests-replicaset-ddvqd, resource: bindings, ignored listing per whitelist
May 14 16:23:54.168: INFO: namespace e2e-tests-replicaset-ddvqd deletion completed in 10.031867831s

• [SLOW TEST:17.635 seconds]
[sig-apps] ReplicaSet
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] [sig-node] PreStop
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:23:54.168: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating server pod server in namespace e2e-tests-prestop-vd8l4
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-vd8l4
STEP: Deleting pre-stop pod
May 14 16:24:07.871: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:24:07.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-vd8l4" for this suite.
May 14 16:24:48.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:24:49.196: INFO: namespace: e2e-tests-prestop-vd8l4, resource: bindings, ignored listing per whitelist
May 14 16:24:51.465: INFO: namespace e2e-tests-prestop-vd8l4 deletion completed in 43.473561628s

• [SLOW TEST:57.296 seconds]
[k8s.io] [sig-node] PreStop
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:24:51.465: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test downward API volume plugin
May 14 16:24:51.709: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ccc96245-7664-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-projected-rpq6r" to be "success or failure"
May 14 16:24:51.805: INFO: Pod "downwardapi-volume-ccc96245-7664-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 95.826094ms
May 14 16:24:53.968: INFO: Pod "downwardapi-volume-ccc96245-7664-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.258583989s
STEP: Saw pod success
May 14 16:24:53.968: INFO: Pod "downwardapi-volume-ccc96245-7664-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:24:53.976: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod downwardapi-volume-ccc96245-7664-11e9-96ed-42d4de3e15aa container client-container: <nil>
STEP: delete the pod
May 14 16:24:54.188: INFO: Waiting for pod downwardapi-volume-ccc96245-7664-11e9-96ed-42d4de3e15aa to disappear
May 14 16:24:54.279: INFO: Pod downwardapi-volume-ccc96245-7664-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:24:54.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rpq6r" for this suite.
May 14 16:25:00.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:25:00.629: INFO: namespace: e2e-tests-projected-rpq6r, resource: bindings, ignored listing per whitelist
May 14 16:25:03.605: INFO: namespace e2e-tests-projected-rpq6r deletion completed in 9.239439949s

• [SLOW TEST:12.140 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:25:03.605: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:84
[It] should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating service endpoint-test2 in namespace e2e-tests-services-hdlcc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hdlcc to expose endpoints map[]
May 14 16:25:04.127: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hdlcc exposes endpoints map[] (102.307555ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-hdlcc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hdlcc to expose endpoints map[pod1:[80]]
May 14 16:25:07.337: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hdlcc exposes endpoints map[pod1:[80]] (3.112839709s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-hdlcc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hdlcc to expose endpoints map[pod1:[80] pod2:[80]]
May 14 16:25:09.477: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hdlcc exposes endpoints map[pod1:[80] pod2:[80]] (2.131188331s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-hdlcc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hdlcc to expose endpoints map[pod2:[80]]
May 14 16:25:10.589: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hdlcc exposes endpoints map[pod2:[80]] (1.020625635s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-hdlcc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hdlcc to expose endpoints map[]
May 14 16:25:10.717: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hdlcc exposes endpoints map[] (24.40685ms elapsed)
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:25:10.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-hdlcc" for this suite.
May 14 16:25:17.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:25:17.791: INFO: namespace: e2e-tests-services-hdlcc, resource: bindings, ignored listing per whitelist
May 14 16:25:20.371: INFO: namespace e2e-tests-services-hdlcc deletion completed in 9.509309095s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:89

• [SLOW TEST:16.766 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:25:20.373: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating configMap with name configmap-test-volume-map-de270829-7664-11e9-96ed-42d4de3e15aa
STEP: Creating a pod to test consume configMaps
May 14 16:25:20.947: INFO: Waiting up to 5m0s for pod "pod-configmaps-de368f0e-7664-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-configmap-wzjs6" to be "success or failure"
May 14 16:25:21.039: INFO: Pod "pod-configmaps-de368f0e-7664-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 91.478256ms
May 14 16:25:23.063: INFO: Pod "pod-configmaps-de368f0e-7664-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.115496973s
STEP: Saw pod success
May 14 16:25:23.064: INFO: Pod "pod-configmaps-de368f0e-7664-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:25:23.067: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-configmaps-de368f0e-7664-11e9-96ed-42d4de3e15aa container configmap-volume-test: <nil>
STEP: delete the pod
May 14 16:25:23.257: INFO: Waiting for pod pod-configmaps-de368f0e-7664-11e9-96ed-42d4de3e15aa to disappear
May 14 16:25:23.346: INFO: Pod pod-configmaps-de368f0e-7664-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:25:23.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wzjs6" for this suite.
May 14 16:25:29.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:25:31.516: INFO: namespace: e2e-tests-configmap-wzjs6, resource: bindings, ignored listing per whitelist
May 14 16:25:32.916: INFO: namespace e2e-tests-configmap-wzjs6 deletion completed in 9.56663473s

• [SLOW TEST:12.543 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:25:32.916: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-ngg62
May 14 16:25:35.259: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-ngg62
STEP: checking the pod's current state and verifying that restartCount is present
May 14 16:25:35.260: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:29:36.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ngg62" for this suite.
May 14 16:29:42.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:29:44.551: INFO: namespace: e2e-tests-container-probe-ngg62, resource: bindings, ignored listing per whitelist
May 14 16:29:46.083: INFO: namespace e2e-tests-container-probe-ngg62 deletion completed in 9.467106596s

• [SLOW TEST:253.167 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:29:46.083: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 14 16:29:46.893: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bpjtl,SelfLink:/api/v1/namespaces/e2e-tests-watch-bpjtl/configmaps/e2e-watch-test-label-changed,UID:7cacd183-7665-11e9-a4a8-42010a8c006e,ResourceVersion:19547,Generation:0,CreationTimestamp:2019-05-14 16:29:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 14 16:29:46.893: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bpjtl,SelfLink:/api/v1/namespaces/e2e-tests-watch-bpjtl/configmaps/e2e-watch-test-label-changed,UID:7cacd183-7665-11e9-a4a8-42010a8c006e,ResourceVersion:19550,Generation:0,CreationTimestamp:2019-05-14 16:29:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 14 16:29:46.893: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bpjtl,SelfLink:/api/v1/namespaces/e2e-tests-watch-bpjtl/configmaps/e2e-watch-test-label-changed,UID:7cacd183-7665-11e9-a4a8-42010a8c006e,ResourceVersion:19551,Generation:0,CreationTimestamp:2019-05-14 16:29:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 14 16:29:57.022: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bpjtl,SelfLink:/api/v1/namespaces/e2e-tests-watch-bpjtl/configmaps/e2e-watch-test-label-changed,UID:7cacd183-7665-11e9-a4a8-42010a8c006e,ResourceVersion:19577,Generation:0,CreationTimestamp:2019-05-14 16:29:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 14 16:29:57.023: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bpjtl,SelfLink:/api/v1/namespaces/e2e-tests-watch-bpjtl/configmaps/e2e-watch-test-label-changed,UID:7cacd183-7665-11e9-a4a8-42010a8c006e,ResourceVersion:19578,Generation:0,CreationTimestamp:2019-05-14 16:29:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 14 16:29:57.023: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bpjtl,SelfLink:/api/v1/namespaces/e2e-tests-watch-bpjtl/configmaps/e2e-watch-test-label-changed,UID:7cacd183-7665-11e9-a4a8-42010a8c006e,ResourceVersion:19579,Generation:0,CreationTimestamp:2019-05-14 16:29:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:29:57.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-bpjtl" for this suite.
May 14 16:30:03.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:30:06.351: INFO: namespace: e2e-tests-watch-bpjtl, resource: bindings, ignored listing per whitelist
May 14 16:30:06.352: INFO: namespace e2e-tests-watch-bpjtl deletion completed in 9.325429215s

• [SLOW TEST:20.268 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:30:06.352: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 14 16:30:06.610: INFO: Waiting up to 5m0s for pod "pod-8879e048-7665-11e9-96ed-42d4de3e15aa" in namespace "e2e-tests-emptydir-rgc7b" to be "success or failure"
May 14 16:30:06.702: INFO: Pod "pod-8879e048-7665-11e9-96ed-42d4de3e15aa": Phase="Pending", Reason="", readiness=false. Elapsed: 92.12503ms
May 14 16:30:08.706: INFO: Pod "pod-8879e048-7665-11e9-96ed-42d4de3e15aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.095332448s
STEP: Saw pod success
May 14 16:30:08.706: INFO: Pod "pod-8879e048-7665-11e9-96ed-42d4de3e15aa" satisfied condition "success or failure"
May 14 16:30:08.708: INFO: Trying to get logs from node gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-37tk pod pod-8879e048-7665-11e9-96ed-42d4de3e15aa container test-container: <nil>
STEP: delete the pod
May 14 16:30:08.917: INFO: Waiting for pod pod-8879e048-7665-11e9-96ed-42d4de3e15aa to disappear
May 14 16:30:09.003: INFO: Pod pod-8879e048-7665-11e9-96ed-42d4de3e15aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:30:09.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rgc7b" for this suite.
May 14 16:30:15.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:30:17.571: INFO: namespace: e2e-tests-emptydir-rgc7b, resource: bindings, ignored listing per whitelist
May 14 16:30:18.209: INFO: namespace e2e-tests-emptydir-rgc7b deletion completed in 9.200341889s

• [SLOW TEST:11.858 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:30:18.210: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:127
[It] should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: creating pod
May 14 16:30:20.594: INFO: Pod pod-hostip-8f8a9c69-7665-11e9-96ed-42d4de3e15aa has hostIP: 10.140.0.68
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:30:20.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-cvfs8" for this suite.
May 14 16:30:42.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:30:45.569: INFO: namespace: e2e-tests-pods-cvfs8, resource: bindings, ignored listing per whitelist
May 14 16:30:46.095: INFO: namespace e2e-tests-pods-cvfs8 deletion completed in 25.498497061s

• [SLOW TEST:27.886 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679
  should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141
STEP: Creating a kubernetes client
May 14 16:30:46.095: INFO: >>> kubeConfig: /tmp/gke-kubecfg055961731
STEP: Building a namespace api object
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38
[It] should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
STEP: Creating the pod
May 14 16:30:49.237: INFO: Successfully updated pod "labelsupdatea02c846a-7665-11e9-96ed-42d4de3e15aa"
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142
May 14 16:30:51.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qwx5p" for this suite.
May 14 16:31:13.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 14 16:31:16.425: INFO: namespace: e2e-tests-downward-api-qwx5p, resource: bindings, ignored listing per whitelist
May 14 16:31:16.675: INFO: namespace e2e-tests-downward-api-qwx5p deletion completed in 25.417460194s

• [SLOW TEST:30.580 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684
------------------------------
SSSSSSMay 14 16:31:16.675: INFO: Running AfterSuite actions on all node
May 14 16:31:16.675: INFO: Running AfterSuite actions on node 1
May 14 16:31:16.675: INFO: Skipping dumping logs from cluster

Ran 165 of 1009 Specs in 5045.414 seconds
SUCCESS! -- 165 Passed | 0 Failed | 0 Pending | 844 Skipped PASS

Ginkgo ran 1 suite in 1h24m5.897654581s
Test Suite Passed
2019/05/14 16:31:16 process.go:155: Step './hack/ginkgo-e2e.sh --ginkgo.focus=\[Conformance\] --ginkgo.skip=Alpha|\[(Disruptive|Feature:[^\]]+|Flaky)\] --gce-api-endpoint=https://www.googleapis.com/compute/cm_staging_v1/ --num-nodes=3 --report-dir=/logs/artifacts --disable-log-dump=true' finished in 1h24m6.388167842s
2019/05/14 16:31:16 process.go:153: Running: bash -c 
function log_dump_custom_get_instances() {
  if [[ $1 == "master" ]]; then
    return 0
  fi

  gcloud compute instances list '--project=senlu-customer-gce-staging' '--filter=(metadata.created-by:*zones/us-west1-pj1/instanceGroupManagers/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-grp)' '--format=get(name)'
}
export -f log_dump_custom_get_instances
# Set below vars that log-dump.sh expects in order to use scp with gcloud.
export PROJECT=senlu-customer-gce-staging
export ZONE='us-west1-pj1'
export KUBERNETES_PROVIDER=gke
export KUBE_NODE_OS_DISTRIBUTION='gci'
./cluster/log-dump/log-dump.sh '/logs/artifacts'
Checking for custom logdump instances, if any
Using 'use_custom_instance_list' with gke, skipping check for LOG_DUMP_SSH_KEY and LOG_DUMP_SSH_USER
Dumping logs from master locally to '/logs/artifacts'
No masters found?
Dumping logs from nodes locally to '/logs/artifacts'
Dumping logs for nodes provided by log_dump_custom_get_instances() function
No nodes found!
2019/05/14 16:31:18 process.go:155: Step 'bash -c 
function log_dump_custom_get_instances() {
  if [[ $1 == "master" ]]; then
    return 0
  fi

  gcloud compute instances list '--project=senlu-customer-gce-staging' '--filter=(metadata.created-by:*zones/us-west1-pj1/instanceGroupManagers/gke-e2e-f3159dd9b8-3e8d8-default-pool-556b11bb-grp)' '--format=get(name)'
}
export -f log_dump_custom_get_instances
# Set below vars that log-dump.sh expects in order to use scp with gcloud.
export PROJECT=senlu-customer-gce-staging
export ZONE='us-west1-pj1'
export KUBERNETES_PROVIDER=gke
export KUBE_NODE_OS_DISTRIBUTION='gci'
./cluster/log-dump/log-dump.sh '/logs/artifacts'
' finished in 1.771368775s
2019/05/14 16:31:18 process.go:153: Running: gcloud container clusters delete -q e2e-f3159dd9b8-3e8d8 --project=senlu-customer-gce-staging --zone=us-west1-pj1
Deleting cluster e2e-f3159dd9b8-3e8d8...
..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.
Deleted [https://gce-staging-sandbox-test-container.sandbox.googleapis.com/v1/projects/senlu-customer-gce-staging/zones/us-west1-pj1/clusters/e2e-f3159dd9b8-3e8d8].
2019/05/14 16:33:46 process.go:155: Step 'gcloud container clusters delete -q e2e-f3159dd9b8-3e8d8 --project=senlu-customer-gce-staging --zone=us-west1-pj1' finished in 2m28.523009613s
2019/05/14 16:33:46 process.go:96: Saved XML output to /logs/artifacts/junit_runner.xml.
+ EXIT_VALUE=0
+ set +o xtrace
